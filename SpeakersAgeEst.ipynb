{"cells":[{"cell_type":"markdown","metadata":{"id":"ywV7fuzi7Xdo"},"source":["# Prepare Environment"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"v5CcbARQGRgE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662207953110,"user_tz":-180,"elapsed":41764,"user":{"displayName":"אורי אוחיון","userId":"05864461685659628366"}},"outputId":"d025bed1-727e-447d-e9c7-f46ab10cee97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/DL_Projects/Final Project/Age_Estimation_Final_205362791\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from -r SpeakersAgeEstimation/requirements.txt (line 1)) (1.12.1+cu113)\n","Requirement already satisfied: torchaudio>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from -r SpeakersAgeEstimation/requirements.txt (line 2)) (0.12.1+cu113)\n","Collecting wavencoder\n","  Downloading wavencoder-0.1.3-py3-none-any.whl (30 kB)\n","Collecting pytorch-lightning==1.6.4\n","  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n","\u001b[K     |████████████████████████████████| 585 kB 12.7 MB/s \n","\u001b[?25hCollecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting torch-optimizer\n","  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 502 kB/s \n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 43.3 MB/s \n","\u001b[?25hCollecting tensorboardx\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 59.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r SpeakersAgeEstimation/requirements.txt (line 9)) (1.21.6)\n","Collecting blitz\n","  Downloading blitz-0.3.3.tar.gz (4.9 kB)\n","Collecting blitz-bayesian-pytorch\n","  Downloading blitz_bayesian_pytorch-0.2.8-py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (4.64.0)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 61.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (21.3)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (6.0)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (2022.7.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (4.1.1)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (3.17.3)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (2.8.0)\n","Collecting pyDeprecate>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (3.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (57.4.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.47.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (0.37.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.8.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (3.2.0)\n","Collecting fairseq\n","  Downloading fairseq-0.12.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n","\u001b[K     |████████████████████████████████| 11.0 MB 47.2 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r SpeakersAgeEstimation/requirements.txt (line 5)) (1.0.2)\n","Collecting pytorch-ranger>=0.1.1\n","  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r SpeakersAgeEstimation/requirements.txt (line 7)) (5.4.8)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r SpeakersAgeEstimation/requirements.txt (line 7)) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 59.5 MB/s \n","\u001b[?25hCollecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 59.5 MB/s \n","\u001b[?25hCollecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r SpeakersAgeEstimation/requirements.txt (line 7)) (2.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 59.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 34.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 60.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 60.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 69.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 67.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from blitz-bayesian-pytorch->-r SpeakersAgeEstimation/requirements.txt (line 11)) (7.1.2)\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from blitz-bayesian-pytorch->-r SpeakersAgeEstimation/requirements.txt (line 11)) (0.13.1+cu113)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r SpeakersAgeEstimation/requirements.txt (line 5)) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r SpeakersAgeEstimation/requirements.txt (line 5)) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r SpeakersAgeEstimation/requirements.txt (line 5)) (1.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.8.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4->-r SpeakersAgeEstimation/requirements.txt (line 4)) (0.13.0)\n","Collecting omegaconf<2.1\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Collecting bitarray\n","  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq->wavencoder->-r SpeakersAgeEstimation/requirements.txt (line 3)) (2022.6.2)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq->wavencoder->-r SpeakersAgeEstimation/requirements.txt (line 3)) (1.15.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq->wavencoder->-r SpeakersAgeEstimation/requirements.txt (line 3)) (0.29.32)\n","Collecting hydra-core<1.1,>=1.0.7\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 48.2 MB/s \n","\u001b[?25hCollecting sacrebleu>=1.4.12\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","\u001b[K     |████████████████████████████████| 116 kB 56.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq->wavencoder->-r SpeakersAgeEstimation/requirements.txt (line 3)) (5.9.0)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 60.5 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq->wavencoder->-r SpeakersAgeEstimation/requirements.txt (line 3)) (0.8.10)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq->wavencoder->-r SpeakersAgeEstimation/requirements.txt (line 3)) (4.9.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq->wavencoder->-r SpeakersAgeEstimation/requirements.txt (line 3)) (2.21)\n","Building wheels for collected packages: sklearn, blitz, antlr4-python3-runtime, pathtools\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=f71ea382a1bb4ad03e6a498719b4bf3ea2d2db7405d268bbd6df1a14097c8d63\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","  Building wheel for blitz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for blitz: filename=blitz-0.3.3-py3-none-any.whl size=7266 sha256=61543097981b05e9c781d08a38339a3639c9898dc1cb5333bb9fd0d1c8fc3d1d\n","  Stored in directory: /root/.cache/pip/wheels/f4/a6/fa/2cc6bf101f3fb314881157540650f617609bdb74df93d312a6\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=b7a4ea3ed9bf6b9c3c9041aaf1e488ab4b00f58eb89fadc7a3b0af9bdd7e64af\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=9a3f72afd0e1664e58c171f6ac68e467c5a90423d8ec9277cfabbec68890459e\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built sklearn blitz antlr4-python3-runtime pathtools\n","Installing collected packages: smmap, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, gitdb, bitarray, torchmetrics, shortuuid, setproctitle, sentry-sdk, pytorch-ranger, pyDeprecate, pathtools, GitPython, fairseq, docker-pycreds, wavencoder, wandb, torch-optimizer, tensorboardx, sklearn, pytorch-lightning, blitz-bayesian-pytorch, blitz\n","Successfully installed GitPython-3.1.27 antlr4-python3-runtime-4.8 bitarray-2.6.0 blitz-0.3.3 blitz-bayesian-pytorch-0.2.8 colorama-0.4.5 docker-pycreds-0.4.0 fairseq-0.12.2 gitdb-4.0.9 hydra-core-1.0.7 omegaconf-2.0.6 pathtools-0.1.2 portalocker-2.5.1 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 pytorch-ranger-0.1.1 sacrebleu-2.2.0 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 sklearn-0.0 smmap-5.0.0 tensorboardx-2.5.1 torch-optimizer-0.3.0 torchmetrics-0.9.3 wandb-0.13.2 wavencoder-0.1.3\n","/content/drive/MyDrive/DL_Projects/Final Project/Age_Estimation_Final_205362791/SpeakersAgeEstimation\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/DL_Projects/Final Project/Age_Estimation_Final_205362791\n","!pip install -r SpeakersAgeEstimation/requirements.txt\n","%cd SpeakersAgeEstimation/"]},{"cell_type":"markdown","metadata":{"id":"HVKZ0sF2_jJN"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"cGL4EEK8Aoah"},"source":["Edit config.py with data path or add as arguments"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuQxXIOt_ZeI","outputId":"71537526-29ad-444d-ba7c-9d9a6f49a9c4","executionInfo":{"status":"ok","timestamp":1662135986504,"user_tz":-180,"elapsed":10702342,"user":{"displayName":"אורי אוחיון","userId":"05864461685659628366"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 262:  56% 100/178 [00:20<00:16,  4.80it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.646]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.45it/s]\u001b[A\n","Epoch 262:  67% 120/178 [00:20<00:10,  5.72it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.646]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.05it/s]\u001b[A\n","Epoch 262:  79% 140/178 [00:21<00:05,  6.63it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.646]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.22it/s]\u001b[A\n","Epoch 262:  90% 160/178 [00:21<00:02,  7.52it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.646]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.85it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.85it/s]\u001b[A\n","Epoch 262: 100% 178/178 [00:21<00:00,  8.32it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.260, train/acc=0.646]\n","Epoch 263:   0% 0/178 [00:10<?, ?it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 263:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 102.25it/s]\u001b[A\n","Epoch 263:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 118.77it/s]\u001b[A\n","Epoch 263:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 122.58it/s]\u001b[A\n","Epoch 263:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 122.12it/s]\u001b[A\n","Epoch 263:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 124.62it/s]\u001b[A\n","Epoch 263:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 124.42it/s]\u001b[A\n","Epoch 263:  79% 140/178 [00:20<00:05,  6.76it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 125.13it/s]\u001b[A\n","Epoch 263:  90% 160/178 [00:20<00:02,  7.66it/s, loss=1.26, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.250, train/acc=0.653]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 131.68it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 131.68it/s]\u001b[A\n","Epoch 263: 100% 178/178 [00:20<00:00,  8.48it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.653]\n","Epoch 264:   0% 0/178 [00:00<?, ?it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 264:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.98it/s]\u001b[A\n","Epoch 264:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.66it/s]\u001b[A\n","Epoch 264:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.77it/s]\u001b[A\n","Epoch 264:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.85it/s]\u001b[A\n","Epoch 264:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.38it/s]\u001b[A\n","Epoch 264:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.56it/s]\u001b[A\n","Epoch 264:  79% 140/178 [00:20<00:05,  6.86it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.74it/s]\u001b[A\n","Epoch 264:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.440, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.65it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.65it/s]\u001b[A\n","Epoch 264: 100% 178/178 [00:20<00:00,  8.61it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.648]\n","Epoch 265:   0% 0/178 [00:00<?, ?it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Epoch 265:   0% 0/178 [00:19<?, ?it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 265:  11% 20/178 [00:19<02:32,  1.03it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 102.65it/s]\u001b[A\n","Epoch 265:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 115.11it/s]\u001b[A\n","Epoch 265:  34% 60/178 [00:19<00:38,  3.06it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.31it/s]\u001b[A\n","Epoch 265:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 124.57it/s]\u001b[A\n","Epoch 265:  56% 100/178 [00:19<00:15,  5.02it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.46it/s]\u001b[A\n","Epoch 265:  67% 120/178 [00:20<00:09,  5.98it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.52it/s]\u001b[A\n","Epoch 265:  79% 140/178 [00:20<00:05,  6.93it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.32it/s]\u001b[A\n","Epoch 265:  90% 160/178 [00:20<00:02,  7.85it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.250, train/acc=0.650]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.38it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.38it/s]\u001b[A\n","Epoch 265: 100% 178/178 [00:20<00:00,  8.69it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.250, train/acc=0.650]\n","                                                               \u001b[AMetric train/loss improved by 0.007 >= min_delta = 0.0. New best score: 1.233\n","Epoch 266:   0% 0/178 [00:18<?, ?it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 266:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:00, 153.27it/s]\u001b[A\n","Epoch 266:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 144.64it/s]\u001b[A\n","Epoch 266:  34% 60/178 [00:20<00:39,  3.00it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 140.85it/s]\u001b[A\n","Epoch 266:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 135.34it/s]\u001b[A\n","Epoch 266:  56% 100/178 [00:20<00:15,  4.92it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.23it/s]\u001b[A\n","Epoch 266:  67% 120/178 [00:20<00:09,  5.86it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.67it/s]\u001b[A\n","Epoch 266:  79% 140/178 [00:20<00:05,  6.79it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.09it/s]\u001b[A\n","Epoch 266:  90% 160/178 [00:20<00:02,  7.71it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.56it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.56it/s]\u001b[A\n","Epoch 266: 100% 178/178 [00:20<00:00,  8.52it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.230, train/acc=0.673]\n","Epoch 267:   0% 0/178 [00:17<?, ?it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 267:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 119.46it/s]\u001b[A\n","Epoch 267:  22% 40/178 [00:20<01:11,  1.94it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.94it/s]\u001b[A\n","Epoch 267:  34% 60/178 [00:20<00:40,  2.89it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.11it/s]\u001b[A\n","Epoch 267:  45% 80/178 [00:20<00:25,  3.82it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.68it/s]\u001b[A\n","Epoch 267:  56% 100/178 [00:21<00:16,  4.75it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.47it/s]\u001b[A\n","Epoch 267:  67% 120/178 [00:21<00:10,  5.65it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.41it/s]\u001b[A\n","Epoch 267:  79% 140/178 [00:21<00:05,  6.55it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.59it/s]\u001b[A\n","Epoch 267:  90% 160/178 [00:21<00:02,  7.43it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.62it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.62it/s]\u001b[A\n","Epoch 267: 100% 178/178 [00:21<00:00,  8.22it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.240, train/acc=0.662]\n","Epoch 268:   0% 0/178 [00:15<?, ?it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 268:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.59it/s]\u001b[A\n","Epoch 268:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.46it/s]\u001b[A\n","Epoch 268:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.79it/s]\u001b[A\n","Epoch 268:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.36it/s]\u001b[A\n","Epoch 268:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 127.69it/s]\u001b[A\n","Epoch 268:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.28it/s]\u001b[A\n","Epoch 268:  79% 140/178 [00:20<00:05,  6.86it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.76it/s]\u001b[A\n","Epoch 268:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.25, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.96it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.96it/s]\u001b[A\n","Epoch 268: 100% 178/178 [00:20<00:00,  8.61it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.655]\n","Epoch 269:   0% 0/178 [00:15<?, ?it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 269:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.71it/s]\u001b[A\n","Epoch 269:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.18it/s]\u001b[A\n","Epoch 269:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.09it/s]\u001b[A\n","Epoch 269:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.13it/s]\u001b[A\n","Epoch 269:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.17it/s]\u001b[A\n","Epoch 269:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.35it/s]\u001b[A\n","Epoch 269:  79% 140/178 [00:20<00:05,  6.85it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.46it/s]\u001b[A\n","Epoch 269:  90% 160/178 [00:20<00:02,  7.77it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.10it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.10it/s]\u001b[A\n","Epoch 269: 100% 178/178 [00:20<00:00,  8.60it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.250, train/acc=0.659]\n","Epoch 270:   0% 0/178 [00:14<?, ?it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 270:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 115.80it/s]\u001b[A\n","Epoch 270:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.04it/s]\u001b[A\n","Epoch 270:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.61it/s]\u001b[A\n","Epoch 270:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.72it/s]\u001b[A\n","Epoch 270:  56% 100/178 [00:20<00:16,  4.83it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.77it/s]\u001b[A\n","Epoch 270:  67% 120/178 [00:20<00:10,  5.76it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.08it/s]\u001b[A\n","Epoch 270:  79% 140/178 [00:20<00:05,  6.67it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.31it/s]\u001b[A\n","Epoch 270:  90% 160/178 [00:21<00:02,  7.56it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.24it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.24it/s]\u001b[A\n","Epoch 270: 100% 178/178 [00:21<00:00,  8.37it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.240, train/acc=0.662]\n","                                                               \u001b[AMetric train/loss improved by 0.006 >= min_delta = 0.0. New best score: 1.227\n","Epoch 271:   0% 0/178 [00:13<?, ?it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 271:  11% 20/178 [00:18<02:29,  1.06it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 110.82it/s]\u001b[A\n","Epoch 271:  22% 40/178 [00:19<01:05,  2.10it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.35it/s]\u001b[A\n","Epoch 271:  34% 60/178 [00:19<00:37,  3.12it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.95it/s]\u001b[A\n","Epoch 271:  45% 80/178 [00:19<00:23,  4.13it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.56it/s]\u001b[A\n","Epoch 271:  56% 100/178 [00:19<00:15,  5.12it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.08it/s]\u001b[A\n","Epoch 271:  67% 120/178 [00:19<00:09,  6.10it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.38it/s]\u001b[A\n","Epoch 271:  79% 140/178 [00:19<00:05,  7.06it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.05it/s]\u001b[A\n","Epoch 271:  90% 160/178 [00:19<00:02,  8.01it/s, loss=1.23, v_num=2, val/loss=1.390, Val/acc=0.518, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.47it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.47it/s]\u001b[A\n","Epoch 271: 100% 178/178 [00:20<00:00,  8.85it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.680]\n","Epoch 272:   0% 0/178 [00:13<?, ?it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 272:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.28it/s]\u001b[A\n","Epoch 272:  22% 40/178 [00:20<01:10,  1.97it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.86it/s]\u001b[A\n","Epoch 272:  34% 60/178 [00:20<00:40,  2.93it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.90it/s]\u001b[A\n","Epoch 272:  45% 80/178 [00:20<00:25,  3.88it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.62it/s]\u001b[A\n","Epoch 272:  56% 100/178 [00:20<00:16,  4.81it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.29it/s]\u001b[A\n","Epoch 272:  67% 120/178 [00:20<00:10,  5.73it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.05it/s]\u001b[A\n","Epoch 272:  79% 140/178 [00:21<00:05,  6.64it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.87it/s]\u001b[A\n","Epoch 272:  90% 160/178 [00:21<00:02,  7.53it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.11it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.11it/s]\u001b[A\n","Epoch 272: 100% 178/178 [00:21<00:00,  8.33it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.240, train/acc=0.666]\n","                                                               \u001b[AMetric train/loss improved by 0.000 >= min_delta = 0.0. New best score: 1.227\n","Epoch 273:   0% 0/178 [00:11<?, ?it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 273:  11% 20/178 [00:20<02:43,  1.04s/it, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 123.69it/s]\u001b[A\n","Epoch 273:  22% 40/178 [00:20<01:11,  1.92it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 134.18it/s]\u001b[A\n","Epoch 273:  34% 60/178 [00:20<00:41,  2.86it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 136.39it/s]\u001b[A\n","Epoch 273:  45% 80/178 [00:21<00:25,  3.79it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 134.38it/s]\u001b[A\n","Epoch 273:  56% 100/178 [00:21<00:16,  4.70it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 137.08it/s]\u001b[A\n","Epoch 273:  67% 120/178 [00:21<00:10,  5.60it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 136.07it/s]\u001b[A\n","Epoch 273:  79% 140/178 [00:21<00:05,  6.49it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.71it/s]\u001b[A\n","Epoch 273:  90% 160/178 [00:21<00:02,  7.37it/s, loss=1.24, v_num=2, val/loss=1.380, Val/acc=0.530, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.89it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.89it/s]\u001b[A\n","Epoch 273: 100% 178/178 [00:21<00:00,  8.15it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.679]\n","Epoch 274:   0% 0/178 [00:00<?, ?it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 274:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 109.19it/s]\u001b[A\n","Epoch 274:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.00it/s]\u001b[A\n","Epoch 274:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.43it/s]\u001b[A\n","Epoch 274:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.88it/s]\u001b[A\n","Epoch 274:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.30it/s]\u001b[A\n","Epoch 274:  67% 120/178 [00:20<00:09,  5.83it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.25it/s]\u001b[A\n","Epoch 274:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 127.96it/s]\u001b[A\n","Epoch 274:  90% 160/178 [00:20<00:02,  7.66it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.82it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.82it/s]\u001b[A\n","Epoch 274: 100% 178/178 [00:20<00:00,  8.48it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.663]\n","Epoch 275:   0% 0/178 [00:18<?, ?it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 275:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 130.26it/s]\u001b[A\n","Epoch 275:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 135.57it/s]\u001b[A\n","Epoch 275:  34% 60/178 [00:20<00:39,  2.95it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.08it/s]\u001b[A\n","Epoch 275:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.65it/s]\u001b[A\n","Epoch 275:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.20it/s]\u001b[A\n","Epoch 275:  67% 120/178 [00:20<00:10,  5.78it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.63it/s]\u001b[A\n","Epoch 275:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.46it/s]\u001b[A\n","Epoch 275:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.260, train/acc=0.647]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.90it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.90it/s]\u001b[A\n","Epoch 275: 100% 178/178 [00:21<00:00,  8.40it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.647]\n","Epoch 276:   0% 0/178 [00:17<?, ?it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 276:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 101.31it/s]\u001b[A\n","Epoch 276:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 119.81it/s]\u001b[A\n","Epoch 276:  34% 60/178 [00:19<00:38,  3.07it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.83it/s]\u001b[A\n","Epoch 276:  45% 80/178 [00:19<00:24,  4.07it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.59it/s]\u001b[A\n","Epoch 276:  56% 100/178 [00:19<00:15,  5.04it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.89it/s]\u001b[A\n","Epoch 276:  67% 120/178 [00:19<00:09,  6.01it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.61it/s]\u001b[A\n","Epoch 276:  79% 140/178 [00:20<00:05,  6.96it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.21it/s]\u001b[A\n","Epoch 276:  90% 160/178 [00:20<00:02,  7.89it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.24it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.24it/s]\u001b[A\n","Epoch 276: 100% 178/178 [00:20<00:00,  8.73it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.260, train/acc=0.643]\n","Epoch 277:   0% 0/178 [00:17<?, ?it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 277:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 104.72it/s]\u001b[A\n","Epoch 277:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.81it/s]\u001b[A\n","Epoch 277:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.95it/s]\u001b[A\n","Epoch 277:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.51it/s]\u001b[A\n","Epoch 277:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.93it/s]\u001b[A\n","Epoch 277:  67% 120/178 [00:20<00:09,  5.82it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.94it/s]\u001b[A\n","Epoch 277:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.15it/s]\u001b[A\n","Epoch 277:  90% 160/178 [00:20<00:02,  7.65it/s, loss=1.27, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.270, train/acc=0.627]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.45it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.45it/s]\u001b[A\n","Epoch 277: 100% 178/178 [00:21<00:00,  8.47it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.270, train/acc=0.627]\n","Epoch 278:   0% 0/178 [00:16<?, ?it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 278:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 101.57it/s]\u001b[A\n","Epoch 278:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.20it/s]\u001b[A\n","Epoch 278:  34% 60/178 [00:20<00:39,  2.95it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.62it/s]\u001b[A\n","Epoch 278:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.75it/s]\u001b[A\n","Epoch 278:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.06it/s]\u001b[A\n","Epoch 278:  67% 120/178 [00:20<00:10,  5.77it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.21it/s]\u001b[A\n","Epoch 278:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.15it/s]\u001b[A\n","Epoch 278:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.26, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.250, train/acc=0.657]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.03it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.03it/s]\u001b[A\n","Epoch 278: 100% 178/178 [00:21<00:00,  8.39it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.657]\n","Epoch 279:   0% 0/178 [00:14<?, ?it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 279:  11% 20/178 [00:20<02:43,  1.03s/it, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 101.46it/s]\u001b[A\n","Epoch 279:  22% 40/178 [00:20<01:11,  1.92it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 117.33it/s]\u001b[A\n","Epoch 279:  34% 60/178 [00:20<00:41,  2.86it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.64it/s]\u001b[A\n","Epoch 279:  45% 80/178 [00:21<00:25,  3.79it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.58it/s]\u001b[A\n","Epoch 279:  56% 100/178 [00:21<00:16,  4.70it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.93it/s]\u001b[A\n","Epoch 279:  67% 120/178 [00:21<00:10,  5.61it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.20it/s]\u001b[A\n","Epoch 279:  79% 140/178 [00:21<00:05,  6.49it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.60it/s]\u001b[A\n","Epoch 279:  90% 160/178 [00:21<00:02,  7.37it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.260, train/acc=0.643]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.24it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.24it/s]\u001b[A\n","Epoch 279: 100% 178/178 [00:21<00:00,  8.16it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.260, train/acc=0.643]\n","Epoch 280:   0% 0/178 [00:13<?, ?it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 280:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 118.31it/s]\u001b[A\n","Epoch 280:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.07it/s]\u001b[A\n","Epoch 280:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.25it/s]\u001b[A\n","Epoch 280:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.98it/s]\u001b[A\n","Epoch 280:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.15it/s]\u001b[A\n","Epoch 280:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.59it/s]\u001b[A\n","Epoch 280:  79% 140/178 [00:20<00:05,  6.76it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.91it/s]\u001b[A\n","Epoch 280:  90% 160/178 [00:20<00:02,  7.67it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.80it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.80it/s]\u001b[A\n","Epoch 280: 100% 178/178 [00:20<00:00,  8.48it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.240, train/acc=0.667]\n","Epoch 281:   0% 0/178 [00:12<?, ?it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 281:  11% 20/178 [00:19<02:32,  1.04it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.63it/s]\u001b[A\n","Epoch 281:  22% 40/178 [00:19<01:07,  2.06it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.55it/s]\u001b[A\n","Epoch 281:  34% 60/178 [00:19<00:38,  3.06it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.52it/s]\u001b[A\n","Epoch 281:  45% 80/178 [00:19<00:24,  4.05it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.99it/s]\u001b[A\n","Epoch 281:  56% 100/178 [00:19<00:15,  5.03it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.08it/s]\u001b[A\n","Epoch 281:  67% 120/178 [00:20<00:09,  5.99it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.33it/s]\u001b[A\n","Epoch 281:  79% 140/178 [00:20<00:05,  6.93it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.13it/s]\u001b[A\n","Epoch 281:  90% 160/178 [00:20<00:02,  7.86it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.661]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.30it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.30it/s]\u001b[A\n","Epoch 281: 100% 178/178 [00:20<00:00,  8.70it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.250, train/acc=0.661]\n","Epoch 282:   0% 0/178 [00:11<?, ?it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 282:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 104.72it/s]\u001b[A\n","Epoch 282:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.25it/s]\u001b[A\n","Epoch 282:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.36it/s]\u001b[A\n","Epoch 282:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.70it/s]\u001b[A\n","Epoch 282:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.38it/s]\u001b[A\n","Epoch 282:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.38it/s]\u001b[A\n","Epoch 282:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.42it/s]\u001b[A\n","Epoch 282:  90% 160/178 [00:20<00:02,  7.68it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.63it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.63it/s]\u001b[A\n","Epoch 282: 100% 178/178 [00:20<00:00,  8.49it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.662]\n","Epoch 283:   0% 0/178 [00:10<?, ?it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 283:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.14it/s]\u001b[A\n","Epoch 283:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.05it/s]\u001b[A\n","Epoch 283:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.88it/s]\u001b[A\n","Epoch 283:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.01it/s]\u001b[A\n","Epoch 283:  56% 100/178 [00:20<00:15,  4.91it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.29it/s]\u001b[A\n","Epoch 283:  67% 120/178 [00:20<00:09,  5.85it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.05it/s]\u001b[A\n","Epoch 283:  79% 140/178 [00:20<00:05,  6.78it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.99it/s]\u001b[A\n","Epoch 283:  90% 160/178 [00:20<00:02,  7.69it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.73it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.73it/s]\u001b[A\n","Epoch 283: 100% 178/178 [00:20<00:00,  8.51it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.240, train/acc=0.660]\n","Epoch 284:   0% 0/178 [00:00<?, ?it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 284:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 122.25it/s]\u001b[A\n","Epoch 284:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.62it/s]\u001b[A\n","Epoch 284:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.53it/s]\u001b[A\n","Epoch 284:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.47it/s]\u001b[A\n","Epoch 284:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.68it/s]\u001b[A\n","Epoch 284:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.57it/s]\u001b[A\n","Epoch 284:  79% 140/178 [00:20<00:05,  6.85it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 127.98it/s]\u001b[A\n","Epoch 284:  90% 160/178 [00:20<00:02,  7.77it/s, loss=1.25, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.250, train/acc=0.655]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.12it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.12it/s]\u001b[A\n","Epoch 284: 100% 178/178 [00:20<00:00,  8.60it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.250, train/acc=0.655]\n","Epoch 285:   0% 0/178 [00:18<?, ?it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 285:  11% 20/178 [00:20<02:45,  1.05s/it, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.04it/s]\u001b[A\n","Epoch 285:  22% 40/178 [00:21<01:12,  1.90it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.90it/s]\u001b[A\n","Epoch 285:  34% 60/178 [00:21<00:41,  2.82it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.10it/s]\u001b[A\n","Epoch 285:  45% 80/178 [00:21<00:26,  3.74it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.15it/s]\u001b[A\n","Epoch 285:  56% 100/178 [00:21<00:16,  4.64it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.90it/s]\u001b[A\n","Epoch 285:  67% 120/178 [00:21<00:10,  5.53it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.99it/s]\u001b[A\n","Epoch 285:  79% 140/178 [00:21<00:05,  6.41it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.44it/s]\u001b[A\n","Epoch 285:  90% 160/178 [00:22<00:02,  7.27it/s, loss=1.26, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.95it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.95it/s]\u001b[A\n","Epoch 285: 100% 178/178 [00:22<00:00,  8.05it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.270, train/acc=0.634]\n","Epoch 286:   0% 0/178 [00:16<?, ?it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 286:  11% 20/178 [00:20<02:43,  1.03s/it, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 124.14it/s]\u001b[A\n","Epoch 286:  22% 40/178 [00:20<01:11,  1.92it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.46it/s]\u001b[A\n","Epoch 286:  34% 60/178 [00:20<00:41,  2.86it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.45it/s]\u001b[A\n","Epoch 286:  45% 80/178 [00:21<00:25,  3.79it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.37it/s]\u001b[A\n","Epoch 286:  56% 100/178 [00:21<00:16,  4.70it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.15it/s]\u001b[A\n","Epoch 286:  67% 120/178 [00:21<00:10,  5.60it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 126.15it/s]\u001b[A\n","Epoch 286:  79% 140/178 [00:21<00:05,  6.49it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 125.94it/s]\u001b[A\n","Epoch 286:  90% 160/178 [00:21<00:02,  7.36it/s, loss=1.26, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.29it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.29it/s]\u001b[A\n","Epoch 286: 100% 178/178 [00:21<00:00,  8.14it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.250, train/acc=0.651]\n","Epoch 287:   0% 0/178 [00:14<?, ?it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 287:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 136.51it/s]\u001b[A\n","Epoch 287:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 136.48it/s]\u001b[A\n","Epoch 287:  34% 60/178 [00:20<00:39,  2.96it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.27it/s]\u001b[A\n","Epoch 287:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.25it/s]\u001b[A\n","Epoch 287:  56% 100/178 [00:20<00:16,  4.86it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.90it/s]\u001b[A\n","Epoch 287:  67% 120/178 [00:20<00:10,  5.79it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.10it/s]\u001b[A\n","Epoch 287:  79% 140/178 [00:20<00:05,  6.70it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.28it/s]\u001b[A\n","Epoch 287:  90% 160/178 [00:21<00:02,  7.60it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.20it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.20it/s]\u001b[A\n","Epoch 287: 100% 178/178 [00:21<00:00,  8.41it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.668]\n","Epoch 288:   0% 0/178 [00:13<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 288:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 125.69it/s]\u001b[A\n","Epoch 288:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.47it/s]\u001b[A\n","Epoch 288:  34% 60/178 [00:20<00:39,  2.95it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.71it/s]\u001b[A\n","Epoch 288:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.40it/s]\u001b[A\n","Epoch 288:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.23it/s]\u001b[A\n","Epoch 288:  67% 120/178 [00:20<00:10,  5.78it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.76it/s]\u001b[A\n","Epoch 288:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.52it/s]\u001b[A\n","Epoch 288:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.61it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.61it/s]\u001b[A\n","Epoch 288: 100% 178/178 [00:21<00:00,  8.40it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.680]\n","Epoch 289:   0% 0/178 [00:12<?, ?it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 289:  11% 20/178 [00:19<02:32,  1.04it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.32it/s]\u001b[A\n","Epoch 289:  22% 40/178 [00:19<01:07,  2.06it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.62it/s]\u001b[A\n","Epoch 289:  34% 60/178 [00:19<00:38,  3.07it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.43it/s]\u001b[A\n","Epoch 289:  45% 80/178 [00:19<00:24,  4.06it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.34it/s]\u001b[A\n","Epoch 289:  56% 100/178 [00:19<00:15,  5.03it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.52it/s]\u001b[A\n","Epoch 289:  67% 120/178 [00:20<00:09,  5.99it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.85it/s]\u001b[A\n","Epoch 289:  79% 140/178 [00:20<00:05,  6.94it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.97it/s]\u001b[A\n","Epoch 289:  90% 160/178 [00:20<00:02,  7.87it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.41it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.41it/s]\u001b[A\n","Epoch 289: 100% 178/178 [00:20<00:00,  8.70it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.665]\n","                                                               \u001b[AMetric train/loss improved by 0.002 >= min_delta = 0.0. New best score: 1.225\n","Epoch 290:   0% 0/178 [00:11<?, ?it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 290:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 101.97it/s]\u001b[A\n","Epoch 290:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.74it/s]\u001b[A\n","Epoch 290:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.54it/s]\u001b[A\n","Epoch 290:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.37it/s]\u001b[A\n","Epoch 290:  56% 100/178 [00:19<00:15,  5.01it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.32it/s]\u001b[A\n","Epoch 290:  67% 120/178 [00:20<00:09,  5.96it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.20it/s]\u001b[A\n","Epoch 290:  79% 140/178 [00:20<00:05,  6.91it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.43it/s]\u001b[A\n","Epoch 290:  90% 160/178 [00:20<00:02,  7.84it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.68it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.68it/s]\u001b[A\n","Epoch 290: 100% 178/178 [00:20<00:00,  8.66it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.681]\n","Epoch 291:   0% 0/178 [00:11<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 291:  11% 20/178 [00:20<02:40,  1.01s/it, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 110.26it/s]\u001b[A\n","Epoch 291:  22% 40/178 [00:20<01:10,  1.96it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.15it/s]\u001b[A\n","Epoch 291:  34% 60/178 [00:20<00:40,  2.92it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.76it/s]\u001b[A\n","Epoch 291:  45% 80/178 [00:20<00:25,  3.86it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.57it/s]\u001b[A\n","Epoch 291:  56% 100/178 [00:20<00:16,  4.79it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.79it/s]\u001b[A\n","Epoch 291:  67% 120/178 [00:21<00:10,  5.71it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.44it/s]\u001b[A\n","Epoch 291:  79% 140/178 [00:21<00:05,  6.62it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.17it/s]\u001b[A\n","Epoch 291:  90% 160/178 [00:21<00:02,  7.51it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.46it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.46it/s]\u001b[A\n","Epoch 291: 100% 178/178 [00:21<00:00,  8.31it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.230, train/acc=0.670]\n","Epoch 292:   0% 0/178 [00:19<?, ?it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 292:  11% 20/178 [00:20<02:43,  1.03s/it, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 92.79it/s]\u001b[A\n","Epoch 292:  22% 40/178 [00:20<01:11,  1.92it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 115.92it/s]\u001b[A\n","Epoch 292:  34% 60/178 [00:20<00:41,  2.87it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 123.54it/s]\u001b[A\n","Epoch 292:  45% 80/178 [00:21<00:25,  3.79it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.70it/s]\u001b[A\n","Epoch 292:  56% 100/178 [00:21<00:16,  4.71it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.01it/s]\u001b[A\n","Epoch 292:  67% 120/178 [00:21<00:10,  5.61it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.72it/s]\u001b[A\n","Epoch 292:  79% 140/178 [00:21<00:05,  6.50it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 126.55it/s]\u001b[A\n","Epoch 292:  90% 160/178 [00:21<00:02,  7.37it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.18it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.18it/s]\u001b[A\n","Epoch 292: 100% 178/178 [00:21<00:00,  8.16it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.240, train/acc=0.665]\n","Epoch 293:   0% 0/178 [00:18<?, ?it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 293:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 92.32it/s]\u001b[A\n","Epoch 293:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 116.33it/s]\u001b[A\n","Epoch 293:  34% 60/178 [00:20<00:40,  2.95it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 123.83it/s]\u001b[A\n","Epoch 293:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.91it/s]\u001b[A\n","Epoch 293:  56% 100/178 [00:20<00:16,  4.84it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.57it/s]\u001b[A\n","Epoch 293:  67% 120/178 [00:20<00:10,  5.76it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.36it/s]\u001b[A\n","Epoch 293:  79% 140/178 [00:20<00:05,  6.68it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.76it/s]\u001b[A\n","Epoch 293:  90% 160/178 [00:21<00:02,  7.57it/s, loss=1.25, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.21it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.21it/s]\u001b[A\n","Epoch 293: 100% 178/178 [00:21<00:00,  8.38it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.250, train/acc=0.651]\n","Epoch 294:   0% 0/178 [00:16<?, ?it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 294:  11% 20/178 [00:19<02:34,  1.03it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.86it/s]\u001b[A\n","Epoch 294:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.35it/s]\u001b[A\n","Epoch 294:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.92it/s]\u001b[A\n","Epoch 294:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.84it/s]\u001b[A\n","Epoch 294:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.17it/s]\u001b[A\n","Epoch 294:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.18it/s]\u001b[A\n","Epoch 294:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.72it/s]\u001b[A\n","Epoch 294:  90% 160/178 [00:20<00:02,  7.79it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.22it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.22it/s]\u001b[A\n","Epoch 294: 100% 178/178 [00:20<00:00,  8.62it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Epoch 295:   0% 0/178 [00:16<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 295:  11% 20/178 [00:19<02:32,  1.03it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.09it/s]\u001b[A\n","Epoch 295:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.05it/s]\u001b[A\n","Epoch 295:  34% 60/178 [00:19<00:38,  3.06it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.92it/s]\u001b[A\n","Epoch 295:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.10it/s]\u001b[A\n","Epoch 295:  56% 100/178 [00:19<00:15,  5.02it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.45it/s]\u001b[A\n","Epoch 295:  67% 120/178 [00:20<00:09,  5.98it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.34it/s]\u001b[A\n","Epoch 295:  79% 140/178 [00:20<00:05,  6.92it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.37it/s]\u001b[A\n","Epoch 295:  90% 160/178 [00:20<00:02,  7.85it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.41it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.41it/s]\u001b[A\n","Epoch 295: 100% 178/178 [00:20<00:00,  8.68it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.671]\n","Epoch 296:   0% 0/178 [00:15<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 296:  11% 20/178 [00:20<02:38,  1.01s/it, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.90it/s]\u001b[A\n","Epoch 296:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.08it/s]\u001b[A\n","Epoch 296:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.58it/s]\u001b[A\n","Epoch 296:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.51it/s]\u001b[A\n","Epoch 296:  56% 100/178 [00:20<00:16,  4.84it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.06it/s]\u001b[A\n","Epoch 296:  67% 120/178 [00:20<00:10,  5.76it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 136.29it/s]\u001b[A\n","Epoch 296:  79% 140/178 [00:20<00:05,  6.68it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.48it/s]\u001b[A\n","Epoch 296:  90% 160/178 [00:21<00:02,  7.57it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.37it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.37it/s]\u001b[A\n","Epoch 296: 100% 178/178 [00:21<00:00,  8.37it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.669]\n","Epoch 297:   0% 0/178 [00:14<?, ?it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 297:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.35it/s]\u001b[A\n","Epoch 297:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.10it/s]\u001b[A\n","Epoch 297:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.37it/s]\u001b[A\n","Epoch 297:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 134.80it/s]\u001b[A\n","Epoch 297:  56% 100/178 [00:20<00:15,  4.99it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.80it/s]\u001b[A\n","Epoch 297:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.49it/s]\u001b[A\n","Epoch 297:  79% 140/178 [00:20<00:05,  6.88it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.77it/s]\u001b[A\n","Epoch 297:  90% 160/178 [00:20<00:02,  7.81it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.63it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.63it/s]\u001b[A\n","Epoch 297: 100% 178/178 [00:20<00:00,  8.64it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.230, train/acc=0.675]\n","Epoch 298:   0% 0/178 [00:13<?, ?it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 298:  11% 20/178 [00:18<02:28,  1.07it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 113.50it/s]\u001b[A\n","Epoch 298:  22% 40/178 [00:18<01:05,  2.12it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.91it/s]\u001b[A\n","Epoch 298:  34% 60/178 [00:19<00:37,  3.15it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.89it/s]\u001b[A\n","Epoch 298:  45% 80/178 [00:19<00:23,  4.17it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.77it/s]\u001b[A\n","Epoch 298:  56% 100/178 [00:19<00:15,  5.17it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.16it/s]\u001b[A\n","Epoch 298:  67% 120/178 [00:19<00:09,  6.16it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.04it/s]\u001b[A\n","Epoch 298:  79% 140/178 [00:19<00:05,  7.13it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.88it/s]\u001b[A\n","Epoch 298:  90% 160/178 [00:19<00:02,  8.09it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.74it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.74it/s]\u001b[A\n","Epoch 298: 100% 178/178 [00:19<00:00,  8.95it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.663]\n","Epoch 299:   0% 0/178 [00:13<?, ?it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 299:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.62it/s]\u001b[A\n","Epoch 299:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.71it/s]\u001b[A\n","Epoch 299:  34% 60/178 [00:20<00:39,  2.95it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.52it/s]\u001b[A\n","Epoch 299:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.08it/s]\u001b[A\n","Epoch 299:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.72it/s]\u001b[A\n","Epoch 299:  67% 120/178 [00:20<00:10,  5.78it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.80it/s]\u001b[A\n","Epoch 299:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.40it/s]\u001b[A\n","Epoch 299:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.62it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.62it/s]\u001b[A\n","Epoch 299: 100% 178/178 [00:21<00:00,  8.40it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.660]\n","Epoch 300:   0% 0/178 [00:12<?, ?it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 300:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:00, 146.79it/s]\u001b[A\n","Epoch 300:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 142.27it/s]\u001b[A\n","Epoch 300:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 136.59it/s]\u001b[A\n","Epoch 300:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 134.97it/s]\u001b[A\n","Epoch 300:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 137.15it/s]\u001b[A\n","Epoch 300:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.55it/s]\u001b[A\n","Epoch 300:  79% 140/178 [00:20<00:05,  6.82it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 136.38it/s]\u001b[A\n","Epoch 300:  90% 160/178 [00:20<00:02,  7.74it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.260, train/acc=0.649]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.47it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.47it/s]\u001b[A\n","Epoch 300: 100% 178/178 [00:20<00:00,  8.56it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.260, train/acc=0.649]\n","Epoch 301:   0% 0/178 [00:11<?, ?it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 301:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 116.57it/s]\u001b[A\n","Epoch 301:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.35it/s]\u001b[A\n","Epoch 301:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.78it/s]\u001b[A\n","Epoch 301:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.96it/s]\u001b[A\n","Epoch 301:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.17it/s]\u001b[A\n","Epoch 301:  67% 120/178 [00:20<00:09,  5.80it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.78it/s]\u001b[A\n","Epoch 301:  79% 140/178 [00:20<00:05,  6.72it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.84it/s]\u001b[A\n","Epoch 301:  90% 160/178 [00:20<00:02,  7.62it/s, loss=1.26, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.07it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.07it/s]\u001b[A\n","Epoch 301: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.656]\n","Epoch 302:   0% 0/178 [00:10<?, ?it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 302:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 109.15it/s]\u001b[A\n","Epoch 302:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.29it/s]\u001b[A\n","Epoch 302:  34% 60/178 [00:20<00:40,  2.90it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.84it/s]\u001b[A\n","Epoch 302:  45% 80/178 [00:20<00:25,  3.84it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.78it/s]\u001b[A\n","Epoch 302:  56% 100/178 [00:20<00:16,  4.77it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.34it/s]\u001b[A\n","Epoch 302:  67% 120/178 [00:21<00:10,  5.68it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.70it/s]\u001b[A\n","Epoch 302:  79% 140/178 [00:21<00:05,  6.58it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.39it/s]\u001b[A\n","Epoch 302:  90% 160/178 [00:21<00:02,  7.47it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.29it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.29it/s]\u001b[A\n","Epoch 302: 100% 178/178 [00:21<00:00,  8.26it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Epoch 303:   0% 0/178 [00:00<?, ?it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 303:  11% 20/178 [00:18<02:29,  1.05it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.55it/s]\u001b[A\n","Epoch 303:  22% 40/178 [00:19<01:05,  2.09it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.18it/s]\u001b[A\n","Epoch 303:  34% 60/178 [00:19<00:37,  3.12it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.63it/s]\u001b[A\n","Epoch 303:  45% 80/178 [00:19<00:23,  4.12it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.29it/s]\u001b[A\n","Epoch 303:  56% 100/178 [00:19<00:15,  5.12it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.91it/s]\u001b[A\n","Epoch 303:  67% 120/178 [00:19<00:09,  6.09it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.62it/s]\u001b[A\n","Epoch 303:  79% 140/178 [00:19<00:05,  7.05it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.48it/s]\u001b[A\n","Epoch 303:  90% 160/178 [00:19<00:02,  8.00it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.652]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.33it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.33it/s]\u001b[A\n","Epoch 303: 100% 178/178 [00:20<00:00,  8.85it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.250, train/acc=0.652]\n","Epoch 304:   0% 0/178 [00:18<?, ?it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 304:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.87it/s]\u001b[A\n","Epoch 304:  22% 40/178 [00:20<01:10,  1.97it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.30it/s]\u001b[A\n","Epoch 304:  34% 60/178 [00:20<00:40,  2.93it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.43it/s]\u001b[A\n","Epoch 304:  45% 80/178 [00:20<00:25,  3.88it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.58it/s]\u001b[A\n","Epoch 304:  56% 100/178 [00:20<00:16,  4.82it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.49it/s]\u001b[A\n","Epoch 304:  67% 120/178 [00:20<00:10,  5.74it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.02it/s]\u001b[A\n","Epoch 304:  79% 140/178 [00:21<00:05,  6.65it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.28it/s]\u001b[A\n","Epoch 304:  90% 160/178 [00:21<00:02,  7.55it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.434, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.99it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.99it/s]\u001b[A\n","Epoch 304: 100% 178/178 [00:21<00:00,  8.35it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.230, train/acc=0.669]\n","Epoch 305:   0% 0/178 [00:17<?, ?it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 305:  11% 20/178 [00:20<02:45,  1.04s/it, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.71it/s]\u001b[A\n","Epoch 305:  22% 40/178 [00:21<01:12,  1.90it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.26it/s]\u001b[A\n","Epoch 305:  34% 60/178 [00:21<00:41,  2.84it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.27it/s]\u001b[A\n","Epoch 305:  45% 80/178 [00:21<00:26,  3.75it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.11it/s]\u001b[A\n","Epoch 305:  56% 100/178 [00:21<00:16,  4.66it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.10it/s]\u001b[A\n","Epoch 305:  67% 120/178 [00:21<00:10,  5.55it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.90it/s]\u001b[A\n","Epoch 305:  79% 140/178 [00:21<00:05,  6.44it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.48it/s]\u001b[A\n","Epoch 305:  90% 160/178 [00:21<00:02,  7.31it/s, loss=1.24, v_num=2, val/loss=1.370, Val/acc=0.530, train/loss=1.240, train/acc=0.661]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.80it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.80it/s]\u001b[A\n","Epoch 305: 100% 178/178 [00:22<00:00,  8.09it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.240, train/acc=0.661]\n","Epoch 306:   0% 0/178 [00:15<?, ?it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 306:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 116.55it/s]\u001b[A\n","Epoch 306:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.30it/s]\u001b[A\n","Epoch 306:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.65it/s]\u001b[A\n","Epoch 306:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.52it/s]\u001b[A\n","Epoch 306:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.38it/s]\u001b[A\n","Epoch 306:  67% 120/178 [00:20<00:09,  5.94it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.48it/s]\u001b[A\n","Epoch 306:  79% 140/178 [00:20<00:05,  6.88it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.35it/s]\u001b[A\n","Epoch 306:  90% 160/178 [00:20<00:02,  7.80it/s, loss=1.25, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.250, train/acc=0.647]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.18it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.18it/s]\u001b[A\n","Epoch 306: 100% 178/178 [00:20<00:00,  8.63it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.250, train/acc=0.647]\n","Epoch 307:   0% 0/178 [00:14<?, ?it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 307:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.89it/s]\u001b[A\n","Epoch 307:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.55it/s]\u001b[A\n","Epoch 307:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.28it/s]\u001b[A\n","Epoch 307:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.48it/s]\u001b[A\n","Epoch 307:  56% 100/178 [00:20<00:15,  4.92it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.57it/s]\u001b[A\n","Epoch 307:  67% 120/178 [00:20<00:09,  5.87it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.78it/s]\u001b[A\n","Epoch 307:  79% 140/178 [00:20<00:05,  6.79it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 127.84it/s]\u001b[A\n","Epoch 307:  90% 160/178 [00:20<00:02,  7.70it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.71it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.71it/s]\u001b[A\n","Epoch 307: 100% 178/178 [00:20<00:00,  8.52it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.240, train/acc=0.665]\n","Epoch 308:   0% 0/178 [00:13<?, ?it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 308:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 122.74it/s]\u001b[A\n","Epoch 308:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.05it/s]\u001b[A\n","Epoch 308:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.70it/s]\u001b[A\n","Epoch 308:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.43it/s]\u001b[A\n","Epoch 308:  56% 100/178 [00:20<00:15,  5.00it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.91it/s]\u001b[A\n","Epoch 308:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.03it/s]\u001b[A\n","Epoch 308:  79% 140/178 [00:20<00:05,  6.89it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.98it/s]\u001b[A\n","Epoch 308:  90% 160/178 [00:20<00:02,  7.82it/s, loss=1.24, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.65it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.65it/s]\u001b[A\n","Epoch 308: 100% 178/178 [00:20<00:00,  8.65it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Epoch 309:   0% 0/178 [00:13<?, ?it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 309:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 119.42it/s]\u001b[A\n","Epoch 309:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.33it/s]\u001b[A\n","Epoch 309:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.99it/s]\u001b[A\n","Epoch 309:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.78it/s]\u001b[A\n","Epoch 309:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.21it/s]\u001b[A\n","Epoch 309:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.04it/s]\u001b[A\n","Epoch 309:  79% 140/178 [00:20<00:05,  6.85it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.31it/s]\u001b[A\n","Epoch 309:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.250, train/acc=0.659]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.07it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.07it/s]\u001b[A\n","Epoch 309: 100% 178/178 [00:20<00:00,  8.61it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.250, train/acc=0.659]\n","Epoch 310:   0% 0/178 [00:12<?, ?it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 310:  11% 20/178 [00:19<02:34,  1.03it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 129.79it/s]\u001b[A\n","Epoch 310:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.18it/s]\u001b[A\n","Epoch 310:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.57it/s]\u001b[A\n","Epoch 310:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.34it/s]\u001b[A\n","Epoch 310:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.27it/s]\u001b[A\n","Epoch 310:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.92it/s]\u001b[A\n","Epoch 310:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.57it/s]\u001b[A\n","Epoch 310:  90% 160/178 [00:20<00:02,  7.79it/s, loss=1.25, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.79it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.79it/s]\u001b[A\n","Epoch 310: 100% 178/178 [00:20<00:00,  8.62it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Epoch 311:   0% 0/178 [00:11<?, ?it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 311:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.69it/s]\u001b[A\n","Epoch 311:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.12it/s]\u001b[A\n","Epoch 311:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.07it/s]\u001b[A\n","Epoch 311:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.25it/s]\u001b[A\n","Epoch 311:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.68it/s]\u001b[A\n","Epoch 311:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.22it/s]\u001b[A\n","Epoch 311:  79% 140/178 [00:20<00:05,  6.81it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.38it/s]\u001b[A\n","Epoch 311:  90% 160/178 [00:20<00:02,  7.72it/s, loss=1.24, v_num=2, val/loss=1.500, Val/acc=0.410, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.53it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.53it/s]\u001b[A\n","Epoch 311: 100% 178/178 [00:20<00:00,  8.54it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.668]\n","Epoch 312:   0% 0/178 [00:10<?, ?it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 312:  11% 20/178 [00:21<02:46,  1.05s/it, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.48it/s]\u001b[A\n","Epoch 312:  22% 40/178 [00:21<01:13,  1.89it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.28it/s]\u001b[A\n","Epoch 312:  34% 60/178 [00:21<00:41,  2.81it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.41it/s]\u001b[A\n","Epoch 312:  45% 80/178 [00:21<00:26,  3.73it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.78it/s]\u001b[A\n","Epoch 312:  56% 100/178 [00:21<00:16,  4.63it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.31it/s]\u001b[A\n","Epoch 312:  67% 120/178 [00:21<00:10,  5.52it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.72it/s]\u001b[A\n","Epoch 312:  79% 140/178 [00:21<00:05,  6.39it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.12it/s]\u001b[A\n","Epoch 312:  90% 160/178 [00:22<00:02,  7.25it/s, loss=1.23, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.55it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.55it/s]\u001b[A\n","Epoch 312: 100% 178/178 [00:22<00:00,  8.02it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.240, train/acc=0.667]\n","Epoch 313:   0% 0/178 [00:18<?, ?it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 313:  11% 20/178 [00:20<02:38,  1.01s/it, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 90.39it/s]\u001b[A\n","Epoch 313:  22% 40/178 [00:20<01:10,  1.96it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 79.04it/s]\u001b[A\n","Epoch 313:  34% 60/178 [00:20<00:40,  2.92it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:01, 96.79it/s]\u001b[A\n","Epoch 313:  45% 80/178 [00:20<00:25,  3.86it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 108.29it/s]\u001b[A\n","Epoch 313:  56% 100/178 [00:20<00:16,  4.79it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 113.81it/s]\u001b[A\n","Epoch 313:  67% 120/178 [00:21<00:10,  5.70it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  72% 120/166 [00:01<00:00, 117.79it/s]\u001b[A\n","Epoch 313:  79% 140/178 [00:21<00:05,  6.61it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 124.39it/s]\u001b[A\n","Epoch 313:  90% 160/178 [00:21<00:02,  7.50it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 131.06it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 131.06it/s]\u001b[A\n","Epoch 313: 100% 178/178 [00:21<00:00,  8.30it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.250, train/acc=0.656]\n","Epoch 314:   0% 0/178 [00:17<?, ?it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 314:  11% 20/178 [00:19<02:32,  1.03it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 125.88it/s]\u001b[A\n","Epoch 314:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.42it/s]\u001b[A\n","Epoch 314:  34% 60/178 [00:19<00:38,  3.06it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.52it/s]\u001b[A\n","Epoch 314:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.24it/s]\u001b[A\n","Epoch 314:  56% 100/178 [00:19<00:15,  5.02it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.49it/s]\u001b[A\n","Epoch 314:  67% 120/178 [00:20<00:09,  5.97it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.21it/s]\u001b[A\n","Epoch 314:  79% 140/178 [00:20<00:05,  6.92it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.84it/s]\u001b[A\n","Epoch 314:  90% 160/178 [00:20<00:02,  7.85it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.62it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.62it/s]\u001b[A\n","Epoch 314: 100% 178/178 [00:20<00:00,  8.68it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.665]\n","Epoch 315:   0% 0/178 [00:16<?, ?it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 315:  11% 20/178 [00:19<02:32,  1.04it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.77it/s]\u001b[A\n","Epoch 315:  22% 40/178 [00:19<01:07,  2.06it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 119.63it/s]\u001b[A\n","Epoch 315:  34% 60/178 [00:19<00:38,  3.06it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 122.24it/s]\u001b[A\n","Epoch 315:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 123.77it/s]\u001b[A\n","Epoch 315:  56% 100/178 [00:19<00:15,  5.01it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 123.50it/s]\u001b[A\n","Epoch 315:  67% 120/178 [00:20<00:09,  5.97it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 126.97it/s]\u001b[A\n","Epoch 315:  79% 140/178 [00:20<00:05,  6.91it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 127.54it/s]\u001b[A\n","Epoch 315:  90% 160/178 [00:20<00:02,  7.84it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.440, train/loss=1.240, train/acc=0.669]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.12it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.12it/s]\u001b[A\n","Epoch 315: 100% 178/178 [00:20<00:00,  8.68it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.240, train/acc=0.669]\n","Epoch 316:   0% 0/178 [00:16<?, ?it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 316:  11% 20/178 [00:20<02:43,  1.03s/it, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.98it/s]\u001b[A\n","Epoch 316:  22% 40/178 [00:20<01:11,  1.93it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.78it/s]\u001b[A\n","Epoch 316:  34% 60/178 [00:20<00:41,  2.87it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.54it/s]\u001b[A\n","Epoch 316:  45% 80/178 [00:21<00:25,  3.79it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.34it/s]\u001b[A\n","Epoch 316:  56% 100/178 [00:21<00:16,  4.71it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.10it/s]\u001b[A\n","Epoch 316:  67% 120/178 [00:21<00:10,  5.61it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.68it/s]\u001b[A\n","Epoch 316:  79% 140/178 [00:21<00:05,  6.50it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.09it/s]\u001b[A\n","Epoch 316:  90% 160/178 [00:21<00:02,  7.38it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.250, train/acc=0.648]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.70it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.70it/s]\u001b[A\n","Epoch 316: 100% 178/178 [00:21<00:00,  8.16it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.250, train/acc=0.648]\n","Epoch 317:   0% 0/178 [00:14<?, ?it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 317:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.49it/s]\u001b[A\n","Epoch 317:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.94it/s]\u001b[A\n","Epoch 317:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 123.40it/s]\u001b[A\n","Epoch 317:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.23it/s]\u001b[A\n","Epoch 317:  56% 100/178 [00:20<00:15,  4.93it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.10it/s]\u001b[A\n","Epoch 317:  67% 120/178 [00:20<00:09,  5.87it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.86it/s]\u001b[A\n","Epoch 317:  79% 140/178 [00:20<00:05,  6.80it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.72it/s]\u001b[A\n","Epoch 317:  90% 160/178 [00:20<00:02,  7.72it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.464, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.47it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.47it/s]\u001b[A\n","Epoch 317: 100% 178/178 [00:20<00:00,  8.54it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.678]\n","Epoch 318:   0% 0/178 [00:13<?, ?it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 318:  11% 20/178 [00:21<02:50,  1.08s/it, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.66it/s]\u001b[A\n","Epoch 318:  22% 40/178 [00:21<01:14,  1.84it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.93it/s]\u001b[A\n","Epoch 318:  34% 60/178 [00:21<00:42,  2.75it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.60it/s]\u001b[A\n","Epoch 318:  45% 80/178 [00:22<00:26,  3.63it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.48it/s]\u001b[A\n","Epoch 318:  56% 100/178 [00:22<00:17,  4.51it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.34it/s]\u001b[A\n","Epoch 318:  67% 120/178 [00:22<00:10,  5.38it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.96it/s]\u001b[A\n","Epoch 318:  79% 140/178 [00:22<00:06,  6.23it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.76it/s]\u001b[A\n","Epoch 318:  90% 160/178 [00:22<00:02,  7.07it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.73it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.73it/s]\u001b[A\n","Epoch 318: 100% 178/178 [00:22<00:00,  7.83it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.240, train/acc=0.664]\n","Epoch 319:   0% 0/178 [00:10<?, ?it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 319:  11% 20/178 [00:20<02:44,  1.04s/it, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 103.91it/s]\u001b[A\n","Epoch 319:  22% 40/178 [00:20<01:12,  1.91it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.65it/s]\u001b[A\n","Epoch 319:  34% 60/178 [00:21<00:41,  2.84it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.80it/s]\u001b[A\n","Epoch 319:  45% 80/178 [00:21<00:26,  3.76it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.82it/s]\u001b[A\n","Epoch 319:  56% 100/178 [00:21<00:16,  4.67it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 127.75it/s]\u001b[A\n","Epoch 319:  67% 120/178 [00:21<00:10,  5.57it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.67it/s]\u001b[A\n","Epoch 319:  79% 140/178 [00:21<00:05,  6.45it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.04it/s]\u001b[A\n","Epoch 319:  90% 160/178 [00:21<00:02,  7.32it/s, loss=1.24, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.49it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.49it/s]\u001b[A\n","Epoch 319: 100% 178/178 [00:21<00:00,  8.10it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Epoch 320:   0% 0/178 [00:18<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 320:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.39it/s]\u001b[A\n","Epoch 320:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.94it/s]\u001b[A\n","Epoch 320:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.43it/s]\u001b[A\n","Epoch 320:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.87it/s]\u001b[A\n","Epoch 320:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.50it/s]\u001b[A\n","Epoch 320:  67% 120/178 [00:20<00:09,  5.81it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.62it/s]\u001b[A\n","Epoch 320:  79% 140/178 [00:20<00:05,  6.72it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.33it/s]\u001b[A\n","Epoch 320:  90% 160/178 [00:20<00:02,  7.63it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.18it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.18it/s]\u001b[A\n","Epoch 320: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.676]\n","Epoch 321:   0% 0/178 [00:17<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 321:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 118.13it/s]\u001b[A\n","Epoch 321:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.20it/s]\u001b[A\n","Epoch 321:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.50it/s]\u001b[A\n","Epoch 321:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.69it/s]\u001b[A\n","Epoch 321:  56% 100/178 [00:19<00:15,  5.00it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.33it/s]\u001b[A\n","Epoch 321:  67% 120/178 [00:20<00:09,  5.96it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.98it/s]\u001b[A\n","Epoch 321:  79% 140/178 [00:20<00:05,  6.90it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.68it/s]\u001b[A\n","Epoch 321:  90% 160/178 [00:20<00:02,  7.83it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.13it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.13it/s]\u001b[A\n","Epoch 321: 100% 178/178 [00:20<00:00,  8.66it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.669]\n","Epoch 322:   0% 0/178 [00:17<?, ?it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 322:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.13it/s]\u001b[A\n","Epoch 322:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.51it/s]\u001b[A\n","Epoch 322:  34% 60/178 [00:20<00:40,  2.95it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.69it/s]\u001b[A\n","Epoch 322:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.65it/s]\u001b[A\n","Epoch 322:  56% 100/178 [00:20<00:16,  4.84it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.16it/s]\u001b[A\n","Epoch 322:  67% 120/178 [00:20<00:10,  5.77it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.11it/s]\u001b[A\n","Epoch 322:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.25it/s]\u001b[A\n","Epoch 322:  90% 160/178 [00:21<00:02,  7.58it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.39it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.39it/s]\u001b[A\n","Epoch 322: 100% 178/178 [00:21<00:00,  8.39it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.675]\n","Epoch 323:   0% 0/178 [00:15<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 323:  11% 20/178 [00:20<02:38,  1.01s/it, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.33it/s]\u001b[A\n","Epoch 323:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.52it/s]\u001b[A\n","Epoch 323:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.90it/s]\u001b[A\n","Epoch 323:  45% 80/178 [00:20<00:25,  3.89it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.63it/s]\u001b[A\n","Epoch 323:  56% 100/178 [00:20<00:16,  4.83it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.35it/s]\u001b[A\n","Epoch 323:  67% 120/178 [00:20<00:10,  5.75it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.06it/s]\u001b[A\n","Epoch 323:  79% 140/178 [00:21<00:05,  6.67it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.39it/s]\u001b[A\n","Epoch 323:  90% 160/178 [00:21<00:02,  7.57it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.77it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.77it/s]\u001b[A\n","Epoch 323: 100% 178/178 [00:21<00:00,  8.37it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.678]\n","Epoch 324:   0% 0/178 [00:14<?, ?it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 324:  11% 20/178 [00:20<02:40,  1.02s/it, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 99.01it/s]\u001b[A\n","Epoch 324:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 119.33it/s]\u001b[A\n","Epoch 324:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.67it/s]\u001b[A\n","Epoch 324:  45% 80/178 [00:20<00:25,  3.85it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.85it/s]\u001b[A\n","Epoch 324:  56% 100/178 [00:20<00:16,  4.78it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.60it/s]\u001b[A\n","Epoch 324:  67% 120/178 [00:21<00:10,  5.69it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.98it/s]\u001b[A\n","Epoch 324:  79% 140/178 [00:21<00:05,  6.59it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.45it/s]\u001b[A\n","Epoch 324:  90% 160/178 [00:21<00:02,  7.48it/s, loss=1.24, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.29it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.29it/s]\u001b[A\n","Epoch 324: 100% 178/178 [00:21<00:00,  8.28it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.230, train/acc=0.677]\n","Epoch 325:   0% 0/178 [00:12<?, ?it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 325:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 113.19it/s]\u001b[A\n","Epoch 325:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.81it/s]\u001b[A\n","Epoch 325:  34% 60/178 [00:20<00:40,  2.90it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.64it/s]\u001b[A\n","Epoch 325:  45% 80/178 [00:20<00:25,  3.84it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 124.76it/s]\u001b[A\n","Epoch 325:  56% 100/178 [00:21<00:16,  4.76it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.41it/s]\u001b[A\n","Epoch 325:  67% 120/178 [00:21<00:10,  5.67it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 127.51it/s]\u001b[A\n","Epoch 325:  79% 140/178 [00:21<00:05,  6.57it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.71it/s]\u001b[A\n","Epoch 325:  90% 160/178 [00:21<00:02,  7.46it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.88it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.88it/s]\u001b[A\n","Epoch 325: 100% 178/178 [00:21<00:00,  8.25it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Epoch 326:   0% 0/178 [00:11<?, ?it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 326:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.37it/s]\u001b[A\n","Epoch 326:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.48it/s]\u001b[A\n","Epoch 326:  34% 60/178 [00:20<00:39,  3.00it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.70it/s]\u001b[A\n","Epoch 326:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.45it/s]\u001b[A\n","Epoch 326:  56% 100/178 [00:20<00:15,  4.92it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 126.80it/s]\u001b[A\n","Epoch 326:  67% 120/178 [00:20<00:09,  5.85it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.68it/s]\u001b[A\n","Epoch 326:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 126.40it/s]\u001b[A\n","Epoch 326:  90% 160/178 [00:20<00:02,  7.69it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.240, train/acc=0.659]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.09it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.09it/s]\u001b[A\n","Epoch 326: 100% 178/178 [00:20<00:00,  8.50it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.240, train/acc=0.659]\n","Epoch 327:   0% 0/178 [00:10<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 327:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.53it/s]\u001b[A\n","Epoch 327:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.55it/s]\u001b[A\n","Epoch 327:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.24it/s]\u001b[A\n","Epoch 327:  45% 80/178 [00:19<00:24,  4.00it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.77it/s]\u001b[A\n","Epoch 327:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.25it/s]\u001b[A\n","Epoch 327:  67% 120/178 [00:20<00:09,  5.91it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.13it/s]\u001b[A\n","Epoch 327:  79% 140/178 [00:20<00:05,  6.85it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.66it/s]\u001b[A\n","Epoch 327:  90% 160/178 [00:20<00:02,  7.77it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.49it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.49it/s]\u001b[A\n","Epoch 327: 100% 178/178 [00:20<00:00,  8.59it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.668]\n","Epoch 328:   0% 0/178 [00:00<?, ?it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 328:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.31it/s]\u001b[A\n","Epoch 328:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 120.39it/s]\u001b[A\n","Epoch 328:  34% 60/178 [00:19<00:38,  3.09it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.06it/s]\u001b[A\n","Epoch 328:  45% 80/178 [00:19<00:24,  4.08it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.14it/s]\u001b[A\n","Epoch 328:  56% 100/178 [00:19<00:15,  5.06it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.40it/s]\u001b[A\n","Epoch 328:  67% 120/178 [00:19<00:09,  6.03it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.16it/s]\u001b[A\n","Epoch 328:  79% 140/178 [00:20<00:05,  6.99it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.91it/s]\u001b[A\n","Epoch 328:  90% 160/178 [00:20<00:02,  7.93it/s, loss=1.23, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.92it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.92it/s]\u001b[A\n","Epoch 328: 100% 178/178 [00:20<00:00,  8.77it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.679]\n","Epoch 329:   0% 0/178 [00:00<?, ?it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 329:  11% 20/178 [00:18<02:29,  1.06it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.27it/s]\u001b[A\n","Epoch 329:  22% 40/178 [00:19<01:05,  2.10it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.02it/s]\u001b[A\n","Epoch 329:  34% 60/178 [00:19<00:37,  3.12it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.31it/s]\u001b[A\n","Epoch 329:  45% 80/178 [00:19<00:23,  4.13it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.46it/s]\u001b[A\n","Epoch 329:  56% 100/178 [00:19<00:15,  5.13it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.21it/s]\u001b[A\n","Epoch 329:  67% 120/178 [00:19<00:09,  6.11it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.09it/s]\u001b[A\n","Epoch 329:  79% 140/178 [00:19<00:05,  7.07it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.90it/s]\u001b[A\n","Epoch 329:  90% 160/178 [00:19<00:02,  8.02it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.06it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.06it/s]\u001b[A\n","Epoch 329: 100% 178/178 [00:20<00:00,  8.87it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","                                                               \u001b[AMetric train/loss improved by 0.000 >= min_delta = 0.0. New best score: 1.225\n","Epoch 330:   0% 0/178 [00:00<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Epoch 330:   0% 0/178 [00:19<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 330:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 137.99it/s]\u001b[A\n","Epoch 330:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.92it/s]\u001b[A\n","Epoch 330:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.93it/s]\u001b[A\n","Epoch 330:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.63it/s]\u001b[A\n","Epoch 330:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.51it/s]\u001b[A\n","Epoch 330:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.92it/s]\u001b[A\n","Epoch 330:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.95it/s]\u001b[A\n","Epoch 330:  90% 160/178 [00:20<00:02,  7.79it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.684]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.62it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.62it/s]\u001b[A\n","Epoch 330: 100% 178/178 [00:20<00:00,  8.62it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.684]\n","Epoch 331:   0% 0/178 [00:18<?, ?it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 331:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 127.93it/s]\u001b[A\n","Epoch 331:  22% 40/178 [00:20<01:11,  1.93it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.44it/s]\u001b[A\n","Epoch 331:  34% 60/178 [00:20<00:41,  2.88it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.60it/s]\u001b[A\n","Epoch 331:  45% 80/178 [00:21<00:25,  3.81it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.29it/s]\u001b[A\n","Epoch 331:  56% 100/178 [00:21<00:16,  4.72it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.48it/s]\u001b[A\n","Epoch 331:  67% 120/178 [00:21<00:10,  5.63it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.20it/s]\u001b[A\n","Epoch 331:  79% 140/178 [00:21<00:05,  6.52it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.27it/s]\u001b[A\n","Epoch 331:  90% 160/178 [00:21<00:02,  7.40it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.60it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.60it/s]\u001b[A\n","Epoch 331: 100% 178/178 [00:21<00:00,  8.19it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.670]\n","Epoch 332:   0% 0/178 [00:16<?, ?it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 332:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.88it/s]\u001b[A\n","Epoch 332:  22% 40/178 [00:20<01:09,  1.97it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.90it/s]\u001b[A\n","Epoch 332:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.19it/s]\u001b[A\n","Epoch 332:  45% 80/178 [00:20<00:25,  3.89it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.37it/s]\u001b[A\n","Epoch 332:  56% 100/178 [00:20<00:16,  4.82it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.02it/s]\u001b[A\n","Epoch 332:  67% 120/178 [00:20<00:10,  5.75it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.53it/s]\u001b[A\n","Epoch 332:  79% 140/178 [00:21<00:05,  6.66it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.66it/s]\u001b[A\n","Epoch 332:  90% 160/178 [00:21<00:02,  7.56it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.668]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.13it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.13it/s]\u001b[A\n","Epoch 332: 100% 178/178 [00:21<00:00,  8.36it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.230, train/acc=0.668]\n","Epoch 333:   0% 0/178 [00:15<?, ?it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 333:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.12it/s]\u001b[A\n","Epoch 333:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.06it/s]\u001b[A\n","Epoch 333:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.60it/s]\u001b[A\n","Epoch 333:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.65it/s]\u001b[A\n","Epoch 333:  56% 100/178 [00:20<00:15,  4.91it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.87it/s]\u001b[A\n","Epoch 333:  67% 120/178 [00:20<00:09,  5.85it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.96it/s]\u001b[A\n","Epoch 333:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.22it/s]\u001b[A\n","Epoch 333:  90% 160/178 [00:20<00:02,  7.69it/s, loss=1.24, v_num=2, val/loss=1.510, Val/acc=0.398, train/loss=1.240, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.31it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.31it/s]\u001b[A\n","Epoch 333: 100% 178/178 [00:20<00:00,  8.50it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.240, train/acc=0.670]\n","Epoch 334:   0% 0/178 [00:14<?, ?it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 334:  11% 20/178 [00:19<02:32,  1.04it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 119.95it/s]\u001b[A\n","Epoch 334:  22% 40/178 [00:19<01:06,  2.06it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.77it/s]\u001b[A\n","Epoch 334:  34% 60/178 [00:19<00:38,  3.07it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.51it/s]\u001b[A\n","Epoch 334:  45% 80/178 [00:19<00:24,  4.06it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.38it/s]\u001b[A\n","Epoch 334:  56% 100/178 [00:19<00:15,  5.04it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.88it/s]\u001b[A\n","Epoch 334:  67% 120/178 [00:20<00:09,  6.00it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.10it/s]\u001b[A\n","Epoch 334:  79% 140/178 [00:20<00:05,  6.95it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.18it/s]\u001b[A\n","Epoch 334:  90% 160/178 [00:20<00:02,  7.88it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.250, train/acc=0.658]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.11it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.11it/s]\u001b[A\n","Epoch 334: 100% 178/178 [00:20<00:00,  8.71it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.250, train/acc=0.658]\n","Epoch 335:   0% 0/178 [00:13<?, ?it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 335:  11% 20/178 [00:20<02:45,  1.05s/it, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.75it/s]\u001b[A\n","Epoch 335:  22% 40/178 [00:21<01:12,  1.89it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.58it/s]\u001b[A\n","Epoch 335:  34% 60/178 [00:21<00:41,  2.82it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.07it/s]\u001b[A\n","Epoch 335:  45% 80/178 [00:21<00:26,  3.74it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.45it/s]\u001b[A\n","Epoch 335:  56% 100/178 [00:21<00:16,  4.64it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.02it/s]\u001b[A\n","Epoch 335:  67% 120/178 [00:21<00:10,  5.53it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.40it/s]\u001b[A\n","Epoch 335:  79% 140/178 [00:21<00:05,  6.40it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.96it/s]\u001b[A\n","Epoch 335:  90% 160/178 [00:22<00:02,  7.27it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.88it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.88it/s]\u001b[A\n","Epoch 335: 100% 178/178 [00:22<00:00,  8.04it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.672]\n","Epoch 336:   0% 0/178 [00:11<?, ?it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 336:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 100.79it/s]\u001b[A\n","Epoch 336:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 120.35it/s]\u001b[A\n","Epoch 336:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.01it/s]\u001b[A\n","Epoch 336:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.59it/s]\u001b[A\n","Epoch 336:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.24it/s]\u001b[A\n","Epoch 336:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.75it/s]\u001b[A\n","Epoch 336:  79% 140/178 [00:20<00:05,  6.81it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.28it/s]\u001b[A\n","Epoch 336:  90% 160/178 [00:20<00:02,  7.73it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.250, train/acc=0.660]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.55it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.55it/s]\u001b[A\n","Epoch 336: 100% 178/178 [00:20<00:00,  8.55it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.250, train/acc=0.660]\n","Epoch 337:   0% 0/178 [00:10<?, ?it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 337:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 110.86it/s]\u001b[A\n","Epoch 337:  22% 40/178 [00:20<01:11,  1.93it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.87it/s]\u001b[A\n","Epoch 337:  34% 60/178 [00:20<00:40,  2.88it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.54it/s]\u001b[A\n","Epoch 337:  45% 80/178 [00:20<00:25,  3.81it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.87it/s]\u001b[A\n","Epoch 337:  56% 100/178 [00:21<00:16,  4.73it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.72it/s]\u001b[A\n","Epoch 337:  67% 120/178 [00:21<00:10,  5.64it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.39it/s]\u001b[A\n","Epoch 337:  79% 140/178 [00:21<00:05,  6.53it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.71it/s]\u001b[A\n","Epoch 337:  90% 160/178 [00:21<00:02,  7.41it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.57it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.57it/s]\u001b[A\n","Epoch 337: 100% 178/178 [00:21<00:00,  8.20it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.230, train/acc=0.673]\n","                                                               \u001b[AMetric train/loss improved by 0.002 >= min_delta = 0.0. New best score: 1.223\n","Epoch 338:   0% 0/178 [00:19<?, ?it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 338:  11% 20/178 [00:20<02:40,  1.01s/it, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:00, 150.40it/s]\u001b[A\n","Epoch 338:  22% 40/178 [00:20<01:10,  1.96it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 140.09it/s]\u001b[A\n","Epoch 338:  34% 60/178 [00:20<00:40,  2.92it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 137.77it/s]\u001b[A\n","Epoch 338:  45% 80/178 [00:20<00:25,  3.87it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 135.84it/s]\u001b[A\n","Epoch 338:  56% 100/178 [00:20<00:16,  4.80it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.39it/s]\u001b[A\n","Epoch 338:  67% 120/178 [00:20<00:10,  5.72it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.68it/s]\u001b[A\n","Epoch 338:  79% 140/178 [00:21<00:05,  6.62it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.93it/s]\u001b[A\n","Epoch 338:  90% 160/178 [00:21<00:02,  7.51it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.482, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.20it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.20it/s]\u001b[A\n","Epoch 338: 100% 178/178 [00:21<00:00,  8.31it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.682]\n","                                                               \u001b[AMetric train/loss improved by 0.005 >= min_delta = 0.0. New best score: 1.217\n","Epoch 339:   0% 0/178 [00:17<?, ?it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 339:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 122.29it/s]\u001b[A\n","Epoch 339:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.67it/s]\u001b[A\n","Epoch 339:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.12it/s]\u001b[A\n","Epoch 339:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.12it/s]\u001b[A\n","Epoch 339:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.36it/s]\u001b[A\n","Epoch 339:  67% 120/178 [00:20<00:09,  5.83it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.05it/s]\u001b[A\n","Epoch 339:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.28it/s]\u001b[A\n","Epoch 339:  90% 160/178 [00:20<00:02,  7.66it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.416, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.10it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.10it/s]\u001b[A\n","Epoch 339: 100% 178/178 [00:20<00:00,  8.48it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.687]\n","Epoch 340:   0% 0/178 [00:16<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 340:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.74it/s]\u001b[A\n","Epoch 340:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.93it/s]\u001b[A\n","Epoch 340:  34% 60/178 [00:20<00:39,  2.96it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.07it/s]\u001b[A\n","Epoch 340:  45% 80/178 [00:20<00:25,  3.92it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.75it/s]\u001b[A\n","Epoch 340:  56% 100/178 [00:20<00:16,  4.86it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.66it/s]\u001b[A\n","Epoch 340:  67% 120/178 [00:20<00:10,  5.79it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.11it/s]\u001b[A\n","Epoch 340:  79% 140/178 [00:20<00:05,  6.71it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.34it/s]\u001b[A\n","Epoch 340:  90% 160/178 [00:21<00:02,  7.61it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.55it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.55it/s]\u001b[A\n","Epoch 340: 100% 178/178 [00:21<00:00,  8.42it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.230, train/acc=0.670]\n","Epoch 341:   0% 0/178 [00:15<?, ?it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 341:  11% 20/178 [00:20<02:40,  1.02s/it, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.87it/s]\u001b[A\n","Epoch 341:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.05it/s]\u001b[A\n","Epoch 341:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.97it/s]\u001b[A\n","Epoch 341:  45% 80/178 [00:20<00:25,  3.85it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.65it/s]\u001b[A\n","Epoch 341:  56% 100/178 [00:20<00:16,  4.77it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.71it/s]\u001b[A\n","Epoch 341:  67% 120/178 [00:21<00:10,  5.69it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.60it/s]\u001b[A\n","Epoch 341:  79% 140/178 [00:21<00:05,  6.59it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.84it/s]\u001b[A\n","Epoch 341:  90% 160/178 [00:21<00:02,  7.48it/s, loss=1.24, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.05it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.05it/s]\u001b[A\n","Epoch 341: 100% 178/178 [00:21<00:00,  8.28it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.663]\n","Epoch 342:   0% 0/178 [00:14<?, ?it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 342:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 103.00it/s]\u001b[A\n","Epoch 342:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 120.14it/s]\u001b[A\n","Epoch 342:  34% 60/178 [00:20<00:40,  2.95it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.30it/s]\u001b[A\n","Epoch 342:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.17it/s]\u001b[A\n","Epoch 342:  56% 100/178 [00:20<00:16,  4.84it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 126.94it/s]\u001b[A\n","Epoch 342:  67% 120/178 [00:20<00:10,  5.76it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 127.76it/s]\u001b[A\n","Epoch 342:  79% 140/178 [00:20<00:05,  6.67it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 126.95it/s]\u001b[A\n","Epoch 342:  90% 160/178 [00:21<00:02,  7.57it/s, loss=1.25, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.240, train/acc=0.660]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.63it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.63it/s]\u001b[A\n","Epoch 342: 100% 178/178 [00:21<00:00,  8.38it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.240, train/acc=0.660]\n","Epoch 343:   0% 0/178 [00:12<?, ?it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 343:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 124.65it/s]\u001b[A\n","Epoch 343:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 135.46it/s]\u001b[A\n","Epoch 343:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.58it/s]\u001b[A\n","Epoch 343:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 134.33it/s]\u001b[A\n","Epoch 343:  56% 100/178 [00:19<00:15,  5.02it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.86it/s]\u001b[A\n","Epoch 343:  67% 120/178 [00:20<00:09,  5.97it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.80it/s]\u001b[A\n","Epoch 343:  79% 140/178 [00:20<00:05,  6.92it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.98it/s]\u001b[A\n","Epoch 343:  90% 160/178 [00:20<00:02,  7.85it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.60it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.60it/s]\u001b[A\n","Epoch 343: 100% 178/178 [00:20<00:00,  8.68it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.656]\n","Epoch 344:   0% 0/178 [00:12<?, ?it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 344:  11% 20/178 [00:20<02:38,  1.01s/it, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 99.35it/s]\u001b[A\n","Epoch 344:  22% 40/178 [00:20<01:09,  1.97it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 119.08it/s]\u001b[A\n","Epoch 344:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.93it/s]\u001b[A\n","Epoch 344:  45% 80/178 [00:20<00:25,  3.89it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.91it/s]\u001b[A\n","Epoch 344:  56% 100/178 [00:20<00:16,  4.83it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.64it/s]\u001b[A\n","Epoch 344:  67% 120/178 [00:20<00:10,  5.75it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.63it/s]\u001b[A\n","Epoch 344:  79% 140/178 [00:20<00:05,  6.67it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.90it/s]\u001b[A\n","Epoch 344:  90% 160/178 [00:21<00:02,  7.56it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.25it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.25it/s]\u001b[A\n","Epoch 344: 100% 178/178 [00:21<00:00,  8.36it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.662]\n","Epoch 345:   0% 0/178 [00:10<?, ?it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 345:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.71it/s]\u001b[A\n","Epoch 345:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 119.05it/s]\u001b[A\n","Epoch 345:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.15it/s]\u001b[A\n","Epoch 345:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.26it/s]\u001b[A\n","Epoch 345:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.40it/s]\u001b[A\n","Epoch 345:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.44it/s]\u001b[A\n","Epoch 345:  79% 140/178 [00:20<00:05,  6.86it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.20it/s]\u001b[A\n","Epoch 345:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.97it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.97it/s]\u001b[A\n","Epoch 345: 100% 178/178 [00:20<00:00,  8.61it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.668]\n","Epoch 346:   0% 0/178 [00:10<?, ?it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 346:  11% 20/178 [00:20<02:43,  1.04s/it, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 122.06it/s]\u001b[A\n","Epoch 346:  22% 40/178 [00:20<01:11,  1.92it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.43it/s]\u001b[A\n","Epoch 346:  34% 60/178 [00:20<00:41,  2.86it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.90it/s]\u001b[A\n","Epoch 346:  45% 80/178 [00:21<00:25,  3.78it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.87it/s]\u001b[A\n","Epoch 346:  56% 100/178 [00:21<00:16,  4.70it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.27it/s]\u001b[A\n","Epoch 346:  67% 120/178 [00:21<00:10,  5.59it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.50it/s]\u001b[A\n","Epoch 346:  79% 140/178 [00:21<00:05,  6.48it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.64it/s]\u001b[A\n","Epoch 346:  90% 160/178 [00:21<00:02,  7.35it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.260, train/acc=0.640]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.33it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.33it/s]\u001b[A\n","Epoch 346: 100% 178/178 [00:21<00:00,  8.14it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.640]\n","Epoch 347:   0% 0/178 [00:18<?, ?it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 347:  11% 20/178 [00:20<02:40,  1.02s/it, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 115.91it/s]\u001b[A\n","Epoch 347:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.89it/s]\u001b[A\n","Epoch 347:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.93it/s]\u001b[A\n","Epoch 347:  45% 80/178 [00:20<00:25,  3.85it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.73it/s]\u001b[A\n","Epoch 347:  56% 100/178 [00:20<00:16,  4.78it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.18it/s]\u001b[A\n","Epoch 347:  67% 120/178 [00:21<00:10,  5.69it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.02it/s]\u001b[A\n","Epoch 347:  79% 140/178 [00:21<00:05,  6.59it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.66it/s]\u001b[A\n","Epoch 347:  90% 160/178 [00:21<00:02,  7.48it/s, loss=1.28, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.280, train/acc=0.622]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.87it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.87it/s]\u001b[A\n","Epoch 347: 100% 178/178 [00:21<00:00,  8.28it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.622]\n","Epoch 348:   0% 0/178 [00:16<?, ?it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 348:  11% 20/178 [00:18<02:30,  1.05it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 128.87it/s]\u001b[A\n","Epoch 348:  22% 40/178 [00:19<01:05,  2.09it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 135.49it/s]\u001b[A\n","Epoch 348:  34% 60/178 [00:19<00:37,  3.11it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.53it/s]\u001b[A\n","Epoch 348:  45% 80/178 [00:19<00:23,  4.12it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.85it/s]\u001b[A\n","Epoch 348:  56% 100/178 [00:19<00:15,  5.11it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.19it/s]\u001b[A\n","Epoch 348:  67% 120/178 [00:19<00:09,  6.08it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.69it/s]\u001b[A\n","Epoch 348:  79% 140/178 [00:19<00:05,  7.04it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.39it/s]\u001b[A\n","Epoch 348:  90% 160/178 [00:20<00:02,  7.98it/s, loss=1.28, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.280, train/acc=0.624]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.58it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.58it/s]\u001b[A\n","Epoch 348: 100% 178/178 [00:20<00:00,  8.82it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.280, train/acc=0.624]\n","Epoch 349:   0% 0/178 [00:16<?, ?it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 349:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 104.68it/s]\u001b[A\n","Epoch 349:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.20it/s]\u001b[A\n","Epoch 349:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.71it/s]\u001b[A\n","Epoch 349:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.57it/s]\u001b[A\n","Epoch 349:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.45it/s]\u001b[A\n","Epoch 349:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.19it/s]\u001b[A\n","Epoch 349:  79% 140/178 [00:20<00:05,  6.82it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.31it/s]\u001b[A\n","Epoch 349:  90% 160/178 [00:20<00:02,  7.73it/s, loss=1.27, v_num=2, val/loss=1.460, Val/acc=0.452, train/loss=1.270, train/acc=0.634]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.09it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.09it/s]\u001b[A\n","Epoch 349: 100% 178/178 [00:20<00:00,  8.55it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.270, train/acc=0.634]\n","Epoch 350:   0% 0/178 [00:15<?, ?it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 350:  11% 20/178 [00:21<02:46,  1.05s/it, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 115.38it/s]\u001b[A\n","Epoch 350:  22% 40/178 [00:21<01:13,  1.89it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.98it/s]\u001b[A\n","Epoch 350:  34% 60/178 [00:21<00:41,  2.81it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.15it/s]\u001b[A\n","Epoch 350:  45% 80/178 [00:21<00:26,  3.72it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.64it/s]\u001b[A\n","Epoch 350:  56% 100/178 [00:21<00:16,  4.62it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.18it/s]\u001b[A\n","Epoch 350:  67% 120/178 [00:21<00:10,  5.51it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.17it/s]\u001b[A\n","Epoch 350:  79% 140/178 [00:21<00:05,  6.38it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.70it/s]\u001b[A\n","Epoch 350:  90% 160/178 [00:22<00:02,  7.24it/s, loss=1.26, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.260, train/acc=0.644]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.64it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.64it/s]\u001b[A\n","Epoch 350: 100% 178/178 [00:22<00:00,  8.01it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.260, train/acc=0.644]\n","Epoch 351:   0% 0/178 [00:13<?, ?it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 351:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 127.02it/s]\u001b[A\n","Epoch 351:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.75it/s]\u001b[A\n","Epoch 351:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.07it/s]\u001b[A\n","Epoch 351:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.85it/s]\u001b[A\n","Epoch 351:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.43it/s]\u001b[A\n","Epoch 351:  67% 120/178 [00:20<00:09,  5.80it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.25it/s]\u001b[A\n","Epoch 351:  79% 140/178 [00:20<00:05,  6.72it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.23it/s]\u001b[A\n","Epoch 351:  90% 160/178 [00:20<00:02,  7.62it/s, loss=1.25, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.250, train/acc=0.651]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.87it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.87it/s]\u001b[A\n","Epoch 351: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.250, train/acc=0.651]\n","Epoch 352:   0% 0/178 [00:12<?, ?it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 352:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 101.95it/s]\u001b[A\n","Epoch 352:  22% 40/178 [00:20<01:09,  1.97it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 117.51it/s]\u001b[A\n","Epoch 352:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 123.20it/s]\u001b[A\n","Epoch 352:  45% 80/178 [00:20<00:25,  3.89it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.17it/s]\u001b[A\n","Epoch 352:  56% 100/178 [00:20<00:16,  4.82it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.24it/s]\u001b[A\n","Epoch 352:  67% 120/178 [00:20<00:10,  5.75it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.11it/s]\u001b[A\n","Epoch 352:  79% 140/178 [00:21<00:05,  6.66it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.78it/s]\u001b[A\n","Epoch 352:  90% 160/178 [00:21<00:02,  7.55it/s, loss=1.25, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.21it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.21it/s]\u001b[A\n","Epoch 352: 100% 178/178 [00:21<00:00,  8.36it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.240, train/acc=0.662]\n","Epoch 353:   0% 0/178 [00:11<?, ?it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 353:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.11it/s]\u001b[A\n","Epoch 353:  22% 40/178 [00:20<01:09,  1.97it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.42it/s]\u001b[A\n","Epoch 353:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.66it/s]\u001b[A\n","Epoch 353:  45% 80/178 [00:20<00:25,  3.89it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 134.32it/s]\u001b[A\n","Epoch 353:  56% 100/178 [00:20<00:16,  4.83it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.90it/s]\u001b[A\n","Epoch 353:  67% 120/178 [00:20<00:10,  5.75it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.64it/s]\u001b[A\n","Epoch 353:  79% 140/178 [00:21<00:05,  6.66it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.65it/s]\u001b[A\n","Epoch 353:  90% 160/178 [00:21<00:02,  7.55it/s, loss=1.24, v_num=2, val/loss=1.470, Val/acc=0.410, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.83it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.83it/s]\u001b[A\n","Epoch 353: 100% 178/178 [00:21<00:00,  8.36it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.670]\n","Epoch 354:   0% 0/178 [00:00<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Epoch 354:   0% 0/178 [00:19<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 354:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.41it/s]\u001b[A\n","Epoch 354:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.13it/s]\u001b[A\n","Epoch 354:  34% 60/178 [00:20<00:39,  2.95it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.53it/s]\u001b[A\n","Epoch 354:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.52it/s]\u001b[A\n","Epoch 354:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.77it/s]\u001b[A\n","Epoch 354:  67% 120/178 [00:20<00:10,  5.77it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.09it/s]\u001b[A\n","Epoch 354:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.52it/s]\u001b[A\n","Epoch 354:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.230, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.63it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.63it/s]\u001b[A\n","Epoch 354: 100% 178/178 [00:21<00:00,  8.40it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.682]\n","Epoch 355:   0% 0/178 [00:18<?, ?it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 355:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 102.08it/s]\u001b[A\n","Epoch 355:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.64it/s]\u001b[A\n","Epoch 355:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.84it/s]\u001b[A\n","Epoch 355:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.29it/s]\u001b[A\n","Epoch 355:  56% 100/178 [00:20<00:15,  5.00it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.25it/s]\u001b[A\n","Epoch 355:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.61it/s]\u001b[A\n","Epoch 355:  79% 140/178 [00:20<00:05,  6.90it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.50it/s]\u001b[A\n","Epoch 355:  90% 160/178 [00:20<00:02,  7.83it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.74it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.74it/s]\u001b[A\n","Epoch 355: 100% 178/178 [00:20<00:00,  8.66it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.673]\n","Epoch 356:   0% 0/178 [00:17<?, ?it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 356:  11% 20/178 [00:20<02:45,  1.05s/it, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 120.15it/s]\u001b[A\n","Epoch 356:  22% 40/178 [00:21<01:12,  1.90it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.79it/s]\u001b[A\n","Epoch 356:  34% 60/178 [00:21<00:41,  2.82it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.32it/s]\u001b[A\n","Epoch 356:  45% 80/178 [00:21<00:26,  3.74it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 133.44it/s]\u001b[A\n","Epoch 356:  56% 100/178 [00:21<00:16,  4.64it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.29it/s]\u001b[A\n","Epoch 356:  67% 120/178 [00:21<00:10,  5.53it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.65it/s]\u001b[A\n","Epoch 356:  79% 140/178 [00:21<00:05,  6.41it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.24it/s]\u001b[A\n","Epoch 356:  90% 160/178 [00:22<00:02,  7.27it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.44it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.44it/s]\u001b[A\n","Epoch 356: 100% 178/178 [00:22<00:00,  8.05it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Epoch 357:   0% 0/178 [00:15<?, ?it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 357:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 136.02it/s]\u001b[A\n","Epoch 357:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 138.33it/s]\u001b[A\n","Epoch 357:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 137.79it/s]\u001b[A\n","Epoch 357:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 133.16it/s]\u001b[A\n","Epoch 357:  56% 100/178 [00:20<00:15,  4.91it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.39it/s]\u001b[A\n","Epoch 357:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.87it/s]\u001b[A\n","Epoch 357:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.81it/s]\u001b[A\n","Epoch 357:  90% 160/178 [00:20<00:02,  7.68it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.54it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.54it/s]\u001b[A\n","Epoch 357: 100% 178/178 [00:20<00:00,  8.50it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.674]\n","Epoch 358:   0% 0/178 [00:14<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 358:  11% 20/178 [00:19<02:30,  1.05it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 115.98it/s]\u001b[A\n","Epoch 358:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.32it/s]\u001b[A\n","Epoch 358:  34% 60/178 [00:19<00:38,  3.10it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.17it/s]\u001b[A\n","Epoch 358:  45% 80/178 [00:19<00:23,  4.10it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.94it/s]\u001b[A\n","Epoch 358:  56% 100/178 [00:19<00:15,  5.08it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.02it/s]\u001b[A\n","Epoch 358:  67% 120/178 [00:19<00:09,  6.05it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.40it/s]\u001b[A\n","Epoch 358:  79% 140/178 [00:19<00:05,  7.01it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.22it/s]\u001b[A\n","Epoch 358:  90% 160/178 [00:20<00:02,  7.95it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.669]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.48it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.48it/s]\u001b[A\n","Epoch 358: 100% 178/178 [00:20<00:00,  8.79it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.230, train/acc=0.669]\n","Epoch 359:   0% 0/178 [00:14<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 359:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.43it/s]\u001b[A\n","Epoch 359:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.28it/s]\u001b[A\n","Epoch 359:  34% 60/178 [00:20<00:39,  2.96it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.18it/s]\u001b[A\n","Epoch 359:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.88it/s]\u001b[A\n","Epoch 359:  56% 100/178 [00:20<00:16,  4.86it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.57it/s]\u001b[A\n","Epoch 359:  67% 120/178 [00:20<00:10,  5.79it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.51it/s]\u001b[A\n","Epoch 359:  79% 140/178 [00:20<00:05,  6.70it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.44it/s]\u001b[A\n","Epoch 359:  90% 160/178 [00:21<00:02,  7.61it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.440, train/loss=1.240, train/acc=0.663]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.63it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.63it/s]\u001b[A\n","Epoch 359: 100% 178/178 [00:21<00:00,  8.41it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.240, train/acc=0.663]\n","Epoch 360:   0% 0/178 [00:13<?, ?it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 360:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 104.97it/s]\u001b[A\n","Epoch 360:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.82it/s]\u001b[A\n","Epoch 360:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.68it/s]\u001b[A\n","Epoch 360:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.39it/s]\u001b[A\n","Epoch 360:  56% 100/178 [00:20<00:15,  5.00it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.89it/s]\u001b[A\n","Epoch 360:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.39it/s]\u001b[A\n","Epoch 360:  79% 140/178 [00:20<00:05,  6.89it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.23it/s]\u001b[A\n","Epoch 360:  90% 160/178 [00:20<00:02,  7.82it/s, loss=1.24, v_num=2, val/loss=1.490, Val/acc=0.410, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.83it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.83it/s]\u001b[A\n","Epoch 360: 100% 178/178 [00:20<00:00,  8.65it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Epoch 361:   0% 0/178 [00:12<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 361:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.09it/s]\u001b[A\n","Epoch 361:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.74it/s]\u001b[A\n","Epoch 361:  34% 60/178 [00:20<00:39,  2.96it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.71it/s]\u001b[A\n","Epoch 361:  45% 80/178 [00:20<00:25,  3.92it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.94it/s]\u001b[A\n","Epoch 361:  56% 100/178 [00:20<00:16,  4.86it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.12it/s]\u001b[A\n","Epoch 361:  67% 120/178 [00:20<00:10,  5.79it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.08it/s]\u001b[A\n","Epoch 361:  79% 140/178 [00:20<00:05,  6.70it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.12it/s]\u001b[A\n","Epoch 361:  90% 160/178 [00:21<00:02,  7.61it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.666]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.71it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.71it/s]\u001b[A\n","Epoch 361: 100% 178/178 [00:21<00:00,  8.41it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.666]\n","Epoch 362:   0% 0/178 [00:11<?, ?it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 362:  11% 20/178 [00:19<02:34,  1.03it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 119.95it/s]\u001b[A\n","Epoch 362:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.06it/s]\u001b[A\n","Epoch 362:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.53it/s]\u001b[A\n","Epoch 362:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.20it/s]\u001b[A\n","Epoch 362:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.18it/s]\u001b[A\n","Epoch 362:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.06it/s]\u001b[A\n","Epoch 362:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.24it/s]\u001b[A\n","Epoch 362:  90% 160/178 [00:20<00:02,  7.79it/s, loss=1.24, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.250, train/acc=0.643]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.25it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.25it/s]\u001b[A\n","Epoch 362: 100% 178/178 [00:20<00:00,  8.62it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.643]\n","Epoch 363:   0% 0/178 [00:10<?, ?it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 363:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.88it/s]\u001b[A\n","Epoch 363:  22% 40/178 [00:20<01:11,  1.93it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.63it/s]\u001b[A\n","Epoch 363:  34% 60/178 [00:20<00:40,  2.88it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.73it/s]\u001b[A\n","Epoch 363:  45% 80/178 [00:20<00:25,  3.81it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.93it/s]\u001b[A\n","Epoch 363:  56% 100/178 [00:21<00:16,  4.73it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.20it/s]\u001b[A\n","Epoch 363:  67% 120/178 [00:21<00:10,  5.64it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.18it/s]\u001b[A\n","Epoch 363:  79% 140/178 [00:21<00:05,  6.53it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.78it/s]\u001b[A\n","Epoch 363:  90% 160/178 [00:21<00:02,  7.41it/s, loss=1.25, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.250, train/acc=0.656]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.03it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.03it/s]\u001b[A\n","Epoch 363: 100% 178/178 [00:21<00:00,  8.20it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.250, train/acc=0.656]\n","Epoch 364:   0% 0/178 [00:00<?, ?it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 364:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 100.61it/s]\u001b[A\n","Epoch 364:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.60it/s]\u001b[A\n","Epoch 364:  34% 60/178 [00:19<00:38,  3.08it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 123.94it/s]\u001b[A\n","Epoch 364:  45% 80/178 [00:19<00:24,  4.08it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.03it/s]\u001b[A\n","Epoch 364:  56% 100/178 [00:19<00:15,  5.06it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.41it/s]\u001b[A\n","Epoch 364:  67% 120/178 [00:19<00:09,  6.02it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.23it/s]\u001b[A\n","Epoch 364:  79% 140/178 [00:20<00:05,  6.97it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.89it/s]\u001b[A\n","Epoch 364:  90% 160/178 [00:20<00:02,  7.91it/s, loss=1.24, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.28it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.28it/s]\u001b[A\n","Epoch 364: 100% 178/178 [00:20<00:00,  8.75it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.670]\n","Epoch 365:   0% 0/178 [00:18<?, ?it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 365:  11% 20/178 [00:20<02:40,  1.02s/it, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.21it/s]\u001b[A\n","Epoch 365:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.69it/s]\u001b[A\n","Epoch 365:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.56it/s]\u001b[A\n","Epoch 365:  45% 80/178 [00:20<00:25,  3.85it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.12it/s]\u001b[A\n","Epoch 365:  56% 100/178 [00:20<00:16,  4.77it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.77it/s]\u001b[A\n","Epoch 365:  67% 120/178 [00:21<00:10,  5.69it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.28it/s]\u001b[A\n","Epoch 365:  79% 140/178 [00:21<00:05,  6.59it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.37it/s]\u001b[A\n","Epoch 365:  90% 160/178 [00:21<00:02,  7.48it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.39it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.39it/s]\u001b[A\n","Epoch 365: 100% 178/178 [00:21<00:00,  8.28it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.679]\n","Epoch 366:   0% 0/178 [00:17<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 366:  11% 20/178 [00:19<02:32,  1.04it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 124.34it/s]\u001b[A\n","Epoch 366:  22% 40/178 [00:19<01:07,  2.06it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.48it/s]\u001b[A\n","Epoch 366:  34% 60/178 [00:19<00:38,  3.07it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.62it/s]\u001b[A\n","Epoch 366:  45% 80/178 [00:19<00:24,  4.06it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.07it/s]\u001b[A\n","Epoch 366:  56% 100/178 [00:19<00:15,  5.03it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.69it/s]\u001b[A\n","Epoch 366:  67% 120/178 [00:20<00:09,  5.99it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.41it/s]\u001b[A\n","Epoch 366:  79% 140/178 [00:20<00:05,  6.94it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.35it/s]\u001b[A\n","Epoch 366:  90% 160/178 [00:20<00:02,  7.87it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.23it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.23it/s]\u001b[A\n","Epoch 366: 100% 178/178 [00:20<00:00,  8.71it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.677]\n","Epoch 367:   0% 0/178 [00:16<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 367:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 113.94it/s]\u001b[A\n","Epoch 367:  22% 40/178 [00:19<01:08,  2.03it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.79it/s]\u001b[A\n","Epoch 367:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.72it/s]\u001b[A\n","Epoch 367:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.97it/s]\u001b[A\n","Epoch 367:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.76it/s]\u001b[A\n","Epoch 367:  67% 120/178 [00:20<00:09,  5.90it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.35it/s]\u001b[A\n","Epoch 367:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.01it/s]\u001b[A\n","Epoch 367:  90% 160/178 [00:20<00:02,  7.74it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.28it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.28it/s]\u001b[A\n","Epoch 367: 100% 178/178 [00:20<00:00,  8.57it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.678]\n","Epoch 368:   0% 0/178 [00:15<?, ?it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 368:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 113.91it/s]\u001b[A\n","Epoch 368:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.51it/s]\u001b[A\n","Epoch 368:  34% 60/178 [00:20<00:39,  3.00it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.12it/s]\u001b[A\n","Epoch 368:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.98it/s]\u001b[A\n","Epoch 368:  56% 100/178 [00:20<00:15,  4.92it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.05it/s]\u001b[A\n","Epoch 368:  67% 120/178 [00:20<00:09,  5.87it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.36it/s]\u001b[A\n","Epoch 368:  79% 140/178 [00:20<00:05,  6.79it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.85it/s]\u001b[A\n","Epoch 368:  90% 160/178 [00:20<00:02,  7.70it/s, loss=1.23, v_num=2, val/loss=1.400, Val/acc=0.500, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.17it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.17it/s]\u001b[A\n","Epoch 368: 100% 178/178 [00:20<00:00,  8.52it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Epoch 369:   0% 0/178 [00:15<?, ?it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 369:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 121.37it/s]\u001b[A\n","Epoch 369:  22% 40/178 [00:20<01:11,  1.93it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.28it/s]\u001b[A\n","Epoch 369:  34% 60/178 [00:20<00:40,  2.88it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.21it/s]\u001b[A\n","Epoch 369:  45% 80/178 [00:20<00:25,  3.81it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.56it/s]\u001b[A\n","Epoch 369:  56% 100/178 [00:21<00:16,  4.73it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.39it/s]\u001b[A\n","Epoch 369:  67% 120/178 [00:21<00:10,  5.64it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.84it/s]\u001b[A\n","Epoch 369:  79% 140/178 [00:21<00:05,  6.53it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.38it/s]\u001b[A\n","Epoch 369:  90% 160/178 [00:21<00:02,  7.41it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.54it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.54it/s]\u001b[A\n","Epoch 369: 100% 178/178 [00:21<00:00,  8.20it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Epoch 370:   0% 0/178 [00:13<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 370:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 125.27it/s]\u001b[A\n","Epoch 370:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 136.48it/s]\u001b[A\n","Epoch 370:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.07it/s]\u001b[A\n","Epoch 370:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.48it/s]\u001b[A\n","Epoch 370:  56% 100/178 [00:20<00:15,  4.99it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.86it/s]\u001b[A\n","Epoch 370:  67% 120/178 [00:20<00:09,  5.94it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.66it/s]\u001b[A\n","Epoch 370:  79% 140/178 [00:20<00:05,  6.88it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.73it/s]\u001b[A\n","Epoch 370:  90% 160/178 [00:20<00:02,  7.81it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.240, train/acc=0.666]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.13it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.13it/s]\u001b[A\n","Epoch 370: 100% 178/178 [00:20<00:00,  8.64it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.240, train/acc=0.666]\n","Epoch 371:   0% 0/178 [00:12<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 371:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 100.47it/s]\u001b[A\n","Epoch 371:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.60it/s]\u001b[A\n","Epoch 371:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.37it/s]\u001b[A\n","Epoch 371:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.32it/s]\u001b[A\n","Epoch 371:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.37it/s]\u001b[A\n","Epoch 371:  67% 120/178 [00:20<00:09,  5.82it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 126.46it/s]\u001b[A\n","Epoch 371:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.31it/s]\u001b[A\n","Epoch 371:  90% 160/178 [00:20<00:02,  7.65it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.09it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.09it/s]\u001b[A\n","Epoch 371: 100% 178/178 [00:21<00:00,  8.47it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.230, train/acc=0.676]\n","Epoch 372:   0% 0/178 [00:11<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 372:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 137.38it/s]\u001b[A\n","Epoch 372:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.72it/s]\u001b[A\n","Epoch 372:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.49it/s]\u001b[A\n","Epoch 372:  45% 80/178 [00:20<00:24,  3.92it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.42it/s]\u001b[A\n","Epoch 372:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.16it/s]\u001b[A\n","Epoch 372:  67% 120/178 [00:20<00:10,  5.80it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 126.71it/s]\u001b[A\n","Epoch 372:  79% 140/178 [00:20<00:05,  6.71it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.04it/s]\u001b[A\n","Epoch 372:  90% 160/178 [00:21<00:02,  7.61it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.446, train/loss=1.220, train/acc=0.687]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.62it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.62it/s]\u001b[A\n","Epoch 372: 100% 178/178 [00:21<00:00,  8.42it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.687]\n","Epoch 373:   0% 0/178 [00:10<?, ?it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 373:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 124.72it/s]\u001b[A\n","Epoch 373:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.08it/s]\u001b[A\n","Epoch 373:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.20it/s]\u001b[A\n","Epoch 373:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.33it/s]\u001b[A\n","Epoch 373:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.85it/s]\u001b[A\n","Epoch 373:  67% 120/178 [00:20<00:09,  5.81it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.96it/s]\u001b[A\n","Epoch 373:  79% 140/178 [00:20<00:05,  6.73it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.76it/s]\u001b[A\n","Epoch 373:  90% 160/178 [00:20<00:02,  7.63it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.86it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.86it/s]\u001b[A\n","Epoch 373: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Epoch 374:   0% 0/178 [00:19<?, ?it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 374:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 128.49it/s]\u001b[A\n","Epoch 374:  22% 40/178 [00:20<01:11,  1.94it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.07it/s]\u001b[A\n","Epoch 374:  34% 60/178 [00:20<00:40,  2.89it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.34it/s]\u001b[A\n","Epoch 374:  45% 80/178 [00:20<00:25,  3.82it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.26it/s]\u001b[A\n","Epoch 374:  56% 100/178 [00:21<00:16,  4.74it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.68it/s]\u001b[A\n","Epoch 374:  67% 120/178 [00:21<00:10,  5.65it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.91it/s]\u001b[A\n","Epoch 374:  79% 140/178 [00:21<00:05,  6.55it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.59it/s]\u001b[A\n","Epoch 374:  90% 160/178 [00:21<00:02,  7.43it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.25it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.25it/s]\u001b[A\n","Epoch 374: 100% 178/178 [00:21<00:00,  8.22it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.688]\n","Epoch 375:   0% 0/178 [00:17<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 375:  11% 20/178 [00:20<02:44,  1.04s/it, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 129.06it/s]\u001b[A\n","Epoch 375:  22% 40/178 [00:20<01:12,  1.91it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.07it/s]\u001b[A\n","Epoch 375:  34% 60/178 [00:21<00:41,  2.84it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.96it/s]\u001b[A\n","Epoch 375:  45% 80/178 [00:21<00:26,  3.75it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 124.13it/s]\u001b[A\n","Epoch 375:  56% 100/178 [00:21<00:16,  4.66it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 125.37it/s]\u001b[A\n","Epoch 375:  67% 120/178 [00:21<00:10,  5.55it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 124.18it/s]\u001b[A\n","Epoch 375:  79% 140/178 [00:21<00:05,  6.42it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 126.49it/s]\u001b[A\n","Epoch 375:  90% 160/178 [00:21<00:02,  7.29it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.680]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 131.40it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 131.40it/s]\u001b[A\n","Epoch 375: 100% 178/178 [00:22<00:00,  8.07it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.680]\n","Epoch 376:   0% 0/178 [00:15<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 376:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.87it/s]\u001b[A\n","Epoch 376:  22% 40/178 [00:20<01:10,  1.97it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.79it/s]\u001b[A\n","Epoch 376:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.03it/s]\u001b[A\n","Epoch 376:  45% 80/178 [00:20<00:25,  3.88it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.39it/s]\u001b[A\n","Epoch 376:  56% 100/178 [00:20<00:16,  4.82it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.09it/s]\u001b[A\n","Epoch 376:  67% 120/178 [00:20<00:10,  5.74it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.78it/s]\u001b[A\n","Epoch 376:  79% 140/178 [00:21<00:05,  6.65it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.66it/s]\u001b[A\n","Epoch 376:  90% 160/178 [00:21<00:02,  7.54it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.07it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 132.07it/s]\u001b[A\n","Epoch 376: 100% 178/178 [00:21<00:00,  8.34it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.673]\n","Epoch 377:   0% 0/178 [00:14<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 377:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 128.31it/s]\u001b[A\n","Epoch 377:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.55it/s]\u001b[A\n","Epoch 377:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.48it/s]\u001b[A\n","Epoch 377:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.59it/s]\u001b[A\n","Epoch 377:  56% 100/178 [00:20<00:15,  4.99it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.21it/s]\u001b[A\n","Epoch 377:  67% 120/178 [00:20<00:09,  5.94it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.74it/s]\u001b[A\n","Epoch 377:  79% 140/178 [00:20<00:05,  6.88it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.30it/s]\u001b[A\n","Epoch 377:  90% 160/178 [00:20<00:02,  7.81it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.683]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.06it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.06it/s]\u001b[A\n","Epoch 377: 100% 178/178 [00:20<00:00,  8.64it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.683]\n","Epoch 378:   0% 0/178 [00:13<?, ?it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 378:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 124.40it/s]\u001b[A\n","Epoch 378:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 136.19it/s]\u001b[A\n","Epoch 378:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.57it/s]\u001b[A\n","Epoch 378:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 133.27it/s]\u001b[A\n","Epoch 378:  56% 100/178 [00:20<00:15,  4.93it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.65it/s]\u001b[A\n","Epoch 378:  67% 120/178 [00:20<00:09,  5.87it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.49it/s]\u001b[A\n","Epoch 378:  79% 140/178 [00:20<00:05,  6.80it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.42it/s]\u001b[A\n","Epoch 378:  90% 160/178 [00:20<00:02,  7.71it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.70it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.70it/s]\u001b[A\n","Epoch 378: 100% 178/178 [00:20<00:00,  8.53it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Epoch 379:   0% 0/178 [00:12<?, ?it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 379:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:00, 146.53it/s]\u001b[A\n","Epoch 379:  22% 40/178 [00:19<01:08,  2.03it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 141.75it/s]\u001b[A\n","Epoch 379:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 138.49it/s]\u001b[A\n","Epoch 379:  45% 80/178 [00:20<00:24,  4.00it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 135.02it/s]\u001b[A\n","Epoch 379:  56% 100/178 [00:20<00:15,  4.96it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 139.30it/s]\u001b[A\n","Epoch 379:  67% 120/178 [00:20<00:09,  5.91it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 138.49it/s]\u001b[A\n","Epoch 379:  79% 140/178 [00:20<00:05,  6.85it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.99it/s]\u001b[A\n","Epoch 379:  90% 160/178 [00:20<00:02,  7.75it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.61it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.61it/s]\u001b[A\n","Epoch 379: 100% 178/178 [00:20<00:00,  8.58it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.240, train/acc=0.667]\n","Epoch 380:   0% 0/178 [00:11<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 380:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 113.59it/s]\u001b[A\n","Epoch 380:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.00it/s]\u001b[A\n","Epoch 380:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.07it/s]\u001b[A\n","Epoch 380:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 133.25it/s]\u001b[A\n","Epoch 380:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.89it/s]\u001b[A\n","Epoch 380:  67% 120/178 [00:20<00:09,  5.80it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.82it/s]\u001b[A\n","Epoch 380:  79% 140/178 [00:20<00:05,  6.72it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.99it/s]\u001b[A\n","Epoch 380:  90% 160/178 [00:20<00:02,  7.63it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.33it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.33it/s]\u001b[A\n","Epoch 380: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.686]\n","                                                               \u001b[AMetric train/loss improved by 0.003 >= min_delta = 0.0. New best score: 1.215\n","Epoch 381:   0% 0/178 [00:10<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 381:  11% 20/178 [00:18<02:27,  1.07it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 109.41it/s]\u001b[A\n","Epoch 381:  22% 40/178 [00:18<01:05,  2.12it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.76it/s]\u001b[A\n","Epoch 381:  34% 60/178 [00:19<00:37,  3.16it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.50it/s]\u001b[A\n","Epoch 381:  45% 80/178 [00:19<00:23,  4.18it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.34it/s]\u001b[A\n","Epoch 381:  56% 100/178 [00:19<00:15,  5.18it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.11it/s]\u001b[A\n","Epoch 381:  67% 120/178 [00:19<00:09,  6.17it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.54it/s]\u001b[A\n","Epoch 381:  79% 140/178 [00:19<00:05,  7.14it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.74it/s]\u001b[A\n","Epoch 381:  90% 160/178 [00:19<00:02,  8.10it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.06it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.06it/s]\u001b[A\n","Epoch 381: 100% 178/178 [00:19<00:00,  8.96it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.210, train/acc=0.693]\n","Epoch 382:   0% 0/178 [00:10<?, ?it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 382:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.63it/s]\u001b[A\n","Epoch 382:  22% 40/178 [00:20<01:11,  1.93it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.12it/s]\u001b[A\n","Epoch 382:  34% 60/178 [00:20<00:41,  2.87it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.11it/s]\u001b[A\n","Epoch 382:  45% 80/178 [00:21<00:25,  3.80it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.29it/s]\u001b[A\n","Epoch 382:  56% 100/178 [00:21<00:16,  4.71it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.65it/s]\u001b[A\n","Epoch 382:  67% 120/178 [00:21<00:10,  5.62it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.74it/s]\u001b[A\n","Epoch 382:  79% 140/178 [00:21<00:05,  6.51it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.99it/s]\u001b[A\n","Epoch 382:  90% 160/178 [00:21<00:02,  7.38it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.482, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.11it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.11it/s]\u001b[A\n","Epoch 382: 100% 178/178 [00:21<00:00,  8.17it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.689]\n","Epoch 383:   0% 0/178 [00:00<?, ?it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 383:  11% 20/178 [00:18<02:29,  1.05it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 134.53it/s]\u001b[A\n","Epoch 383:  22% 40/178 [00:19<01:05,  2.09it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.56it/s]\u001b[A\n","Epoch 383:  34% 60/178 [00:19<00:37,  3.12it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 136.36it/s]\u001b[A\n","Epoch 383:  45% 80/178 [00:19<00:23,  4.12it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 135.16it/s]\u001b[A\n","Epoch 383:  56% 100/178 [00:19<00:15,  5.12it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.74it/s]\u001b[A\n","Epoch 383:  67% 120/178 [00:19<00:09,  6.09it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.76it/s]\u001b[A\n","Epoch 383:  79% 140/178 [00:19<00:05,  7.05it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.08it/s]\u001b[A\n","Epoch 383:  90% 160/178 [00:20<00:02,  8.00it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.25it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.25it/s]\u001b[A\n","Epoch 383: 100% 178/178 [00:20<00:00,  8.84it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.220, train/acc=0.690]\n","Epoch 384:   0% 0/178 [00:18<?, ?it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 384:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 116.39it/s]\u001b[A\n","Epoch 384:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.01it/s]\u001b[A\n","Epoch 384:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.02it/s]\u001b[A\n","Epoch 384:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.61it/s]\u001b[A\n","Epoch 384:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.36it/s]\u001b[A\n","Epoch 384:  67% 120/178 [00:20<00:09,  5.83it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.28it/s]\u001b[A\n","Epoch 384:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.52it/s]\u001b[A\n","Epoch 384:  90% 160/178 [00:20<00:02,  7.66it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.250, train/acc=0.654]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.26it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.26it/s]\u001b[A\n","Epoch 384: 100% 178/178 [00:20<00:00,  8.48it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.250, train/acc=0.654]\n","Epoch 385:   0% 0/178 [00:17<?, ?it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 385:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.37it/s]\u001b[A\n","Epoch 385:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.41it/s]\u001b[A\n","Epoch 385:  34% 60/178 [00:20<00:40,  2.90it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.32it/s]\u001b[A\n","Epoch 385:  45% 80/178 [00:20<00:25,  3.84it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.19it/s]\u001b[A\n","Epoch 385:  56% 100/178 [00:20<00:16,  4.76it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.35it/s]\u001b[A\n","Epoch 385:  67% 120/178 [00:21<00:10,  5.68it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.45it/s]\u001b[A\n","Epoch 385:  79% 140/178 [00:21<00:05,  6.58it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.31it/s]\u001b[A\n","Epoch 385:  90% 160/178 [00:21<00:02,  7.47it/s, loss=1.24, v_num=2, val/loss=1.480, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.13it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.13it/s]\u001b[A\n","Epoch 385: 100% 178/178 [00:21<00:00,  8.26it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.240, train/acc=0.668]\n","                                                               \u001b[AMetric train/loss improved by 0.010 >= min_delta = 0.0. New best score: 1.205\n","Epoch 386:   0% 0/178 [00:16<?, ?it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 386:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 135.86it/s]\u001b[A\n","Epoch 386:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 137.21it/s]\u001b[A\n","Epoch 386:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.21it/s]\u001b[A\n","Epoch 386:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.90it/s]\u001b[A\n","Epoch 386:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.42it/s]\u001b[A\n","Epoch 386:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.69it/s]\u001b[A\n","Epoch 386:  79% 140/178 [00:20<00:05,  6.82it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.21it/s]\u001b[A\n","Epoch 386:  90% 160/178 [00:20<00:02,  7.74it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.200, train/acc=0.699]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.52it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.52it/s]\u001b[A\n","Epoch 386: 100% 178/178 [00:20<00:00,  8.56it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.200, train/acc=0.699]\n","Epoch 387:   0% 0/178 [00:15<?, ?it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 387:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 116.10it/s]\u001b[A\n","Epoch 387:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.20it/s]\u001b[A\n","Epoch 387:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.18it/s]\u001b[A\n","Epoch 387:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.36it/s]\u001b[A\n","Epoch 387:  56% 100/178 [00:20<00:15,  4.99it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.09it/s]\u001b[A\n","Epoch 387:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.59it/s]\u001b[A\n","Epoch 387:  79% 140/178 [00:20<00:05,  6.89it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.85it/s]\u001b[A\n","Epoch 387:  90% 160/178 [00:20<00:02,  7.81it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.678]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.86it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.86it/s]\u001b[A\n","Epoch 387: 100% 178/178 [00:20<00:00,  8.64it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.220, train/acc=0.678]\n","Epoch 388:   0% 0/178 [00:14<?, ?it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 388:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.94it/s]\u001b[A\n","Epoch 388:  22% 40/178 [00:20<01:10,  1.94it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.87it/s]\u001b[A\n","Epoch 388:  34% 60/178 [00:20<00:40,  2.90it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.09it/s]\u001b[A\n","Epoch 388:  45% 80/178 [00:20<00:25,  3.83it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.34it/s]\u001b[A\n","Epoch 388:  56% 100/178 [00:21<00:16,  4.76it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.77it/s]\u001b[A\n","Epoch 388:  67% 120/178 [00:21<00:10,  5.67it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.45it/s]\u001b[A\n","Epoch 388:  79% 140/178 [00:21<00:05,  6.57it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.84it/s]\u001b[A\n","Epoch 388:  90% 160/178 [00:21<00:02,  7.45it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.26it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.26it/s]\u001b[A\n","Epoch 388: 100% 178/178 [00:21<00:00,  8.24it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.694]\n","Epoch 389:   0% 0/178 [00:13<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 389:  11% 20/178 [00:18<02:29,  1.06it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:03, 47.66it/s]\u001b[A\n","Epoch 389:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 77.24it/s]\u001b[A\n","Epoch 389:  34% 60/178 [00:19<00:38,  3.08it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:01, 95.88it/s]\u001b[A\n","Epoch 389:  45% 80/178 [00:19<00:24,  4.08it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 108.04it/s]\u001b[A\n","Epoch 389:  56% 100/178 [00:19<00:15,  5.06it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:01<00:00, 115.13it/s]\u001b[A\n","Epoch 389:  67% 120/178 [00:19<00:09,  6.02it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:01<00:00, 120.38it/s]\u001b[A\n","Epoch 389:  79% 140/178 [00:20<00:05,  6.98it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 123.43it/s]\u001b[A\n","Epoch 389:  90% 160/178 [00:20<00:02,  7.91it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 129.70it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 129.70it/s]\u001b[A\n","Epoch 389: 100% 178/178 [00:20<00:00,  8.75it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.675]\n","Epoch 390:   0% 0/178 [00:12<?, ?it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 390:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 116.61it/s]\u001b[A\n","Epoch 390:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.31it/s]\u001b[A\n","Epoch 390:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.03it/s]\u001b[A\n","Epoch 390:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.10it/s]\u001b[A\n","Epoch 390:  56% 100/178 [00:20<00:15,  5.00it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.73it/s]\u001b[A\n","Epoch 390:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.18it/s]\u001b[A\n","Epoch 390:  79% 140/178 [00:20<00:05,  6.90it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.24it/s]\u001b[A\n","Epoch 390:  90% 160/178 [00:20<00:02,  7.82it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.230, train/acc=0.670]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.41it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.41it/s]\u001b[A\n","Epoch 390: 100% 178/178 [00:20<00:00,  8.66it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.230, train/acc=0.670]\n","Epoch 391:   0% 0/178 [00:12<?, ?it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 391:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 104.27it/s]\u001b[A\n","Epoch 391:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.08it/s]\u001b[A\n","Epoch 391:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.20it/s]\u001b[A\n","Epoch 391:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.44it/s]\u001b[A\n","Epoch 391:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.94it/s]\u001b[A\n","Epoch 391:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.03it/s]\u001b[A\n","Epoch 391:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.47it/s]\u001b[A\n","Epoch 391:  90% 160/178 [00:20<00:02,  7.75it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.446, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.85it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.85it/s]\u001b[A\n","Epoch 391: 100% 178/178 [00:20<00:00,  8.57it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.684]\n","Epoch 392:   0% 0/178 [00:11<?, ?it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 392:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.87it/s]\u001b[A\n","Epoch 392:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.38it/s]\u001b[A\n","Epoch 392:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.99it/s]\u001b[A\n","Epoch 392:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.37it/s]\u001b[A\n","Epoch 392:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.45it/s]\u001b[A\n","Epoch 392:  67% 120/178 [00:20<00:09,  5.83it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.47it/s]\u001b[A\n","Epoch 392:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.73it/s]\u001b[A\n","Epoch 392:  90% 160/178 [00:20<00:02,  7.66it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.01it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.01it/s]\u001b[A\n","Epoch 392: 100% 178/178 [00:21<00:00,  8.47it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Epoch 393:   0% 0/178 [00:10<?, ?it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 393:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 104.61it/s]\u001b[A\n","Epoch 393:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.89it/s]\u001b[A\n","Epoch 393:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.92it/s]\u001b[A\n","Epoch 393:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 124.99it/s]\u001b[A\n","Epoch 393:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.59it/s]\u001b[A\n","Epoch 393:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.64it/s]\u001b[A\n","Epoch 393:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.38it/s]\u001b[A\n","Epoch 393:  90% 160/178 [00:20<00:02,  7.68it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.494, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.44it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.44it/s]\u001b[A\n","Epoch 393: 100% 178/178 [00:20<00:00,  8.50it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.689]\n","Epoch 394:   0% 0/178 [00:19<?, ?it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 394:  11% 20/178 [00:21<02:51,  1.09s/it, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 130.95it/s]\u001b[A\n","Epoch 394:  22% 40/178 [00:21<01:15,  1.83it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 138.07it/s]\u001b[A\n","Epoch 394:  34% 60/178 [00:21<00:43,  2.73it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.94it/s]\u001b[A\n","Epoch 394:  45% 80/178 [00:22<00:27,  3.61it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.46it/s]\u001b[A\n","Epoch 394:  56% 100/178 [00:22<00:17,  4.48it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.18it/s]\u001b[A\n","Epoch 394:  67% 120/178 [00:22<00:10,  5.35it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.78it/s]\u001b[A\n","Epoch 394:  79% 140/178 [00:22<00:06,  6.20it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.79it/s]\u001b[A\n","Epoch 394:  90% 160/178 [00:22<00:02,  7.04it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.458, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.02it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.02it/s]\u001b[A\n","Epoch 394: 100% 178/178 [00:22<00:00,  7.79it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.681]\n","Epoch 395:   0% 0/178 [00:16<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 395:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 121.58it/s]\u001b[A\n","Epoch 395:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 135.92it/s]\u001b[A\n","Epoch 395:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.97it/s]\u001b[A\n","Epoch 395:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 135.21it/s]\u001b[A\n","Epoch 395:  56% 100/178 [00:20<00:15,  4.91it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 137.15it/s]\u001b[A\n","Epoch 395:  67% 120/178 [00:20<00:09,  5.85it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 136.32it/s]\u001b[A\n","Epoch 395:  79% 140/178 [00:20<00:05,  6.78it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 137.88it/s]\u001b[A\n","Epoch 395:  90% 160/178 [00:20<00:02,  7.69it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.44it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.44it/s]\u001b[A\n","Epoch 395: 100% 178/178 [00:20<00:00,  8.51it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Epoch 396:   0% 0/178 [00:15<?, ?it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 396:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.79it/s]\u001b[A\n","Epoch 396:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.43it/s]\u001b[A\n","Epoch 396:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.93it/s]\u001b[A\n","Epoch 396:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.18it/s]\u001b[A\n","Epoch 396:  56% 100/178 [00:20<00:15,  4.93it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.46it/s]\u001b[A\n","Epoch 396:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.95it/s]\u001b[A\n","Epoch 396:  79% 140/178 [00:20<00:05,  6.81it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.64it/s]\u001b[A\n","Epoch 396:  90% 160/178 [00:20<00:02,  7.72it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.98it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.98it/s]\u001b[A\n","Epoch 396: 100% 178/178 [00:20<00:00,  8.54it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.210, train/acc=0.693]\n","Epoch 397:   0% 0/178 [00:14<?, ?it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 397:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.24it/s]\u001b[A\n","Epoch 397:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.55it/s]\u001b[A\n","Epoch 397:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.78it/s]\u001b[A\n","Epoch 397:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.07it/s]\u001b[A\n","Epoch 397:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.73it/s]\u001b[A\n","Epoch 397:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.33it/s]\u001b[A\n","Epoch 397:  79% 140/178 [00:20<00:05,  6.86it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.30it/s]\u001b[A\n","Epoch 397:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.27it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.27it/s]\u001b[A\n","Epoch 397: 100% 178/178 [00:20<00:00,  8.61it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.220, train/acc=0.682]\n","Epoch 398:   0% 0/178 [00:14<?, ?it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 398:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.61it/s]\u001b[A\n","Epoch 398:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.34it/s]\u001b[A\n","Epoch 398:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.09it/s]\u001b[A\n","Epoch 398:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.31it/s]\u001b[A\n","Epoch 398:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.74it/s]\u001b[A\n","Epoch 398:  67% 120/178 [00:20<00:09,  5.94it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.62it/s]\u001b[A\n","Epoch 398:  79% 140/178 [00:20<00:05,  6.88it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 136.81it/s]\u001b[A\n","Epoch 398:  90% 160/178 [00:20<00:02,  7.80it/s, loss=1.21, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.16it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.16it/s]\u001b[A\n","Epoch 398: 100% 178/178 [00:20<00:00,  8.63it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.693]\n","Epoch 399:   0% 0/178 [00:13<?, ?it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 399:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.86it/s]\u001b[A\n","Epoch 399:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.72it/s]\u001b[A\n","Epoch 399:  34% 60/178 [00:20<00:40,  2.95it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.85it/s]\u001b[A\n","Epoch 399:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.40it/s]\u001b[A\n","Epoch 399:  56% 100/178 [00:20<00:16,  4.84it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.59it/s]\u001b[A\n","Epoch 399:  67% 120/178 [00:20<00:10,  5.77it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.64it/s]\u001b[A\n","Epoch 399:  79% 140/178 [00:20<00:05,  6.68it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.46it/s]\u001b[A\n","Epoch 399:  90% 160/178 [00:21<00:02,  7.58it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.35it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.35it/s]\u001b[A\n","Epoch 399: 100% 178/178 [00:21<00:00,  8.39it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.692]\n","Epoch 400:   0% 0/178 [00:12<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 400:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 126.98it/s]\u001b[A\n","Epoch 400:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 136.33it/s]\u001b[A\n","Epoch 400:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.81it/s]\u001b[A\n","Epoch 400:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.83it/s]\u001b[A\n","Epoch 400:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.56it/s]\u001b[A\n","Epoch 400:  67% 120/178 [00:20<00:09,  5.83it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.10it/s]\u001b[A\n","Epoch 400:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.80it/s]\u001b[A\n","Epoch 400:  90% 160/178 [00:20<00:02,  7.66it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.230, train/acc=0.672]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.48it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.48it/s]\u001b[A\n","Epoch 400: 100% 178/178 [00:20<00:00,  8.48it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.230, train/acc=0.672]\n","Epoch 401:   0% 0/178 [00:11<?, ?it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 401:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.45it/s]\u001b[A\n","Epoch 401:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.22it/s]\u001b[A\n","Epoch 401:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.24it/s]\u001b[A\n","Epoch 401:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.29it/s]\u001b[A\n","Epoch 401:  56% 100/178 [00:20<00:16,  4.84it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.79it/s]\u001b[A\n","Epoch 401:  67% 120/178 [00:20<00:10,  5.76it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.95it/s]\u001b[A\n","Epoch 401:  79% 140/178 [00:20<00:05,  6.67it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.74it/s]\u001b[A\n","Epoch 401:  90% 160/178 [00:21<00:02,  7.57it/s, loss=1.24, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.240, train/acc=0.656]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.54it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.54it/s]\u001b[A\n","Epoch 401: 100% 178/178 [00:21<00:00,  8.38it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.240, train/acc=0.656]\n","Epoch 402:   0% 0/178 [00:00<?, ?it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 402:  11% 20/178 [00:19<02:30,  1.05it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.82it/s]\u001b[A\n","Epoch 402:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.02it/s]\u001b[A\n","Epoch 402:  34% 60/178 [00:19<00:38,  3.10it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.78it/s]\u001b[A\n","Epoch 402:  45% 80/178 [00:19<00:23,  4.11it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 133.05it/s]\u001b[A\n","Epoch 402:  56% 100/178 [00:19<00:15,  5.09it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.33it/s]\u001b[A\n","Epoch 402:  67% 120/178 [00:19<00:09,  6.06it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.90it/s]\u001b[A\n","Epoch 402:  79% 140/178 [00:19<00:05,  7.02it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.84it/s]\u001b[A\n","Epoch 402:  90% 160/178 [00:20<00:02,  7.96it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.678]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.68it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.68it/s]\u001b[A\n","Epoch 402: 100% 178/178 [00:20<00:00,  8.81it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.230, train/acc=0.678]\n","Epoch 403:   0% 0/178 [00:00<?, ?it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Epoch 403:   0% 0/178 [00:19<?, ?it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 403:  11% 20/178 [00:19<02:37,  1.01it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 116.20it/s]\u001b[A\n","Epoch 403:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.44it/s]\u001b[A\n","Epoch 403:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.15it/s]\u001b[A\n","Epoch 403:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.97it/s]\u001b[A\n","Epoch 403:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.41it/s]\u001b[A\n","Epoch 403:  67% 120/178 [00:20<00:09,  5.82it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.43it/s]\u001b[A\n","Epoch 403:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.06it/s]\u001b[A\n","Epoch 403:  90% 160/178 [00:20<00:02,  7.66it/s, loss=1.22, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.19it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.19it/s]\u001b[A\n","Epoch 403: 100% 178/178 [00:21<00:00,  8.47it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.685]\n","Epoch 404:   0% 0/178 [00:18<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 404:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.26it/s]\u001b[A\n","Epoch 404:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.24it/s]\u001b[A\n","Epoch 404:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.28it/s]\u001b[A\n","Epoch 404:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.45it/s]\u001b[A\n","Epoch 404:  56% 100/178 [00:19<00:15,  5.00it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 127.87it/s]\u001b[A\n","Epoch 404:  67% 120/178 [00:20<00:09,  5.96it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.89it/s]\u001b[A\n","Epoch 404:  79% 140/178 [00:20<00:05,  6.90it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.12it/s]\u001b[A\n","Epoch 404:  90% 160/178 [00:20<00:02,  7.83it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.506, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.93it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.93it/s]\u001b[A\n","Epoch 404: 100% 178/178 [00:20<00:00,  8.66it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.220, train/acc=0.680]\n","                                                               \u001b[AMetric train/loss improved by 0.007 >= min_delta = 0.0. New best score: 1.198\n","Epoch 405:   0% 0/178 [00:17<?, ?it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 405:  11% 20/178 [00:19<02:32,  1.04it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 143.17it/s]\u001b[A\n","Epoch 405:  22% 40/178 [00:19<01:06,  2.06it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 137.90it/s]\u001b[A\n","Epoch 405:  34% 60/178 [00:19<00:38,  3.07it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.64it/s]\u001b[A\n","Epoch 405:  45% 80/178 [00:19<00:24,  4.06it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.58it/s]\u001b[A\n","Epoch 405:  56% 100/178 [00:19<00:15,  5.03it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.11it/s]\u001b[A\n","Epoch 405:  67% 120/178 [00:20<00:09,  6.00it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.94it/s]\u001b[A\n","Epoch 405:  79% 140/178 [00:20<00:05,  6.95it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 137.43it/s]\u001b[A\n","Epoch 405:  90% 160/178 [00:20<00:02,  7.88it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.711]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.28it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.28it/s]\u001b[A\n","Epoch 405: 100% 178/178 [00:20<00:00,  8.72it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.200, train/acc=0.711]\n","Epoch 406:   0% 0/178 [00:17<?, ?it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 406:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:00, 151.47it/s]\u001b[A\n","Epoch 406:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 143.06it/s]\u001b[A\n","Epoch 406:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.14it/s]\u001b[A\n","Epoch 406:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 136.66it/s]\u001b[A\n","Epoch 406:  56% 100/178 [00:20<00:15,  5.00it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 137.51it/s]\u001b[A\n","Epoch 406:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.22it/s]\u001b[A\n","Epoch 406:  79% 140/178 [00:20<00:05,  6.90it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 136.34it/s]\u001b[A\n","Epoch 406:  90% 160/178 [00:20<00:02,  7.82it/s, loss=1.21, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.220, train/acc=0.681]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.22it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.22it/s]\u001b[A\n","Epoch 406: 100% 178/178 [00:20<00:00,  8.65it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.681]\n","Epoch 407:   0% 0/178 [00:16<?, ?it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 407:  11% 20/178 [00:20<02:45,  1.04s/it, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.32it/s]\u001b[A\n","Epoch 407:  22% 40/178 [00:21<01:12,  1.90it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.06it/s]\u001b[A\n","Epoch 407:  34% 60/178 [00:21<00:41,  2.83it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.48it/s]\u001b[A\n","Epoch 407:  45% 80/178 [00:21<00:26,  3.75it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.84it/s]\u001b[A\n","Epoch 407:  56% 100/178 [00:21<00:16,  4.66it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.48it/s]\u001b[A\n","Epoch 407:  67% 120/178 [00:21<00:10,  5.55it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.24it/s]\u001b[A\n","Epoch 407:  79% 140/178 [00:21<00:05,  6.43it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.53it/s]\u001b[A\n","Epoch 407:  90% 160/178 [00:21<00:02,  7.29it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.98it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.98it/s]\u001b[A\n","Epoch 407: 100% 178/178 [00:22<00:00,  8.07it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.671]\n","Epoch 408:   0% 0/178 [00:14<?, ?it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 408:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 119.80it/s]\u001b[A\n","Epoch 408:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.29it/s]\u001b[A\n","Epoch 408:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.63it/s]\u001b[A\n","Epoch 408:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.33it/s]\u001b[A\n","Epoch 408:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.59it/s]\u001b[A\n","Epoch 408:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.13it/s]\u001b[A\n","Epoch 408:  79% 140/178 [00:20<00:05,  6.86it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.12it/s]\u001b[A\n","Epoch 408:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.23, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.92it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.92it/s]\u001b[A\n","Epoch 408: 100% 178/178 [00:20<00:00,  8.60it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.230, train/acc=0.675]\n","Epoch 409:   0% 0/178 [00:14<?, ?it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 409:  11% 20/178 [00:20<02:40,  1.02s/it, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 118.42it/s]\u001b[A\n","Epoch 409:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.18it/s]\u001b[A\n","Epoch 409:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.12it/s]\u001b[A\n","Epoch 409:  45% 80/178 [00:20<00:25,  3.85it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.35it/s]\u001b[A\n","Epoch 409:  56% 100/178 [00:20<00:16,  4.77it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.15it/s]\u001b[A\n","Epoch 409:  67% 120/178 [00:21<00:10,  5.69it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.90it/s]\u001b[A\n","Epoch 409:  79% 140/178 [00:21<00:05,  6.59it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.04it/s]\u001b[A\n","Epoch 409:  90% 160/178 [00:21<00:02,  7.47it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.35it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.35it/s]\u001b[A\n","Epoch 409: 100% 178/178 [00:21<00:00,  8.27it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.220, train/acc=0.682]\n","Epoch 410:   0% 0/178 [00:12<?, ?it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 410:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 129.49it/s]\u001b[A\n","Epoch 410:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.01it/s]\u001b[A\n","Epoch 410:  34% 60/178 [00:20<00:40,  2.95it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.27it/s]\u001b[A\n","Epoch 410:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.12it/s]\u001b[A\n","Epoch 410:  56% 100/178 [00:20<00:16,  4.84it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.46it/s]\u001b[A\n","Epoch 410:  67% 120/178 [00:20<00:10,  5.77it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.93it/s]\u001b[A\n","Epoch 410:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.99it/s]\u001b[A\n","Epoch 410:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.22, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.32it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.32it/s]\u001b[A\n","Epoch 410: 100% 178/178 [00:21<00:00,  8.39it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Epoch 411:   0% 0/178 [00:11<?, ?it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 411:  11% 20/178 [00:19<02:37,  1.01it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 118.28it/s]\u001b[A\n","Epoch 411:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.84it/s]\u001b[A\n","Epoch 411:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.36it/s]\u001b[A\n","Epoch 411:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.52it/s]\u001b[A\n","Epoch 411:  56% 100/178 [00:20<00:15,  4.88it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.26it/s]\u001b[A\n","Epoch 411:  67% 120/178 [00:20<00:09,  5.81it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.75it/s]\u001b[A\n","Epoch 411:  79% 140/178 [00:20<00:05,  6.74it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.33it/s]\u001b[A\n","Epoch 411:  90% 160/178 [00:20<00:02,  7.64it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.17it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.17it/s]\u001b[A\n","Epoch 411: 100% 178/178 [00:21<00:00,  8.46it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.689]\n","Epoch 412:   0% 0/178 [00:10<?, ?it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 412:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 127.95it/s]\u001b[A\n","Epoch 412:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.55it/s]\u001b[A\n","Epoch 412:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.12it/s]\u001b[A\n","Epoch 412:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.81it/s]\u001b[A\n","Epoch 412:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.20it/s]\u001b[A\n","Epoch 412:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.35it/s]\u001b[A\n","Epoch 412:  79% 140/178 [00:20<00:05,  6.80it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.59it/s]\u001b[A\n","Epoch 412:  90% 160/178 [00:20<00:02,  7.72it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.674]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.45it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.45it/s]\u001b[A\n","Epoch 412: 100% 178/178 [00:20<00:00,  8.54it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.674]\n","Epoch 413:   0% 0/178 [00:19<?, ?it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 413:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 109.12it/s]\u001b[A\n","Epoch 413:  22% 40/178 [00:20<01:10,  1.94it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.66it/s]\u001b[A\n","Epoch 413:  34% 60/178 [00:20<00:40,  2.90it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.92it/s]\u001b[A\n","Epoch 413:  45% 80/178 [00:20<00:25,  3.83it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.01it/s]\u001b[A\n","Epoch 413:  56% 100/178 [00:21<00:16,  4.76it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.41it/s]\u001b[A\n","Epoch 413:  67% 120/178 [00:21<00:10,  5.67it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.41it/s]\u001b[A\n","Epoch 413:  79% 140/178 [00:21<00:05,  6.57it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.51it/s]\u001b[A\n","Epoch 413:  90% 160/178 [00:21<00:02,  7.46it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.86it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.86it/s]\u001b[A\n","Epoch 413: 100% 178/178 [00:21<00:00,  8.25it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.220, train/acc=0.685]\n","Epoch 414:   0% 0/178 [00:17<?, ?it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 414:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.43it/s]\u001b[A\n","Epoch 414:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.06it/s]\u001b[A\n","Epoch 414:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.79it/s]\u001b[A\n","Epoch 414:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.78it/s]\u001b[A\n","Epoch 414:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.18it/s]\u001b[A\n","Epoch 414:  67% 120/178 [00:20<00:09,  5.94it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.11it/s]\u001b[A\n","Epoch 414:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.14it/s]\u001b[A\n","Epoch 414:  90% 160/178 [00:20<00:02,  7.80it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.230, train/acc=0.673]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.23it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.23it/s]\u001b[A\n","Epoch 414: 100% 178/178 [00:20<00:00,  8.62it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.673]\n","Epoch 415:   0% 0/178 [00:17<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 415:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 113.62it/s]\u001b[A\n","Epoch 415:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.48it/s]\u001b[A\n","Epoch 415:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.99it/s]\u001b[A\n","Epoch 415:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.55it/s]\u001b[A\n","Epoch 415:  56% 100/178 [00:20<00:15,  4.88it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.92it/s]\u001b[A\n","Epoch 415:  67% 120/178 [00:20<00:09,  5.81it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.87it/s]\u001b[A\n","Epoch 415:  79% 140/178 [00:20<00:05,  6.73it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.81it/s]\u001b[A\n","Epoch 415:  90% 160/178 [00:20<00:02,  7.64it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.482, train/loss=1.230, train/acc=0.676]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.30it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.30it/s]\u001b[A\n","Epoch 415: 100% 178/178 [00:21<00:00,  8.45it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.230, train/acc=0.676]\n","Epoch 416:   0% 0/178 [00:16<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 416:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.59it/s]\u001b[A\n","Epoch 416:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.00it/s]\u001b[A\n","Epoch 416:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.21it/s]\u001b[A\n","Epoch 416:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.03it/s]\u001b[A\n","Epoch 416:  56% 100/178 [00:20<00:15,  4.93it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.49it/s]\u001b[A\n","Epoch 416:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.87it/s]\u001b[A\n","Epoch 416:  79% 140/178 [00:20<00:05,  6.81it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.74it/s]\u001b[A\n","Epoch 416:  90% 160/178 [00:20<00:02,  7.72it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.14it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.14it/s]\u001b[A\n","Epoch 416: 100% 178/178 [00:20<00:00,  8.55it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.686]\n","Epoch 417:   0% 0/178 [00:15<?, ?it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 417:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 127.18it/s]\u001b[A\n","Epoch 417:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.35it/s]\u001b[A\n","Epoch 417:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.96it/s]\u001b[A\n","Epoch 417:  45% 80/178 [00:19<00:24,  4.00it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.58it/s]\u001b[A\n","Epoch 417:  56% 100/178 [00:20<00:15,  4.96it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.73it/s]\u001b[A\n","Epoch 417:  67% 120/178 [00:20<00:09,  5.91it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 136.13it/s]\u001b[A\n","Epoch 417:  79% 140/178 [00:20<00:05,  6.85it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.29it/s]\u001b[A\n","Epoch 417:  90% 160/178 [00:20<00:02,  7.77it/s, loss=1.23, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.679]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.12it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.12it/s]\u001b[A\n","Epoch 417: 100% 178/178 [00:20<00:00,  8.59it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.679]\n","Epoch 418:   0% 0/178 [00:14<?, ?it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 418:  11% 20/178 [00:19<02:31,  1.05it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.78it/s]\u001b[A\n","Epoch 418:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.97it/s]\u001b[A\n","Epoch 418:  34% 60/178 [00:19<00:38,  3.09it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.84it/s]\u001b[A\n","Epoch 418:  45% 80/178 [00:19<00:23,  4.09it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.19it/s]\u001b[A\n","Epoch 418:  56% 100/178 [00:19<00:15,  5.07it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.51it/s]\u001b[A\n","Epoch 418:  67% 120/178 [00:19<00:09,  6.04it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.03it/s]\u001b[A\n","Epoch 418:  79% 140/178 [00:20<00:05,  7.00it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.86it/s]\u001b[A\n","Epoch 418:  90% 160/178 [00:20<00:02,  7.94it/s, loss=1.24, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.240, train/acc=0.664]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.74it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.74it/s]\u001b[A\n","Epoch 418: 100% 178/178 [00:20<00:00,  8.78it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.240, train/acc=0.664]\n","Epoch 419:   0% 0/178 [00:14<?, ?it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 419:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.29it/s]\u001b[A\n","Epoch 419:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 120.75it/s]\u001b[A\n","Epoch 419:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.13it/s]\u001b[A\n","Epoch 419:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.73it/s]\u001b[A\n","Epoch 419:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.18it/s]\u001b[A\n","Epoch 419:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.75it/s]\u001b[A\n","Epoch 419:  79% 140/178 [00:20<00:05,  6.86it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.34it/s]\u001b[A\n","Epoch 419:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.434, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.93it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.93it/s]\u001b[A\n","Epoch 419: 100% 178/178 [00:20<00:00,  8.61it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.220, train/acc=0.688]\n","Epoch 420:   0% 0/178 [00:13<?, ?it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 420:  11% 20/178 [00:21<02:48,  1.06s/it, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.31it/s]\u001b[A\n","Epoch 420:  22% 40/178 [00:21<01:13,  1.87it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 119.27it/s]\u001b[A\n","Epoch 420:  34% 60/178 [00:21<00:42,  2.78it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.93it/s]\u001b[A\n","Epoch 420:  45% 80/178 [00:21<00:26,  3.69it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.62it/s]\u001b[A\n","Epoch 420:  56% 100/178 [00:21<00:17,  4.58it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.94it/s]\u001b[A\n","Epoch 420:  67% 120/178 [00:21<00:10,  5.45it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.97it/s]\u001b[A\n","Epoch 420:  79% 140/178 [00:22<00:06,  6.32it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.43it/s]\u001b[A\n","Epoch 420:  90% 160/178 [00:22<00:02,  7.18it/s, loss=1.23, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.43it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.43it/s]\u001b[A\n","Epoch 420: 100% 178/178 [00:22<00:00,  7.94it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.230, train/acc=0.675]\n","Epoch 421:   0% 0/178 [00:11<?, ?it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 421:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 119.97it/s]\u001b[A\n","Epoch 421:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.50it/s]\u001b[A\n","Epoch 421:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.37it/s]\u001b[A\n","Epoch 421:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.76it/s]\u001b[A\n","Epoch 421:  56% 100/178 [00:20<00:15,  4.88it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.66it/s]\u001b[A\n","Epoch 421:  67% 120/178 [00:20<00:09,  5.81it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.70it/s]\u001b[A\n","Epoch 421:  79% 140/178 [00:20<00:05,  6.73it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.47it/s]\u001b[A\n","Epoch 421:  90% 160/178 [00:20<00:02,  7.64it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.524, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.40it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.40it/s]\u001b[A\n","Epoch 421: 100% 178/178 [00:21<00:00,  8.45it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.210, train/acc=0.691]\n","Epoch 422:   0% 0/178 [00:19<?, ?it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 422:  11% 20/178 [00:20<02:40,  1.02s/it, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 141.92it/s]\u001b[A\n","Epoch 422:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 138.17it/s]\u001b[A\n","Epoch 422:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 136.21it/s]\u001b[A\n","Epoch 422:  45% 80/178 [00:20<00:25,  3.85it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.37it/s]\u001b[A\n","Epoch 422:  56% 100/178 [00:20<00:16,  4.78it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.32it/s]\u001b[A\n","Epoch 422:  67% 120/178 [00:21<00:10,  5.69it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.40it/s]\u001b[A\n","Epoch 422:  79% 140/178 [00:21<00:05,  6.60it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.51it/s]\u001b[A\n","Epoch 422:  90% 160/178 [00:21<00:02,  7.48it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.446, train/loss=1.220, train/acc=0.690]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.72it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.72it/s]\u001b[A\n","Epoch 422: 100% 178/178 [00:21<00:00,  8.28it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.690]\n","Epoch 423:   0% 0/178 [00:18<?, ?it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 423:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 99.76it/s]\u001b[A\n","Epoch 423:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.66it/s]\u001b[A\n","Epoch 423:  34% 60/178 [00:19<00:38,  3.09it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.73it/s]\u001b[A\n","Epoch 423:  45% 80/178 [00:19<00:23,  4.09it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.99it/s]\u001b[A\n","Epoch 423:  56% 100/178 [00:19<00:15,  5.07it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.92it/s]\u001b[A\n","Epoch 423:  67% 120/178 [00:19<00:09,  6.03it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.90it/s]\u001b[A\n","Epoch 423:  79% 140/178 [00:20<00:05,  6.99it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.67it/s]\u001b[A\n","Epoch 423:  90% 160/178 [00:20<00:02,  7.92it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.72it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.72it/s]\u001b[A\n","Epoch 423: 100% 178/178 [00:20<00:00,  8.77it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Epoch 424:   0% 0/178 [00:18<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 424:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 102.24it/s]\u001b[A\n","Epoch 424:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.24it/s]\u001b[A\n","Epoch 424:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.20it/s]\u001b[A\n","Epoch 424:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.83it/s]\u001b[A\n","Epoch 424:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.28it/s]\u001b[A\n","Epoch 424:  67% 120/178 [00:20<00:09,  5.81it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.23it/s]\u001b[A\n","Epoch 424:  79% 140/178 [00:20<00:05,  6.73it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.71it/s]\u001b[A\n","Epoch 424:  90% 160/178 [00:20<00:02,  7.63it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.88it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.88it/s]\u001b[A\n","Epoch 424: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.682]\n","Epoch 425:   0% 0/178 [00:16<?, ?it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 425:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 123.77it/s]\u001b[A\n","Epoch 425:  22% 40/178 [00:20<01:11,  1.94it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.76it/s]\u001b[A\n","Epoch 425:  34% 60/178 [00:20<00:40,  2.88it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.13it/s]\u001b[A\n","Epoch 425:  45% 80/178 [00:20<00:25,  3.81it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.34it/s]\u001b[A\n","Epoch 425:  56% 100/178 [00:21<00:16,  4.73it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.13it/s]\u001b[A\n","Epoch 425:  67% 120/178 [00:21<00:10,  5.64it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.69it/s]\u001b[A\n","Epoch 425:  79% 140/178 [00:21<00:05,  6.53it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.31it/s]\u001b[A\n","Epoch 425:  90% 160/178 [00:21<00:02,  7.41it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.46it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.46it/s]\u001b[A\n","Epoch 425: 100% 178/178 [00:21<00:00,  8.20it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.695]\n","Epoch 426:   0% 0/178 [00:15<?, ?it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 426:  11% 20/178 [00:21<02:47,  1.06s/it, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.58it/s]\u001b[A\n","Epoch 426:  22% 40/178 [00:21<01:13,  1.87it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.53it/s]\u001b[A\n","Epoch 426:  34% 60/178 [00:21<00:42,  2.79it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.62it/s]\u001b[A\n","Epoch 426:  45% 80/178 [00:21<00:26,  3.69it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.30it/s]\u001b[A\n","Epoch 426:  56% 100/178 [00:21<00:17,  4.58it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.21it/s]\u001b[A\n","Epoch 426:  67% 120/178 [00:21<00:10,  5.46it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.93it/s]\u001b[A\n","Epoch 426:  79% 140/178 [00:22<00:06,  6.33it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.89it/s]\u001b[A\n","Epoch 426:  90% 160/178 [00:22<00:02,  7.18it/s, loss=1.21, v_num=2, val/loss=1.510, Val/acc=0.380, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.86it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.86it/s]\u001b[A\n","Epoch 426: 100% 178/178 [00:22<00:00,  7.95it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.693]\n","Epoch 427:   0% 0/178 [00:12<?, ?it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 427:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.25it/s]\u001b[A\n","Epoch 427:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.26it/s]\u001b[A\n","Epoch 427:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.36it/s]\u001b[A\n","Epoch 427:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.18it/s]\u001b[A\n","Epoch 427:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.28it/s]\u001b[A\n","Epoch 427:  67% 120/178 [00:20<00:09,  5.83it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.06it/s]\u001b[A\n","Epoch 427:  79% 140/178 [00:20<00:05,  6.76it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.40it/s]\u001b[A\n","Epoch 427:  90% 160/178 [00:20<00:02,  7.67it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.705]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.08it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.08it/s]\u001b[A\n","Epoch 427: 100% 178/178 [00:20<00:00,  8.48it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.705] \n","Epoch 428:   0% 0/178 [00:11<?, ?it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 428:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.01it/s]\u001b[A\n","Epoch 428:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.95it/s]\u001b[A\n","Epoch 428:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.04it/s]\u001b[A\n","Epoch 428:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.58it/s]\u001b[A\n","Epoch 428:  56% 100/178 [00:20<00:15,  4.92it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.32it/s]\u001b[A\n","Epoch 428:  67% 120/178 [00:20<00:09,  5.87it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.38it/s]\u001b[A\n","Epoch 428:  79% 140/178 [00:20<00:05,  6.80it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.91it/s]\u001b[A\n","Epoch 428:  90% 160/178 [00:20<00:02,  7.71it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.500, train/loss=1.200, train/acc=0.706]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.29it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.29it/s]\u001b[A\n","Epoch 428: 100% 178/178 [00:20<00:00,  8.53it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.706]\n","                                                               \u001b[AMetric train/loss improved by 0.002 >= min_delta = 0.0. New best score: 1.196\n","Epoch 429:   0% 0/178 [00:10<?, ?it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 429:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.24it/s]\u001b[A\n","Epoch 429:  22% 40/178 [00:20<01:11,  1.94it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.43it/s]\u001b[A\n","Epoch 429:  34% 60/178 [00:20<00:40,  2.89it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.58it/s]\u001b[A\n","Epoch 429:  45% 80/178 [00:20<00:25,  3.83it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.71it/s]\u001b[A\n","Epoch 429:  56% 100/178 [00:21<00:16,  4.75it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.84it/s]\u001b[A\n","Epoch 429:  67% 120/178 [00:21<00:10,  5.66it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.74it/s]\u001b[A\n","Epoch 429:  79% 140/178 [00:21<00:05,  6.56it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.85it/s]\u001b[A\n","Epoch 429:  90% 160/178 [00:21<00:02,  7.45it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.512, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.96it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.96it/s]\u001b[A\n","Epoch 429: 100% 178/178 [00:21<00:00,  8.24it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.710]\n","Epoch 430:   0% 0/178 [00:00<?, ?it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Epoch 430:   0% 0/178 [00:19<?, ?it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 430:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.03it/s]\u001b[A\n","Epoch 430:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.02it/s]\u001b[A\n","Epoch 430:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.67it/s]\u001b[A\n","Epoch 430:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.76it/s]\u001b[A\n","Epoch 430:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.70it/s]\u001b[A\n","Epoch 430:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.74it/s]\u001b[A\n","Epoch 430:  79% 140/178 [00:20<00:05,  6.86it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.81it/s]\u001b[A\n","Epoch 430:  90% 160/178 [00:20<00:02,  7.78it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.54it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.54it/s]\u001b[A\n","Epoch 430: 100% 178/178 [00:20<00:00,  8.60it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.698]\n","Epoch 431:   0% 0/178 [00:18<?, ?it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 431:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 124.82it/s]\u001b[A\n","Epoch 431:  22% 40/178 [00:20<01:09,  1.97it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.30it/s]\u001b[A\n","Epoch 431:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.91it/s]\u001b[A\n","Epoch 431:  45% 80/178 [00:20<00:25,  3.89it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.93it/s]\u001b[A\n","Epoch 431:  56% 100/178 [00:20<00:16,  4.83it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.84it/s]\u001b[A\n","Epoch 431:  67% 120/178 [00:20<00:10,  5.75it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.95it/s]\u001b[A\n","Epoch 431:  79% 140/178 [00:21<00:05,  6.66it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.00it/s]\u001b[A\n","Epoch 431:  90% 160/178 [00:21<00:02,  7.55it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.90it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.90it/s]\u001b[A\n","Epoch 431: 100% 178/178 [00:21<00:00,  8.35it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.210, train/acc=0.690]\n","Epoch 432:   0% 0/178 [00:17<?, ?it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 432:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 123.81it/s]\u001b[A\n","Epoch 432:  22% 40/178 [00:20<01:11,  1.94it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.90it/s]\u001b[A\n","Epoch 432:  34% 60/178 [00:20<00:40,  2.89it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.01it/s]\u001b[A\n","Epoch 432:  45% 80/178 [00:20<00:25,  3.82it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.67it/s]\u001b[A\n","Epoch 432:  56% 100/178 [00:21<00:16,  4.74it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.81it/s]\u001b[A\n","Epoch 432:  67% 120/178 [00:21<00:10,  5.65it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.85it/s]\u001b[A\n","Epoch 432:  79% 140/178 [00:21<00:05,  6.55it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.57it/s]\u001b[A\n","Epoch 432:  90% 160/178 [00:21<00:02,  7.43it/s, loss=1.22, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.64it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.64it/s]\u001b[A\n","Epoch 432: 100% 178/178 [00:21<00:00,  8.22it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.220, train/acc=0.682]\n","Epoch 433:   0% 0/178 [00:15<?, ?it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 433:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 113.14it/s]\u001b[A\n","Epoch 433:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.96it/s]\u001b[A\n","Epoch 433:  34% 60/178 [00:19<00:38,  3.08it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.87it/s]\u001b[A\n","Epoch 433:  45% 80/178 [00:19<00:24,  4.08it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.45it/s]\u001b[A\n","Epoch 433:  56% 100/178 [00:19<00:15,  5.06it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.93it/s]\u001b[A\n","Epoch 433:  67% 120/178 [00:19<00:09,  6.02it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 127.38it/s]\u001b[A\n","Epoch 433:  79% 140/178 [00:20<00:05,  6.97it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.46it/s]\u001b[A\n","Epoch 433:  90% 160/178 [00:20<00:02,  7.90it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.458, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.07it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.07it/s]\u001b[A\n","Epoch 433: 100% 178/178 [00:20<00:00,  8.74it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.695]\n","Epoch 434:   0% 0/178 [00:15<?, ?it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 434:  11% 20/178 [00:20<02:41,  1.02s/it, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 114.65it/s]\u001b[A\n","Epoch 434:  22% 40/178 [00:20<01:10,  1.95it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.00it/s]\u001b[A\n","Epoch 434:  34% 60/178 [00:20<00:40,  2.90it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.07it/s]\u001b[A\n","Epoch 434:  45% 80/178 [00:20<00:25,  3.84it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.66it/s]\u001b[A\n","Epoch 434:  56% 100/178 [00:20<00:16,  4.76it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.23it/s]\u001b[A\n","Epoch 434:  67% 120/178 [00:21<00:10,  5.68it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.97it/s]\u001b[A\n","Epoch 434:  79% 140/178 [00:21<00:05,  6.57it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.70it/s]\u001b[A\n","Epoch 434:  90% 160/178 [00:21<00:02,  7.46it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.36it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.36it/s]\u001b[A\n","Epoch 434: 100% 178/178 [00:21<00:00,  8.26it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.210, train/acc=0.697] \n","Epoch 435:   0% 0/178 [00:13<?, ?it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 435:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.97it/s]\u001b[A\n","Epoch 435:  22% 40/178 [00:20<01:10,  1.97it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.36it/s]\u001b[A\n","Epoch 435:  34% 60/178 [00:20<00:40,  2.93it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.78it/s]\u001b[A\n","Epoch 435:  45% 80/178 [00:20<00:25,  3.88it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.75it/s]\u001b[A\n","Epoch 435:  56% 100/178 [00:20<00:16,  4.82it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.37it/s]\u001b[A\n","Epoch 435:  67% 120/178 [00:20<00:10,  5.74it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.92it/s]\u001b[A\n","Epoch 435:  79% 140/178 [00:21<00:05,  6.65it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.35it/s]\u001b[A\n","Epoch 435:  90% 160/178 [00:21<00:02,  7.54it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.19it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.19it/s]\u001b[A\n","Epoch 435: 100% 178/178 [00:21<00:00,  8.35it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.702]\n","Epoch 436:   0% 0/178 [00:12<?, ?it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 436:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 102.78it/s]\u001b[A\n","Epoch 436:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 120.74it/s]\u001b[A\n","Epoch 436:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.54it/s]\u001b[A\n","Epoch 436:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.91it/s]\u001b[A\n","Epoch 436:  56% 100/178 [00:19<00:15,  5.01it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 125.49it/s]\u001b[A\n","Epoch 436:  67% 120/178 [00:20<00:09,  5.96it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.22it/s]\u001b[A\n","Epoch 436:  79% 140/178 [00:20<00:05,  6.90it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.89it/s]\u001b[A\n","Epoch 436:  90% 160/178 [00:20<00:02,  7.83it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.440, train/loss=1.200, train/acc=0.698]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.31it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.31it/s]\u001b[A\n","Epoch 436: 100% 178/178 [00:20<00:00,  8.66it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.200, train/acc=0.698]\n","Epoch 437:   0% 0/178 [00:11<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 437:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 96.70it/s]\u001b[A\n","Epoch 437:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 116.60it/s]\u001b[A\n","Epoch 437:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 121.54it/s]\u001b[A\n","Epoch 437:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 124.91it/s]\u001b[A\n","Epoch 437:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 127.68it/s]\u001b[A\n","Epoch 437:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 127.68it/s]\u001b[A\n","Epoch 437:  79% 140/178 [00:20<00:05,  6.82it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.59it/s]\u001b[A\n","Epoch 437:  90% 160/178 [00:20<00:02,  7.73it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.75it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.75it/s]\u001b[A\n","Epoch 437: 100% 178/178 [00:20<00:00,  8.55it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.210, train/acc=0.694]\n","Epoch 438:   0% 0/178 [00:10<?, ?it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 438:  11% 20/178 [00:20<02:44,  1.04s/it, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.73it/s]\u001b[A\n","Epoch 438:  22% 40/178 [00:21<01:12,  1.90it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.31it/s]\u001b[A\n","Epoch 438:  34% 60/178 [00:21<00:41,  2.84it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.95it/s]\u001b[A\n","Epoch 438:  45% 80/178 [00:21<00:26,  3.76it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.27it/s]\u001b[A\n","Epoch 438:  56% 100/178 [00:21<00:16,  4.66it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.02it/s]\u001b[A\n","Epoch 438:  67% 120/178 [00:21<00:10,  5.55it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.20it/s]\u001b[A\n","Epoch 438:  79% 140/178 [00:21<00:05,  6.43it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.49it/s]\u001b[A\n","Epoch 438:  90% 160/178 [00:21<00:02,  7.30it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.518, train/loss=1.230, train/acc=0.677]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.17it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.17it/s]\u001b[A\n","Epoch 438: 100% 178/178 [00:22<00:00,  8.07it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.230, train/acc=0.677]\n","Epoch 439:   0% 0/178 [00:18<?, ?it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 439:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 121.56it/s]\u001b[A\n","Epoch 439:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 129.72it/s]\u001b[A\n","Epoch 439:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.54it/s]\u001b[A\n","Epoch 439:  45% 80/178 [00:20<00:24,  3.92it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.98it/s]\u001b[A\n","Epoch 439:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.57it/s]\u001b[A\n","Epoch 439:  67% 120/178 [00:20<00:09,  5.80it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 136.75it/s]\u001b[A\n","Epoch 439:  79% 140/178 [00:20<00:05,  6.72it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.01it/s]\u001b[A\n","Epoch 439:  90% 160/178 [00:20<00:02,  7.63it/s, loss=1.22, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.70it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.70it/s]\u001b[A\n","Epoch 439: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.685]\n","Epoch 440:   0% 0/178 [00:17<?, ?it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 440:  11% 20/178 [00:20<02:38,  1.01s/it, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.37it/s]\u001b[A\n","Epoch 440:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.73it/s]\u001b[A\n","Epoch 440:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.86it/s]\u001b[A\n","Epoch 440:  45% 80/178 [00:20<00:25,  3.90it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.08it/s]\u001b[A\n","Epoch 440:  56% 100/178 [00:20<00:16,  4.83it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.92it/s]\u001b[A\n","Epoch 440:  67% 120/178 [00:20<00:10,  5.76it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.30it/s]\u001b[A\n","Epoch 440:  79% 140/178 [00:20<00:05,  6.67it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.81it/s]\u001b[A\n","Epoch 440:  90% 160/178 [00:21<00:02,  7.57it/s, loss=1.23, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.33it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.33it/s]\u001b[A\n","Epoch 440: 100% 178/178 [00:21<00:00,  8.38it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.220, train/acc=0.684]\n","Epoch 441:   0% 0/178 [00:16<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 441:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.64it/s]\u001b[A\n","Epoch 441:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.04it/s]\u001b[A\n","Epoch 441:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.54it/s]\u001b[A\n","Epoch 441:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.41it/s]\u001b[A\n","Epoch 441:  56% 100/178 [00:20<00:15,  5.00it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.13it/s]\u001b[A\n","Epoch 441:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.16it/s]\u001b[A\n","Epoch 441:  79% 140/178 [00:20<00:05,  6.89it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.69it/s]\u001b[A\n","Epoch 441:  90% 160/178 [00:20<00:02,  7.82it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.500, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.13it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.13it/s]\u001b[A\n","Epoch 441: 100% 178/178 [00:20<00:00,  8.65it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.699] \n","Epoch 442:   0% 0/178 [00:15<?, ?it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 442:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.77it/s]\u001b[A\n","Epoch 442:  22% 40/178 [00:19<01:08,  2.03it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.22it/s]\u001b[A\n","Epoch 442:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.56it/s]\u001b[A\n","Epoch 442:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.87it/s]\u001b[A\n","Epoch 442:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.78it/s]\u001b[A\n","Epoch 442:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.75it/s]\u001b[A\n","Epoch 442:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.30it/s]\u001b[A\n","Epoch 442:  90% 160/178 [00:20<00:02,  7.74it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.704]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.52it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.52it/s]\u001b[A\n","Epoch 442: 100% 178/178 [00:20<00:00,  8.57it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.704]\n","Epoch 443:   0% 0/178 [00:14<?, ?it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 443:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 132.24it/s]\u001b[A\n","Epoch 443:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 135.40it/s]\u001b[A\n","Epoch 443:  34% 60/178 [00:20<00:39,  3.00it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.98it/s]\u001b[A\n","Epoch 443:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.36it/s]\u001b[A\n","Epoch 443:  56% 100/178 [00:20<00:15,  4.92it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.69it/s]\u001b[A\n","Epoch 443:  67% 120/178 [00:20<00:09,  5.86it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.62it/s]\u001b[A\n","Epoch 443:  79% 140/178 [00:20<00:05,  6.79it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.34it/s]\u001b[A\n","Epoch 443:  90% 160/178 [00:20<00:02,  7.70it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.512, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.62it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.62it/s]\u001b[A\n","Epoch 443: 100% 178/178 [00:20<00:00,  8.52it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.694]\n","Epoch 444:   0% 0/178 [00:13<?, ?it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 444:  11% 20/178 [00:18<02:29,  1.06it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 83.48it/s]\u001b[A\n","Epoch 444:  22% 40/178 [00:19<01:05,  2.09it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 95.68it/s]\u001b[A\n","Epoch 444:  34% 60/178 [00:19<00:37,  3.11it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:01, 102.38it/s]\u001b[A\n","Epoch 444:  45% 80/178 [00:19<00:23,  4.11it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 103.63it/s]\u001b[A\n","Epoch 444:  56% 100/178 [00:19<00:15,  5.09it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 110.08it/s]\u001b[A\n","Epoch 444:  67% 120/178 [00:19<00:09,  6.05it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  72% 120/166 [00:01<00:00, 110.31it/s]\u001b[A\n","Epoch 444:  79% 140/178 [00:19<00:05,  7.00it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 112.83it/s]\u001b[A\n","Epoch 444:  90% 160/178 [00:20<00:02,  7.93it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.690]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 119.30it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 119.30it/s]\u001b[A\n","Epoch 444: 100% 178/178 [00:20<00:00,  8.77it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.690]\n","Epoch 445:   0% 0/178 [00:13<?, ?it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 445:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 128.95it/s]\u001b[A\n","Epoch 445:  22% 40/178 [00:19<01:08,  2.03it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 134.77it/s]\u001b[A\n","Epoch 445:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.38it/s]\u001b[A\n","Epoch 445:  45% 80/178 [00:20<00:24,  4.00it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 135.73it/s]\u001b[A\n","Epoch 445:  56% 100/178 [00:20<00:15,  4.96it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.37it/s]\u001b[A\n","Epoch 445:  67% 120/178 [00:20<00:09,  5.91it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 137.31it/s]\u001b[A\n","Epoch 445:  79% 140/178 [00:20<00:05,  6.84it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.55it/s]\u001b[A\n","Epoch 445:  90% 160/178 [00:20<00:02,  7.76it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.470, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.52it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.52it/s]\u001b[A\n","Epoch 445: 100% 178/178 [00:20<00:00,  8.59it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.210, train/acc=0.695]\n","Epoch 446:   0% 0/178 [00:12<?, ?it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 446:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 115.93it/s]\u001b[A\n","Epoch 446:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.41it/s]\u001b[A\n","Epoch 446:  34% 60/178 [00:19<00:38,  3.07it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.09it/s]\u001b[A\n","Epoch 446:  45% 80/178 [00:19<00:24,  4.07it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.71it/s]\u001b[A\n","Epoch 446:  56% 100/178 [00:19<00:15,  5.04it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.63it/s]\u001b[A\n","Epoch 446:  67% 120/178 [00:19<00:09,  6.01it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.04it/s]\u001b[A\n","Epoch 446:  79% 140/178 [00:20<00:05,  6.96it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.89it/s]\u001b[A\n","Epoch 446:  90% 160/178 [00:20<00:02,  7.89it/s, loss=1.22, v_num=2, val/loss=1.390, Val/acc=0.512, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.08it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.08it/s]\u001b[A\n","Epoch 446: 100% 178/178 [00:20<00:00,  8.73it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Epoch 447:   0% 0/178 [00:12<?, ?it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 447:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.24it/s]\u001b[A\n","Epoch 447:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.06it/s]\u001b[A\n","Epoch 447:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.52it/s]\u001b[A\n","Epoch 447:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.69it/s]\u001b[A\n","Epoch 447:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.50it/s]\u001b[A\n","Epoch 447:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.31it/s]\u001b[A\n","Epoch 447:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.98it/s]\u001b[A\n","Epoch 447:  90% 160/178 [00:20<00:02,  7.67it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.689]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.88it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.88it/s]\u001b[A\n","Epoch 447: 100% 178/178 [00:20<00:00,  8.49it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.220, train/acc=0.689]\n","Epoch 448:   0% 0/178 [00:11<?, ?it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 448:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 116.36it/s]\u001b[A\n","Epoch 448:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.35it/s]\u001b[A\n","Epoch 448:  34% 60/178 [00:19<00:38,  3.04it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.09it/s]\u001b[A\n","Epoch 448:  45% 80/178 [00:19<00:24,  4.02it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.11it/s]\u001b[A\n","Epoch 448:  56% 100/178 [00:20<00:15,  4.99it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.47it/s]\u001b[A\n","Epoch 448:  67% 120/178 [00:20<00:09,  5.94it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.66it/s]\u001b[A\n","Epoch 448:  79% 140/178 [00:20<00:05,  6.88it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.71it/s]\u001b[A\n","Epoch 448:  90% 160/178 [00:20<00:02,  7.80it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.422, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.02it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.02it/s]\u001b[A\n","Epoch 448: 100% 178/178 [00:20<00:00,  8.63it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.230, train/acc=0.675]\n","Epoch 449:   0% 0/178 [00:10<?, ?it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 449:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 120.44it/s]\u001b[A\n","Epoch 449:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.37it/s]\u001b[A\n","Epoch 449:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.60it/s]\u001b[A\n","Epoch 449:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.74it/s]\u001b[A\n","Epoch 449:  56% 100/178 [00:20<00:15,  4.92it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.51it/s]\u001b[A\n","Epoch 449:  67% 120/178 [00:20<00:09,  5.86it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.96it/s]\u001b[A\n","Epoch 449:  79% 140/178 [00:20<00:05,  6.78it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.05it/s]\u001b[A\n","Epoch 449:  90% 160/178 [00:20<00:02,  7.69it/s, loss=1.21, v_num=2, val/loss=1.400, Val/acc=0.506, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.78it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.78it/s]\u001b[A\n","Epoch 449: 100% 178/178 [00:20<00:00,  8.51it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.688]\n","Epoch 450:   0% 0/178 [00:00<?, ?it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 450:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 135.19it/s]\u001b[A\n","Epoch 450:  22% 40/178 [00:19<01:08,  2.00it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 137.27it/s]\u001b[A\n","Epoch 450:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.87it/s]\u001b[A\n","Epoch 450:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 133.68it/s]\u001b[A\n","Epoch 450:  56% 100/178 [00:20<00:15,  4.90it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.16it/s]\u001b[A\n","Epoch 450:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.65it/s]\u001b[A\n","Epoch 450:  79% 140/178 [00:20<00:05,  6.76it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 137.52it/s]\u001b[A\n","Epoch 450:  90% 160/178 [00:20<00:02,  7.68it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.29it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 140.29it/s]\u001b[A\n","Epoch 450: 100% 178/178 [00:20<00:00,  8.49it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.220, train/acc=0.682]\n","Epoch 451:   0% 0/178 [00:18<?, ?it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 451:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.30it/s]\u001b[A\n","Epoch 451:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.11it/s]\u001b[A\n","Epoch 451:  34% 60/178 [00:20<00:39,  2.96it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.41it/s]\u001b[A\n","Epoch 451:  45% 80/178 [00:20<00:24,  3.92it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.18it/s]\u001b[A\n","Epoch 451:  56% 100/178 [00:20<00:16,  4.87it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.18it/s]\u001b[A\n","Epoch 451:  67% 120/178 [00:20<00:10,  5.80it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.60it/s]\u001b[A\n","Epoch 451:  79% 140/178 [00:20<00:05,  6.72it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.94it/s]\u001b[A\n","Epoch 451:  90% 160/178 [00:20<00:02,  7.62it/s, loss=1.23, v_num=2, val/loss=1.460, Val/acc=0.428, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.10it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.10it/s]\u001b[A\n","Epoch 451: 100% 178/178 [00:21<00:00,  8.43it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.230, train/acc=0.675]\n","Epoch 452:   0% 0/178 [00:17<?, ?it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 452:  11% 20/178 [00:19<02:31,  1.05it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.02it/s]\u001b[A\n","Epoch 452:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.37it/s]\u001b[A\n","Epoch 452:  34% 60/178 [00:19<00:38,  3.09it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.74it/s]\u001b[A\n","Epoch 452:  45% 80/178 [00:19<00:23,  4.09it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.94it/s]\u001b[A\n","Epoch 452:  56% 100/178 [00:19<00:15,  5.07it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.93it/s]\u001b[A\n","Epoch 452:  67% 120/178 [00:19<00:09,  6.04it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.03it/s]\u001b[A\n","Epoch 452:  79% 140/178 [00:20<00:05,  7.00it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.20it/s]\u001b[A\n","Epoch 452:  90% 160/178 [00:20<00:02,  7.93it/s, loss=1.23, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.13it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.13it/s]\u001b[A\n","Epoch 452: 100% 178/178 [00:20<00:00,  8.78it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.220, train/acc=0.685]\n","Epoch 453:   0% 0/178 [00:17<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 453:  11% 20/178 [00:19<02:30,  1.05it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 118.53it/s]\u001b[A\n","Epoch 453:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.31it/s]\u001b[A\n","Epoch 453:  34% 60/178 [00:19<00:38,  3.10it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.21it/s]\u001b[A\n","Epoch 453:  45% 80/178 [00:19<00:23,  4.10it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.24it/s]\u001b[A\n","Epoch 453:  56% 100/178 [00:19<00:15,  5.08it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.65it/s]\u001b[A\n","Epoch 453:  67% 120/178 [00:19<00:09,  6.06it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.25it/s]\u001b[A\n","Epoch 453:  79% 140/178 [00:19<00:05,  7.02it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.65it/s]\u001b[A\n","Epoch 453:  90% 160/178 [00:20<00:02,  7.95it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.33it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.33it/s]\u001b[A\n","Epoch 453: 100% 178/178 [00:20<00:00,  8.80it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.692]\n","Epoch 454:   0% 0/178 [00:17<?, ?it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 454:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.29it/s]\u001b[A\n","Epoch 454:  22% 40/178 [00:19<01:08,  2.03it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.93it/s]\u001b[A\n","Epoch 454:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.66it/s]\u001b[A\n","Epoch 454:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 126.58it/s]\u001b[A\n","Epoch 454:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.06it/s]\u001b[A\n","Epoch 454:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.65it/s]\u001b[A\n","Epoch 454:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.11it/s]\u001b[A\n","Epoch 454:  90% 160/178 [00:20<00:02,  7.74it/s, loss=1.22, v_num=2, val/loss=1.480, Val/acc=0.422, train/loss=1.210, train/acc=0.687]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.86it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.86it/s]\u001b[A\n","Epoch 454: 100% 178/178 [00:20<00:00,  8.56it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.687]\n","Epoch 455:   0% 0/178 [00:16<?, ?it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 455:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 118.75it/s]\u001b[A\n","Epoch 455:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 128.24it/s]\u001b[A\n","Epoch 455:  34% 60/178 [00:19<00:38,  3.09it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.54it/s]\u001b[A\n","Epoch 455:  45% 80/178 [00:19<00:23,  4.09it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.54it/s]\u001b[A\n","Epoch 455:  56% 100/178 [00:19<00:15,  5.07it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.86it/s]\u001b[A\n","Epoch 455:  67% 120/178 [00:19<00:09,  6.04it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.01it/s]\u001b[A\n","Epoch 455:  79% 140/178 [00:20<00:05,  6.99it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.52it/s]\u001b[A\n","Epoch 455:  90% 160/178 [00:20<00:02,  7.93it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.699]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.94it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.94it/s]\u001b[A\n","Epoch 455: 100% 178/178 [00:20<00:00,  8.77it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.699] \n","Epoch 456:   0% 0/178 [00:16<?, ?it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 456:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 135.36it/s]\u001b[A\n","Epoch 456:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 140.48it/s]\u001b[A\n","Epoch 456:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 137.43it/s]\u001b[A\n","Epoch 456:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.28it/s]\u001b[A\n","Epoch 456:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.87it/s]\u001b[A\n","Epoch 456:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.92it/s]\u001b[A\n","Epoch 456:  79% 140/178 [00:20<00:05,  6.81it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.92it/s]\u001b[A\n","Epoch 456:  90% 160/178 [00:20<00:02,  7.73it/s, loss=1.2, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.64it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.64it/s]\u001b[A\n","Epoch 456: 100% 178/178 [00:20<00:00,  8.55it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.200, train/acc=0.702]\n","Epoch 457:   0% 0/178 [00:15<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 457:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.29it/s]\u001b[A\n","Epoch 457:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.13it/s]\u001b[A\n","Epoch 457:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.20it/s]\u001b[A\n","Epoch 457:  45% 80/178 [00:20<00:24,  4.00it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.73it/s]\u001b[A\n","Epoch 457:  56% 100/178 [00:20<00:15,  4.96it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.52it/s]\u001b[A\n","Epoch 457:  67% 120/178 [00:20<00:09,  5.91it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.09it/s]\u001b[A\n","Epoch 457:  79% 140/178 [00:20<00:05,  6.84it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.68it/s]\u001b[A\n","Epoch 457:  90% 160/178 [00:20<00:02,  7.76it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.37it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.37it/s]\u001b[A\n","Epoch 457: 100% 178/178 [00:20<00:00,  8.59it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.691]\n","Epoch 458:   0% 0/178 [00:14<?, ?it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 458:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 107.37it/s]\u001b[A\n","Epoch 458:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.13it/s]\u001b[A\n","Epoch 458:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.07it/s]\u001b[A\n","Epoch 458:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.87it/s]\u001b[A\n","Epoch 458:  56% 100/178 [00:19<00:15,  5.01it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.33it/s]\u001b[A\n","Epoch 458:  67% 120/178 [00:20<00:09,  5.96it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.91it/s]\u001b[A\n","Epoch 458:  79% 140/178 [00:20<00:05,  6.91it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.04it/s]\u001b[A\n","Epoch 458:  90% 160/178 [00:20<00:02,  7.83it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.476, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.44it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.44it/s]\u001b[A\n","Epoch 458: 100% 178/178 [00:20<00:00,  8.67it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Epoch 459:   0% 0/178 [00:13<?, ?it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 459:  11% 20/178 [00:19<02:34,  1.03it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 103.44it/s]\u001b[A\n","Epoch 459:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.10it/s]\u001b[A\n","Epoch 459:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.57it/s]\u001b[A\n","Epoch 459:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.59it/s]\u001b[A\n","Epoch 459:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.29it/s]\u001b[A\n","Epoch 459:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.52it/s]\u001b[A\n","Epoch 459:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.89it/s]\u001b[A\n","Epoch 459:  90% 160/178 [00:20<00:02,  7.79it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.446, train/loss=1.210, train/acc=0.698]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.49it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.49it/s]\u001b[A\n","Epoch 459: 100% 178/178 [00:20<00:00,  8.62it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.698]\n","Epoch 460:   0% 0/178 [00:13<?, ?it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 460:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.10it/s]\u001b[A\n","Epoch 460:  22% 40/178 [00:19<01:07,  2.03it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 125.41it/s]\u001b[A\n","Epoch 460:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.74it/s]\u001b[A\n","Epoch 460:  45% 80/178 [00:19<00:24,  4.00it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.89it/s]\u001b[A\n","Epoch 460:  56% 100/178 [00:20<00:15,  4.97it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.56it/s]\u001b[A\n","Epoch 460:  67% 120/178 [00:20<00:09,  5.92it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.67it/s]\u001b[A\n","Epoch 460:  79% 140/178 [00:20<00:05,  6.85it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.32it/s]\u001b[A\n","Epoch 460:  90% 160/178 [00:20<00:02,  7.77it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.697]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.46it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.46it/s]\u001b[A\n","Epoch 460: 100% 178/178 [00:20<00:00,  8.60it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.697]\n","Epoch 461:   0% 0/178 [00:12<?, ?it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 461:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.18it/s]\u001b[A\n","Epoch 461:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.65it/s]\u001b[A\n","Epoch 461:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 123.57it/s]\u001b[A\n","Epoch 461:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.04it/s]\u001b[A\n","Epoch 461:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.00it/s]\u001b[A\n","Epoch 461:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.83it/s]\u001b[A\n","Epoch 461:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.67it/s]\u001b[A\n","Epoch 461:  90% 160/178 [00:20<00:02,  7.75it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.689]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.93it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.93it/s]\u001b[A\n","Epoch 461: 100% 178/178 [00:20<00:00,  8.57it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.689]\n","Epoch 462:   0% 0/178 [00:11<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 462:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 120.53it/s]\u001b[A\n","Epoch 462:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 135.37it/s]\u001b[A\n","Epoch 462:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.19it/s]\u001b[A\n","Epoch 462:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 133.89it/s]\u001b[A\n","Epoch 462:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.57it/s]\u001b[A\n","Epoch 462:  67% 120/178 [00:20<00:09,  5.89it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.77it/s]\u001b[A\n","Epoch 462:  79% 140/178 [00:20<00:05,  6.82it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 129.89it/s]\u001b[A\n","Epoch 462:  90% 160/178 [00:20<00:02,  7.74it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.98it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.98it/s]\u001b[A\n","Epoch 462: 100% 178/178 [00:20<00:00,  8.57it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.220, train/acc=0.688]\n","Epoch 463:   0% 0/178 [00:10<?, ?it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 463:  11% 20/178 [00:18<02:28,  1.06it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 105.71it/s]\u001b[A\n","Epoch 463:  22% 40/178 [00:18<01:05,  2.11it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.60it/s]\u001b[A\n","Epoch 463:  34% 60/178 [00:19<00:37,  3.14it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 124.38it/s]\u001b[A\n","Epoch 463:  45% 80/178 [00:19<00:23,  4.16it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.68it/s]\u001b[A\n","Epoch 463:  56% 100/178 [00:19<00:15,  5.15it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.67it/s]\u001b[A\n","Epoch 463:  67% 120/178 [00:19<00:09,  6.14it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.65it/s]\u001b[A\n","Epoch 463:  79% 140/178 [00:19<00:05,  7.11it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.57it/s]\u001b[A\n","Epoch 463:  90% 160/178 [00:19<00:02,  8.06it/s, loss=1.23, v_num=2, val/loss=1.480, Val/acc=0.416, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.24it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.24it/s]\u001b[A\n","Epoch 463: 100% 178/178 [00:19<00:00,  8.91it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.230, train/acc=0.675]\n","Epoch 464:   0% 0/178 [00:10<?, ?it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 464:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.74it/s]\u001b[A\n","Epoch 464:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 118.46it/s]\u001b[A\n","Epoch 464:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.76it/s]\u001b[A\n","Epoch 464:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 123.67it/s]\u001b[A\n","Epoch 464:  56% 100/178 [00:20<00:15,  4.91it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.44it/s]\u001b[A\n","Epoch 464:  67% 120/178 [00:20<00:09,  5.85it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.27it/s]\u001b[A\n","Epoch 464:  79% 140/178 [00:20<00:05,  6.78it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.24it/s]\u001b[A\n","Epoch 464:  90% 160/178 [00:20<00:02,  7.69it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.25it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.25it/s]\u001b[A\n","Epoch 464: 100% 178/178 [00:20<00:00,  8.51it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.220, train/acc=0.686]\n","Epoch 465:   0% 0/178 [00:00<?, ?it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Epoch 465:   0% 0/178 [00:19<?, ?it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 465:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.27it/s]\u001b[A\n","Epoch 465:  22% 40/178 [00:20<01:10,  1.96it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.05it/s]\u001b[A\n","Epoch 465:  34% 60/178 [00:20<00:40,  2.92it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.33it/s]\u001b[A\n","Epoch 465:  45% 80/178 [00:20<00:25,  3.87it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.80it/s]\u001b[A\n","Epoch 465:  56% 100/178 [00:20<00:16,  4.80it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.00it/s]\u001b[A\n","Epoch 465:  67% 120/178 [00:20<00:10,  5.72it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.43it/s]\u001b[A\n","Epoch 465:  79% 140/178 [00:21<00:05,  6.63it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.37it/s]\u001b[A\n","Epoch 465:  90% 160/178 [00:21<00:02,  7.52it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.06it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.06it/s]\u001b[A\n","Epoch 465: 100% 178/178 [00:21<00:00,  8.33it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.210, train/acc=0.692]\n","Epoch 466:   0% 0/178 [00:18<?, ?it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 466:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.26it/s]\u001b[A\n","Epoch 466:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.18it/s]\u001b[A\n","Epoch 466:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.11it/s]\u001b[A\n","Epoch 466:  45% 80/178 [00:19<00:24,  4.03it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.57it/s]\u001b[A\n","Epoch 466:  56% 100/178 [00:20<00:15,  5.00it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.54it/s]\u001b[A\n","Epoch 466:  67% 120/178 [00:20<00:09,  5.95it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.99it/s]\u001b[A\n","Epoch 466:  79% 140/178 [00:20<00:05,  6.90it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.45it/s]\u001b[A\n","Epoch 466:  90% 160/178 [00:20<00:02,  7.82it/s, loss=1.21, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.702]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.27it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.27it/s]\u001b[A\n","Epoch 466: 100% 178/178 [00:20<00:00,  8.66it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.702] \n","Epoch 467:   0% 0/178 [00:17<?, ?it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 467:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 101.41it/s]\u001b[A\n","Epoch 467:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 119.44it/s]\u001b[A\n","Epoch 467:  34% 60/178 [00:20<00:39,  2.95it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.70it/s]\u001b[A\n","Epoch 467:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.33it/s]\u001b[A\n","Epoch 467:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.41it/s]\u001b[A\n","Epoch 467:  67% 120/178 [00:20<00:10,  5.77it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.55it/s]\u001b[A\n","Epoch 467:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.43it/s]\u001b[A\n","Epoch 467:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.2, v_num=2, val/loss=1.410, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.98it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.98it/s]\u001b[A\n","Epoch 467: 100% 178/178 [00:21<00:00,  8.40it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","                                                               \u001b[AMetric train/loss improved by 0.005 >= min_delta = 0.0. New best score: 1.191\n","Epoch 468:   0% 0/178 [00:16<?, ?it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 468:  11% 20/178 [00:19<02:37,  1.01it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.85it/s]\u001b[A\n","Epoch 468:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.59it/s]\u001b[A\n","Epoch 468:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.29it/s]\u001b[A\n","Epoch 468:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.27it/s]\u001b[A\n","Epoch 468:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.84it/s]\u001b[A\n","Epoch 468:  67% 120/178 [00:20<00:09,  5.82it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.30it/s]\u001b[A\n","Epoch 468:  79% 140/178 [00:20<00:05,  6.75it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.41it/s]\u001b[A\n","Epoch 468:  90% 160/178 [00:20<00:02,  7.65it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.30it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.30it/s]\u001b[A\n","Epoch 468: 100% 178/178 [00:21<00:00,  8.46it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.190, train/acc=0.710]\n","Epoch 469:   0% 0/178 [00:15<?, ?it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 469:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 118.73it/s]\u001b[A\n","Epoch 469:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.84it/s]\u001b[A\n","Epoch 469:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.84it/s]\u001b[A\n","Epoch 469:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.90it/s]\u001b[A\n","Epoch 469:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.62it/s]\u001b[A\n","Epoch 469:  67% 120/178 [00:20<00:09,  5.90it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.65it/s]\u001b[A\n","Epoch 469:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.29it/s]\u001b[A\n","Epoch 469:  90% 160/178 [00:20<00:02,  7.75it/s, loss=1.19, v_num=2, val/loss=1.420, Val/acc=0.488, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.35it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 141.35it/s]\u001b[A\n","Epoch 469: 100% 178/178 [00:20<00:00,  8.58it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.200, train/acc=0.704]\n","Epoch 470:   0% 0/178 [00:14<?, ?it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 470:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.15it/s]\u001b[A\n","Epoch 470:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.50it/s]\u001b[A\n","Epoch 470:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.07it/s]\u001b[A\n","Epoch 470:  45% 80/178 [00:20<00:24,  3.95it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.69it/s]\u001b[A\n","Epoch 470:  56% 100/178 [00:20<00:15,  4.91it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.90it/s]\u001b[A\n","Epoch 470:  67% 120/178 [00:20<00:09,  5.84it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.59it/s]\u001b[A\n","Epoch 470:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.26it/s]\u001b[A\n","Epoch 470:  90% 160/178 [00:20<00:02,  7.68it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.74it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.74it/s]\u001b[A\n","Epoch 470: 100% 178/178 [00:20<00:00,  8.50it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.210, train/acc=0.696]\n","Epoch 471:   0% 0/178 [00:13<?, ?it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 471:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 110.44it/s]\u001b[A\n","Epoch 471:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.24it/s]\u001b[A\n","Epoch 471:  34% 60/178 [00:19<00:38,  3.09it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.37it/s]\u001b[A\n","Epoch 471:  45% 80/178 [00:19<00:23,  4.09it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.55it/s]\u001b[A\n","Epoch 471:  56% 100/178 [00:19<00:15,  5.07it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.58it/s]\u001b[A\n","Epoch 471:  67% 120/178 [00:19<00:09,  6.04it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.21it/s]\u001b[A\n","Epoch 471:  79% 140/178 [00:20<00:05,  6.99it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.99it/s]\u001b[A\n","Epoch 471:  90% 160/178 [00:20<00:02,  7.93it/s, loss=1.21, v_num=2, val/loss=1.430, Val/acc=0.470, train/loss=1.220, train/acc=0.685]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.63it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.63it/s]\u001b[A\n","Epoch 471: 100% 178/178 [00:20<00:00,  8.77it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.685]\n","Epoch 472:   0% 0/178 [00:13<?, ?it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 472:  11% 20/178 [00:19<02:34,  1.02it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 102.35it/s]\u001b[A\n","Epoch 472:  22% 40/178 [00:19<01:08,  2.03it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 120.95it/s]\u001b[A\n","Epoch 472:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.98it/s]\u001b[A\n","Epoch 472:  45% 80/178 [00:20<00:24,  4.00it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.02it/s]\u001b[A\n","Epoch 472:  56% 100/178 [00:20<00:15,  4.96it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.33it/s]\u001b[A\n","Epoch 472:  67% 120/178 [00:20<00:09,  5.90it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.04it/s]\u001b[A\n","Epoch 472:  79% 140/178 [00:20<00:05,  6.84it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.04it/s]\u001b[A\n","Epoch 472:  90% 160/178 [00:20<00:02,  7.76it/s, loss=1.22, v_num=2, val/loss=1.450, Val/acc=0.434, train/loss=1.220, train/acc=0.682]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.37it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.37it/s]\u001b[A\n","Epoch 472: 100% 178/178 [00:20<00:00,  8.58it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.682]\n","Epoch 473:   0% 0/178 [00:12<?, ?it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 473:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 125.98it/s]\u001b[A\n","Epoch 473:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.63it/s]\u001b[A\n","Epoch 473:  34% 60/178 [00:20<00:39,  2.96it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.13it/s]\u001b[A\n","Epoch 473:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.37it/s]\u001b[A\n","Epoch 473:  56% 100/178 [00:20<00:16,  4.86it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 137.50it/s]\u001b[A\n","Epoch 473:  67% 120/178 [00:20<00:10,  5.79it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.16it/s]\u001b[A\n","Epoch 473:  79% 140/178 [00:20<00:05,  6.70it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.82it/s]\u001b[A\n","Epoch 473:  90% 160/178 [00:21<00:02,  7.60it/s, loss=1.22, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.49it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.49it/s]\u001b[A\n","Epoch 473: 100% 178/178 [00:21<00:00,  8.41it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.220, train/acc=0.684]\n","Epoch 474:   0% 0/178 [00:11<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 474:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 123.88it/s]\u001b[A\n","Epoch 474:  22% 40/178 [00:19<01:08,  2.01it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 133.15it/s]\u001b[A\n","Epoch 474:  34% 60/178 [00:20<00:39,  2.99it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.73it/s]\u001b[A\n","Epoch 474:  45% 80/178 [00:20<00:24,  3.96it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.91it/s]\u001b[A\n","Epoch 474:  56% 100/178 [00:20<00:15,  4.91it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.05it/s]\u001b[A\n","Epoch 474:  67% 120/178 [00:20<00:09,  5.85it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.71it/s]\u001b[A\n","Epoch 474:  79% 140/178 [00:20<00:05,  6.77it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.89it/s]\u001b[A\n","Epoch 474:  90% 160/178 [00:20<00:02,  7.68it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.44it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.44it/s]\u001b[A\n","Epoch 474: 100% 178/178 [00:20<00:00,  8.50it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.210, train/acc=0.692]\n","Epoch 475:   0% 0/178 [00:10<?, ?it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 475:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.96it/s]\u001b[A\n","Epoch 475:  22% 40/178 [00:19<01:08,  2.03it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.07it/s]\u001b[A\n","Epoch 475:  34% 60/178 [00:19<00:39,  3.02it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 136.11it/s]\u001b[A\n","Epoch 475:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.46it/s]\u001b[A\n","Epoch 475:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.18it/s]\u001b[A\n","Epoch 475:  67% 120/178 [00:20<00:09,  5.90it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.80it/s]\u001b[A\n","Epoch 475:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.54it/s]\u001b[A\n","Epoch 475:  90% 160/178 [00:20<00:02,  7.75it/s, loss=1.21, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.220, train/acc=0.688]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.80it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.80it/s]\u001b[A\n","Epoch 475: 100% 178/178 [00:20<00:00,  8.57it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.220, train/acc=0.688]\n","Epoch 476:   0% 0/178 [00:00<?, ?it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Epoch 476:   0% 0/178 [00:19<?, ?it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 476:  11% 20/178 [00:19<02:37,  1.00it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 128.25it/s]\u001b[A\n","Epoch 476:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 134.25it/s]\u001b[A\n","Epoch 476:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.99it/s]\u001b[A\n","Epoch 476:  45% 80/178 [00:20<00:24,  3.93it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.38it/s]\u001b[A\n","Epoch 476:  56% 100/178 [00:20<00:15,  4.88it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 126.44it/s]\u001b[A\n","Epoch 476:  67% 120/178 [00:20<00:09,  5.81it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 126.09it/s]\u001b[A\n","Epoch 476:  79% 140/178 [00:20<00:05,  6.73it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.31it/s]\u001b[A\n","Epoch 476:  90% 160/178 [00:20<00:02,  7.63it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.416, train/loss=1.240, train/acc=0.665]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.00it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.00it/s]\u001b[A\n","Epoch 476: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.240, train/acc=0.665]\n","Epoch 477:   0% 0/178 [00:18<?, ?it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 477:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 120.06it/s]\u001b[A\n","Epoch 477:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 130.45it/s]\u001b[A\n","Epoch 477:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 133.05it/s]\u001b[A\n","Epoch 477:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.73it/s]\u001b[A\n","Epoch 477:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.47it/s]\u001b[A\n","Epoch 477:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.02it/s]\u001b[A\n","Epoch 477:  79% 140/178 [00:20<00:05,  6.81it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.42it/s]\u001b[A\n","Epoch 477:  90% 160/178 [00:20<00:02,  7.73it/s, loss=1.23, v_num=2, val/loss=1.490, Val/acc=0.398, train/loss=1.220, train/acc=0.686]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.15it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.15it/s]\u001b[A\n","Epoch 477: 100% 178/178 [00:20<00:00,  8.55it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.220, train/acc=0.686]\n","Epoch 478:   0% 0/178 [00:17<?, ?it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 478:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 120.14it/s]\u001b[A\n","Epoch 478:  22% 40/178 [00:20<01:10,  1.97it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.65it/s]\u001b[A\n","Epoch 478:  34% 60/178 [00:20<00:40,  2.93it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.31it/s]\u001b[A\n","Epoch 478:  45% 80/178 [00:20<00:25,  3.88it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.32it/s]\u001b[A\n","Epoch 478:  56% 100/178 [00:20<00:16,  4.81it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.95it/s]\u001b[A\n","Epoch 478:  67% 120/178 [00:20<00:10,  5.74it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.82it/s]\u001b[A\n","Epoch 478:  79% 140/178 [00:21<00:05,  6.65it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.27it/s]\u001b[A\n","Epoch 478:  90% 160/178 [00:21<00:02,  7.54it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.691]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.90it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.90it/s]\u001b[A\n","Epoch 478: 100% 178/178 [00:21<00:00,  8.34it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.691]\n","Epoch 479:   0% 0/178 [00:16<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 479:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 110.97it/s]\u001b[A\n","Epoch 479:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.91it/s]\u001b[A\n","Epoch 479:  34% 60/178 [00:19<00:38,  3.08it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.23it/s]\u001b[A\n","Epoch 479:  45% 80/178 [00:19<00:24,  4.08it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.31it/s]\u001b[A\n","Epoch 479:  56% 100/178 [00:19<00:15,  5.06it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.23it/s]\u001b[A\n","Epoch 479:  67% 120/178 [00:19<00:09,  6.03it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.10it/s]\u001b[A\n","Epoch 479:  79% 140/178 [00:20<00:05,  6.99it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.53it/s]\u001b[A\n","Epoch 479:  90% 160/178 [00:20<00:02,  7.92it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.476, train/loss=1.210, train/acc=0.694]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.04it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.04it/s]\u001b[A\n","Epoch 479: 100% 178/178 [00:20<00:00,  8.76it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.210, train/acc=0.694] \n","Epoch 480:   0% 0/178 [00:16<?, ?it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 480:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 119.58it/s]\u001b[A\n","Epoch 480:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.45it/s]\u001b[A\n","Epoch 480:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 132.49it/s]\u001b[A\n","Epoch 480:  45% 80/178 [00:20<00:24,  3.98it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.76it/s]\u001b[A\n","Epoch 480:  56% 100/178 [00:20<00:15,  4.94it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.05it/s]\u001b[A\n","Epoch 480:  67% 120/178 [00:20<00:09,  5.88it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.67it/s]\u001b[A\n","Epoch 480:  79% 140/178 [00:20<00:05,  6.81it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.46it/s]\u001b[A\n","Epoch 480:  90% 160/178 [00:20<00:02,  7.73it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.707]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.70it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.70it/s]\u001b[A\n","Epoch 480: 100% 178/178 [00:20<00:00,  8.55it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.200, train/acc=0.707]\n","Epoch 481:   0% 0/178 [00:15<?, ?it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 481:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 106.26it/s]\u001b[A\n","Epoch 481:  22% 40/178 [00:20<01:09,  1.97it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.01it/s]\u001b[A\n","Epoch 481:  34% 60/178 [00:20<00:40,  2.94it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.91it/s]\u001b[A\n","Epoch 481:  45% 80/178 [00:20<00:25,  3.89it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.31it/s]\u001b[A\n","Epoch 481:  56% 100/178 [00:20<00:16,  4.82it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.61it/s]\u001b[A\n","Epoch 481:  67% 120/178 [00:20<00:10,  5.75it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 128.11it/s]\u001b[A\n","Epoch 481:  79% 140/178 [00:21<00:05,  6.65it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.58it/s]\u001b[A\n","Epoch 481:  90% 160/178 [00:21<00:02,  7.55it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.392, train/loss=1.210, train/acc=0.696]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.71it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.71it/s]\u001b[A\n","Epoch 481: 100% 178/178 [00:21<00:00,  8.35it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.210, train/acc=0.696]\n","Epoch 482:   0% 0/178 [00:13<?, ?it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 482:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 126.15it/s]\u001b[A\n","Epoch 482:  22% 40/178 [00:19<01:06,  2.07it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.54it/s]\u001b[A\n","Epoch 482:  34% 60/178 [00:19<00:38,  3.08it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 134.38it/s]\u001b[A\n","Epoch 482:  45% 80/178 [00:19<00:24,  4.08it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 132.31it/s]\u001b[A\n","Epoch 482:  56% 100/178 [00:19<00:15,  5.06it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.61it/s]\u001b[A\n","Epoch 482:  67% 120/178 [00:19<00:09,  6.02it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.99it/s]\u001b[A\n","Epoch 482:  79% 140/178 [00:20<00:05,  6.97it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.01it/s]\u001b[A\n","Epoch 482:  90% 160/178 [00:20<00:02,  7.91it/s, loss=1.2, v_num=2, val/loss=1.440, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.71it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.71it/s]\u001b[A\n","Epoch 482: 100% 178/178 [00:20<00:00,  8.75it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.200, train/acc=0.701]\n","Epoch 483:   0% 0/178 [00:13<?, ?it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 483:  11% 20/178 [00:19<02:36,  1.01it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 111.15it/s]\u001b[A\n","Epoch 483:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 123.56it/s]\u001b[A\n","Epoch 483:  34% 60/178 [00:20<00:39,  2.98it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.90it/s]\u001b[A\n","Epoch 483:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 127.14it/s]\u001b[A\n","Epoch 483:  56% 100/178 [00:20<00:15,  4.89it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.56it/s]\u001b[A\n","Epoch 483:  67% 120/178 [00:20<00:09,  5.82it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.16it/s]\u001b[A\n","Epoch 483:  79% 140/178 [00:20<00:05,  6.74it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.95it/s]\u001b[A\n","Epoch 483:  90% 160/178 [00:20<00:02,  7.65it/s, loss=1.2, v_num=2, val/loss=1.500, Val/acc=0.398, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.84it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.84it/s]\u001b[A\n","Epoch 483: 100% 178/178 [00:21<00:00,  8.46it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.210, train/acc=0.693]\n","Epoch 484:   0% 0/178 [00:12<?, ?it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 484:  11% 20/178 [00:19<02:35,  1.02it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:00, 147.50it/s]\u001b[A\n","Epoch 484:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 142.51it/s]\u001b[A\n","Epoch 484:  34% 60/178 [00:19<00:39,  3.01it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 138.81it/s]\u001b[A\n","Epoch 484:  45% 80/178 [00:20<00:24,  3.99it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 135.61it/s]\u001b[A\n","Epoch 484:  56% 100/178 [00:20<00:15,  4.95it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 137.87it/s]\u001b[A\n","Epoch 484:  67% 120/178 [00:20<00:09,  5.90it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.12it/s]\u001b[A\n","Epoch 484:  79% 140/178 [00:20<00:05,  6.83it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.73it/s]\u001b[A\n","Epoch 484:  90% 160/178 [00:20<00:02,  7.74it/s, loss=1.2, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.710]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.24it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.24it/s]\u001b[A\n","Epoch 484: 100% 178/178 [00:20<00:00,  8.56it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.710]\n","Epoch 485:   0% 0/178 [00:11<?, ?it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 485:  11% 20/178 [00:20<02:40,  1.02s/it, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 109.63it/s]\u001b[A\n","Epoch 485:  22% 40/178 [00:20<01:10,  1.96it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.53it/s]\u001b[A\n","Epoch 485:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.43it/s]\u001b[A\n","Epoch 485:  45% 80/178 [00:20<00:25,  3.86it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.69it/s]\u001b[A\n","Epoch 485:  56% 100/178 [00:20<00:16,  4.78it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.22it/s]\u001b[A\n","Epoch 485:  67% 120/178 [00:21<00:10,  5.70it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.06it/s]\u001b[A\n","Epoch 485:  79% 140/178 [00:21<00:05,  6.60it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.88it/s]\u001b[A\n","Epoch 485:  90% 160/178 [00:21<00:02,  7.49it/s, loss=1.19, v_num=2, val/loss=1.430, Val/acc=0.476, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.86it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.86it/s]\u001b[A\n","Epoch 485: 100% 178/178 [00:21<00:00,  8.29it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.712]\n","Epoch 486:   0% 0/178 [00:10<?, ?it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 486:  11% 20/178 [00:19<02:33,  1.03it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 101.32it/s]\u001b[A\n","Epoch 486:  22% 40/178 [00:19<01:07,  2.05it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.39it/s]\u001b[A\n","Epoch 486:  34% 60/178 [00:19<00:38,  3.05it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 128.63it/s]\u001b[A\n","Epoch 486:  45% 80/178 [00:19<00:24,  4.04it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.07it/s]\u001b[A\n","Epoch 486:  56% 100/178 [00:19<00:15,  5.01it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 134.12it/s]\u001b[A\n","Epoch 486:  67% 120/178 [00:20<00:09,  5.97it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.12it/s]\u001b[A\n","Epoch 486:  79% 140/178 [00:20<00:05,  6.92it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.86it/s]\u001b[A\n","Epoch 486:  90% 160/178 [00:20<00:02,  7.84it/s, loss=1.19, v_num=2, val/loss=1.450, Val/acc=0.452, train/loss=1.200, train/acc=0.709]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.31it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.31it/s]\u001b[A\n","Epoch 486: 100% 178/178 [00:20<00:00,  8.68it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.200, train/acc=0.709] \n","Epoch 487:   0% 0/178 [00:00<?, ?it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 487:  11% 20/178 [00:19<02:34,  1.03it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 121.53it/s]\u001b[A\n","Epoch 487:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 134.63it/s]\u001b[A\n","Epoch 487:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.17it/s]\u001b[A\n","Epoch 487:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.52it/s]\u001b[A\n","Epoch 487:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.17it/s]\u001b[A\n","Epoch 487:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.50it/s]\u001b[A\n","Epoch 487:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.11it/s]\u001b[A\n","Epoch 487:  90% 160/178 [00:20<00:02,  7.79it/s, loss=1.2, v_num=2, val/loss=1.400, Val/acc=0.494, train/loss=1.210, train/acc=0.693]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.75it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.75it/s]\u001b[A\n","Epoch 487: 100% 178/178 [00:20<00:00,  8.62it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.693]\n","Epoch 488:   0% 0/178 [00:18<?, ?it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 488:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 97.11it/s]\u001b[A\n","Epoch 488:  22% 40/178 [00:20<01:11,  1.93it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 118.86it/s]\u001b[A\n","Epoch 488:  34% 60/178 [00:20<00:41,  2.87it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 119.97it/s]\u001b[A\n","Epoch 488:  45% 80/178 [00:21<00:25,  3.80it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 124.69it/s]\u001b[A\n","Epoch 488:  56% 100/178 [00:21<00:16,  4.71it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 130.32it/s]\u001b[A\n","Epoch 488:  67% 120/178 [00:21<00:10,  5.62it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.73it/s]\u001b[A\n","Epoch 488:  79% 140/178 [00:21<00:05,  6.51it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 127.53it/s]\u001b[A\n","Epoch 488:  90% 160/178 [00:21<00:02,  7.38it/s, loss=1.21, v_num=2, val/loss=1.440, Val/acc=0.470, train/loss=1.210, train/acc=0.700]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.15it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.15it/s]\u001b[A\n","Epoch 488: 100% 178/178 [00:21<00:00,  8.17it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.700]\n","Epoch 489:   0% 0/178 [00:17<?, ?it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 489:  11% 20/178 [00:19<02:34,  1.03it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 144.94it/s]\u001b[A\n","Epoch 489:  22% 40/178 [00:19<01:07,  2.04it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 138.31it/s]\u001b[A\n","Epoch 489:  34% 60/178 [00:19<00:38,  3.03it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 135.08it/s]\u001b[A\n","Epoch 489:  45% 80/178 [00:19<00:24,  4.01it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.48it/s]\u001b[A\n","Epoch 489:  56% 100/178 [00:20<00:15,  4.98it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.71it/s]\u001b[A\n","Epoch 489:  67% 120/178 [00:20<00:09,  5.93it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.36it/s]\u001b[A\n","Epoch 489:  79% 140/178 [00:20<00:05,  6.87it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.85it/s]\u001b[A\n","Epoch 489:  90% 160/178 [00:20<00:02,  7.79it/s, loss=1.21, v_num=2, val/loss=1.410, Val/acc=0.494, train/loss=1.210, train/acc=0.688]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.33it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 135.33it/s]\u001b[A\n","Epoch 489: 100% 178/178 [00:20<00:00,  8.61it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.688]\n","Epoch 490:   0% 0/178 [00:16<?, ?it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 490:  11% 20/178 [00:19<02:31,  1.04it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 120.15it/s]\u001b[A\n","Epoch 490:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 131.02it/s]\u001b[A\n","Epoch 490:  34% 60/178 [00:19<00:38,  3.09it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 131.62it/s]\u001b[A\n","Epoch 490:  45% 80/178 [00:19<00:23,  4.09it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.84it/s]\u001b[A\n","Epoch 490:  56% 100/178 [00:19<00:15,  5.07it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 136.18it/s]\u001b[A\n","Epoch 490:  67% 120/178 [00:19<00:09,  6.04it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 134.71it/s]\u001b[A\n","Epoch 490:  79% 140/178 [00:20<00:05,  7.00it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.37it/s]\u001b[A\n","Epoch 490:  90% 160/178 [00:20<00:02,  7.94it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.44it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.44it/s]\u001b[A\n","Epoch 490: 100% 178/178 [00:20<00:00,  8.78it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.200, train/acc=0.704]\n","Epoch 491:   0% 0/178 [00:16<?, ?it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 491:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.03it/s]\u001b[A\n","Epoch 491:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 126.73it/s]\u001b[A\n","Epoch 491:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.88it/s]\u001b[A\n","Epoch 491:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.41it/s]\u001b[A\n","Epoch 491:  56% 100/178 [00:20<00:15,  4.93it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 132.00it/s]\u001b[A\n","Epoch 491:  67% 120/178 [00:20<00:09,  5.87it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 133.84it/s]\u001b[A\n","Epoch 491:  79% 140/178 [00:20<00:05,  6.80it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 132.56it/s]\u001b[A\n","Epoch 491:  90% 160/178 [00:20<00:02,  7.71it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.210, train/acc=0.692]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.78it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 137.78it/s]\u001b[A\n","Epoch 491: 100% 178/178 [00:20<00:00,  8.53it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.210, train/acc=0.692]\n","Epoch 492:   0% 0/178 [00:15<?, ?it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 492:  11% 20/178 [00:19<02:30,  1.05it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 121.68it/s]\u001b[A\n","Epoch 492:  22% 40/178 [00:19<01:06,  2.08it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 132.78it/s]\u001b[A\n","Epoch 492:  34% 60/178 [00:19<00:38,  3.10it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 130.92it/s]\u001b[A\n","Epoch 492:  45% 80/178 [00:19<00:23,  4.10it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.37it/s]\u001b[A\n","Epoch 492:  56% 100/178 [00:19<00:15,  5.08it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.18it/s]\u001b[A\n","Epoch 492:  67% 120/178 [00:19<00:09,  6.05it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.31it/s]\u001b[A\n","Epoch 492:  79% 140/178 [00:19<00:05,  7.01it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.21it/s]\u001b[A\n","Epoch 492:  90% 160/178 [00:20<00:02,  7.95it/s, loss=1.22, v_num=2, val/loss=1.440, Val/acc=0.458, train/loss=1.230, train/acc=0.671]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.72it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.72it/s]\u001b[A\n","Epoch 492: 100% 178/178 [00:20<00:00,  8.79it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.230, train/acc=0.671]\n","Epoch 493:   0% 0/178 [00:14<?, ?it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 493:  11% 20/178 [00:20<02:40,  1.01s/it, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 109.08it/s]\u001b[A\n","Epoch 493:  22% 40/178 [00:20<01:10,  1.96it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 115.53it/s]\u001b[A\n","Epoch 493:  34% 60/178 [00:20<00:40,  2.91it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 118.29it/s]\u001b[A\n","Epoch 493:  45% 80/178 [00:20<00:25,  3.85it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 117.51it/s]\u001b[A\n","Epoch 493:  56% 100/178 [00:20<00:16,  4.77it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 121.95it/s]\u001b[A\n","Epoch 493:  67% 120/178 [00:21<00:10,  5.69it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 122.68it/s]\u001b[A\n","Epoch 493:  79% 140/178 [00:21<00:05,  6.58it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 124.17it/s]\u001b[A\n","Epoch 493:  90% 160/178 [00:21<00:02,  7.47it/s, loss=1.22, v_num=2, val/loss=1.430, Val/acc=0.488, train/loss=1.220, train/acc=0.692]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 127.79it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 127.79it/s]\u001b[A\n","Epoch 493: 100% 178/178 [00:21<00:00,  8.26it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.220, train/acc=0.692]\n","Epoch 494:   0% 0/178 [00:13<?, ?it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 494:  11% 20/178 [00:20<02:42,  1.03s/it, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 112.13it/s]\u001b[A\n","Epoch 494:  22% 40/178 [00:20<01:11,  1.94it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:00, 127.79it/s]\u001b[A\n","Epoch 494:  34% 60/178 [00:20<00:40,  2.88it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.87it/s]\u001b[A\n","Epoch 494:  45% 80/178 [00:20<00:25,  3.82it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 131.75it/s]\u001b[A\n","Epoch 494:  56% 100/178 [00:21<00:16,  4.74it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 133.66it/s]\u001b[A\n","Epoch 494:  67% 120/178 [00:21<00:10,  5.64it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 135.48it/s]\u001b[A\n","Epoch 494:  79% 140/178 [00:21<00:05,  6.54it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 134.02it/s]\u001b[A\n","Epoch 494:  90% 160/178 [00:21<00:02,  7.42it/s, loss=1.21, v_num=2, val/loss=1.470, Val/acc=0.428, train/loss=1.210, train/acc=0.695]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.78it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 138.78it/s]\u001b[A\n","Epoch 494: 100% 178/178 [00:21<00:00,  8.21it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.210, train/acc=0.695] \n","Epoch 495:   0% 0/178 [00:11<?, ?it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 495:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 109.91it/s]\u001b[A\n","Epoch 495:  22% 40/178 [00:20<01:09,  1.99it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 121.80it/s]\u001b[A\n","Epoch 495:  34% 60/178 [00:20<00:39,  2.96it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.45it/s]\u001b[A\n","Epoch 495:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.75it/s]\u001b[A\n","Epoch 495:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 128.18it/s]\u001b[A\n","Epoch 495:  67% 120/178 [00:20<00:10,  5.78it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 129.72it/s]\u001b[A\n","Epoch 495:  79% 140/178 [00:20<00:05,  6.70it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 130.41it/s]\u001b[A\n","Epoch 495:  90% 160/178 [00:21<00:02,  7.60it/s, loss=1.2, v_num=2, val/loss=1.390, Val/acc=0.506, train/loss=1.200, train/acc=0.712]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.71it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 133.71it/s]\u001b[A\n","Epoch 495: 100% 178/178 [00:21<00:00,  8.41it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.712]\n","Epoch 496:   0% 0/178 [00:10<?, ?it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 496:  11% 20/178 [00:20<02:38,  1.00s/it, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.15it/s]\u001b[A\n","Epoch 496:  22% 40/178 [00:20<01:09,  1.98it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.97it/s]\u001b[A\n","Epoch 496:  34% 60/178 [00:20<00:39,  2.95it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 126.56it/s]\u001b[A\n","Epoch 496:  45% 80/178 [00:20<00:25,  3.91it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 128.48it/s]\u001b[A\n","Epoch 496:  56% 100/178 [00:20<00:16,  4.85it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.97it/s]\u001b[A\n","Epoch 496:  67% 120/178 [00:20<00:10,  5.78it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 132.03it/s]\u001b[A\n","Epoch 496:  79% 140/178 [00:20<00:05,  6.69it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 133.66it/s]\u001b[A\n","Epoch 496:  90% 160/178 [00:21<00:02,  7.59it/s, loss=1.2, v_num=2, val/loss=1.430, Val/acc=0.464, train/loss=1.200, train/acc=0.701]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.83it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.83it/s]\u001b[A\n","Epoch 496: 100% 178/178 [00:21<00:00,  8.40it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.200, train/acc=0.701]\n","Epoch 497:   0% 0/178 [00:19<?, ?it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 497:  11% 20/178 [00:19<02:35,  1.01it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 117.93it/s]\u001b[A\n","Epoch 497:  22% 40/178 [00:19<01:08,  2.02it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 124.71it/s]\u001b[A\n","Epoch 497:  34% 60/178 [00:19<00:39,  3.00it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 129.69it/s]\u001b[A\n","Epoch 497:  45% 80/178 [00:20<00:24,  3.97it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 130.75it/s]\u001b[A\n","Epoch 497:  56% 100/178 [00:20<00:15,  4.93it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 135.50it/s]\u001b[A\n","Epoch 497:  67% 120/178 [00:20<00:09,  5.87it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 136.47it/s]\u001b[A\n","Epoch 497:  79% 140/178 [00:20<00:05,  6.80it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 135.55it/s]\u001b[A\n","Epoch 497:  90% 160/178 [00:20<00:02,  7.72it/s, loss=1.22, v_num=2, val/loss=1.460, Val/acc=0.440, train/loss=1.230, train/acc=0.675]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.81it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 139.81it/s]\u001b[A\n","Epoch 497: 100% 178/178 [00:20<00:00,  8.54it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.230, train/acc=0.675]\n","Epoch 498:   0% 0/178 [00:18<?, ?it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 498:  11% 20/178 [00:20<02:39,  1.01s/it, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 108.57it/s]\u001b[A\n","Epoch 498:  22% 40/178 [00:20<01:10,  1.97it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 122.66it/s]\u001b[A\n","Epoch 498:  34% 60/178 [00:20<00:40,  2.93it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 127.43it/s]\u001b[A\n","Epoch 498:  45% 80/178 [00:20<00:25,  3.88it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 129.21it/s]\u001b[A\n","Epoch 498:  56% 100/178 [00:20<00:16,  4.82it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 131.99it/s]\u001b[A\n","Epoch 498:  67% 120/178 [00:20<00:10,  5.74it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 131.53it/s]\u001b[A\n","Epoch 498:  79% 140/178 [00:21<00:05,  6.65it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 131.61it/s]\u001b[A\n","Epoch 498:  90% 160/178 [00:21<00:02,  7.55it/s, loss=1.23, v_num=2, val/loss=1.470, Val/acc=0.434, train/loss=1.220, train/acc=0.684]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.21it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 136.21it/s]\u001b[A\n","Epoch 498: 100% 178/178 [00:21<00:00,  8.35it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.684]\n","Epoch 499:   0% 0/178 [00:17<?, ?it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/166 [00:00<?, ?it/s]\u001b[A\n","Epoch 499:  11% 20/178 [00:19<02:37,  1.01it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  12% 20/166 [00:00<00:01, 97.76it/s]\u001b[A\n","Epoch 499:  22% 40/178 [00:20<01:09,  2.00it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  24% 40/166 [00:00<00:01, 115.43it/s]\u001b[A\n","Epoch 499:  34% 60/178 [00:20<00:39,  2.97it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  36% 60/166 [00:00<00:00, 125.66it/s]\u001b[A\n","Epoch 499:  45% 80/178 [00:20<00:24,  3.94it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  48% 80/166 [00:00<00:00, 125.95it/s]\u001b[A\n","Epoch 499:  56% 100/178 [00:20<00:15,  4.88it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  60% 100/166 [00:00<00:00, 129.14it/s]\u001b[A\n","Epoch 499:  67% 120/178 [00:20<00:09,  5.82it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  72% 120/166 [00:00<00:00, 130.40it/s]\u001b[A\n","Epoch 499:  79% 140/178 [00:20<00:05,  6.74it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  84% 140/166 [00:01<00:00, 128.13it/s]\u001b[A\n","Epoch 499:  90% 160/178 [00:20<00:02,  7.64it/s, loss=1.22, v_num=2, val/loss=1.380, Val/acc=0.542, train/loss=1.220, train/acc=0.680]\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.65it/s]\u001b[A\n","Validation DataLoader 0:  96% 160/166 [00:01<00:00, 134.65it/s]\u001b[A\n","Epoch 499: 100% 178/178 [00:21<00:00,  8.45it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.220, train/acc=0.680]\n","Epoch 499: 100% 178/178 [00:21<00:00,  8.44it/s, loss=1.21, v_num=2, val/loss=1.420, Val/acc=0.482, train/loss=1.210, train/acc=0.693]\n"]}],"source":["!python train_voxceleb.py --n_workers=8 --gpu=1 --wdecay 1e-3 --lr 1e-3"]},{"cell_type":"markdown","metadata":{"id":"pKPyVA2nRiGM"},"source":["# Test the trained model\n","\n","add the path to last saved model checkpoint"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33610,"status":"ok","timestamp":1662208168015,"user":{"displayName":"אורי אוחיון","userId":"05864461685659628366"},"user_tz":-180},"id":"KSZXz1FFc1NE","outputId":"e28eb06a-4a45-43af-e789-1165090c0b88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Testing SpectralCNNLSTM from Final_Models/SpectralCNNLSTM_FULL_DB/model.ckpt on VoxCeleb Dataset\n","Cores = 12\t#GPU = 0\n","/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:540: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n","  \"At least one mel filterbank has all zero values. \"\n","2022-09-03 12:28:58 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmpw69pc9nd\n","2022-09-03 12:28:58 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmpw69pc9nd/_remote_module_non_scriptable.py\n","Model Details: #Params = 134338\t#Trainable Params = 134338\n","100% 172/172 [00:28<00:00,  6.07it/s]\n","Male Age RMSE: 11.1880 , Age MAE: 8.8893 \n","Female Age RMSE: 12.4292 , Age MAE: 9.4245 \n","Total RMSE: 11.4960 , Total MAE: 9.0169\n","Gender Accuracy: 0.9477\n"]}],"source":["!python test_voxceleb.py --model_checkpoint='Final_Models/SpectralCNNLSTM_FULL_DB/model.ckpt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCV2k_gGrAWw"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}